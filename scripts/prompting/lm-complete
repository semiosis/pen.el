#!/bin/bash

# Example of usage:
# export PEN_PROMPTS_DIR=$MYGIT/semiosis/prompts
# export PEN_PROMPT="Once upon a time"
# lm-complete

# The envs may be stored in stdin

. $SCRIPTS/lib/stdin_exists

if stdin_exists; then
    IFS= read -rd '' stdin_envs < <(cat);typeset -p stdin_envs &>/dev/null
    # echo "$stdin_envs" | pen-tv &>/dev/null
    eval "$stdin_envs"
fi

{
while [ $# -gt 0 ]; do opt="$1"; case "$opt" in
    "") { shift; }; ;;
    -d) {
        export LM_COMPLETE_DEBUG=y
        shift
    }
    ;;

    *) break;
esac; done

PEN_RESULTS_DIR=~/.pen/results
mkdir -p "$PEN_RESULTS_DIR"

test -n "$PEN_LM_COMMAND" || {
    echo "PEN_LM_COMMAND not supplied"
    exit 1
}

# Force human promptee
PEN_LM_COMMAND=human-complete.sh

test -n "$ALSO_EXPORT" && {
    eval "export $ALSO_EXPORT"
}

: "${PEN_MIN_TOKENS:="20"}"
: "${PEN_MAX_TOKENS:="60"}"
: "${PEN_MIN_GENERATED_TOKENS:="10"}"
: "${PEN_MAX_GENERATED_TOKENS:="10"}"
: "${PEN_ENGINE_MIN_TOKENS:="20"}"
: "${PEN_ENGINE_MAX_TOKENS:="60"}"
: "${PEN_ENGINE_MAX_GENERATED_TOKENS:="256"}"
: "${PEN_TEMPERATURE:="0.8"}"
: "${PEN_TOP_P:="1"}"
: "${PEN_TOP_K:="10"}"
# if test -n "$PEN_PROMPT"; then
#     IFS= read -rd '' PEN_PROMPT < <(printf -- "%s" "$PEN_PROMPT" | base64 -d);typeset -p PEN_PROMPT &>/dev/null
# fi
: "${PEN_PROMPT:="Once upon a time"}"
: "${PEN_N_COMPLETIONS:="1"}"
: "${PEN_ENGINE_MAX_N_COMPLETIONS:="10"}"
: "${PEN_COLLECT_FROM_POS:="$(printf -- "%s" "$PEN_PROMPT" | wc -c)"}"
: "${PEN_USER_AGENT:="emacs/pen"}"

export PEN_LM_COMMAND
export PEN_WORKER
export PEN_USER_AGENT
export PEN_LM_KEY
export PEN_MIN_TOKENS
export PEN_MAX_TOKENS
export PEN_MIN_GENERATED_TOKENS
export PEN_MAX_GENERATED_TOKENS
export PEN_APPROXIMATE_PROMPT_LENGTH
export PEN_ENGINE_MIN_TOKENS
export PEN_ENGINE_MAX_TOKENS
export PEN_ENGINE_MAX_GENERATED_TOKENS
export PEN_TEMPERATURE
export PEN_TOP_P
export PEN_TOP_K
export PEN_PROMPT
export PEN_SUFFIX
export PEN_API_ENDPOINT
export PEN_PAYLOADS
export PEN_FLAGS
export PEN_STOP_SEQUENCE
export PEN_STOP_SEQUENCES
export PEN_N_COMPLETIONS
export PEN_ENGINE_MAX_N_COMPLETIONS
export PEN_COLLECT_FROM_POS
export PEN_MEMORY_COLLECT_FROM_POS
export PEN_END_POS
export PEN_SEARCH_THRESHOLD
export PEN_TRAILING_WHITESPACE
# Each PEN_LM_COMMAND script may take a 'mode'. For example, summarization.
# Sometimes the mode must be specified because there may be multiple API interfaces.
# For pen-hf.py, the mode could be "summarize", but the mode shouldn't be confused with a task
export PEN_MODE
export PEN_GEN_UUID
export PEN_GEN_TIME
export PEN_GEN_DATE
export PEN_GEN_DIR

# TODO Differentiate between these
export PEN_N_JOBS
: "${PEN_N_CONCURRENT_JOBS:="$PEN_N_JOBS"}"
export PEN_N_CONCURRENT_JOBS

if test -n "$LM_COMPLETE_DEBUG"; then
    pen-proxy-generate-envs | pen-tv &>/dev/null
fi

# if test -n "$PEN_GEN_TIME"; then
#     PEN_GEN_DATE="$(date +%d.%m.%y -d "@${PEN_GEN_TIME}")"
# fi
# export PEN_GEN_DIR="$PEN_RESULTS_DIR/results_${PEN_GEN_TIME}_${PEN_GEN_DATE}_${PEN_GEN_UUID}"

# This file expects the PEN_PROMPTS_DIR

# Update caches (would override PEN_CACHE)
if test "$UPDATE" = y; then
    PEN_CACHE=
fi

# It's already broken. Happens in sn
# printf -- "%s" "$PEN_PROMPT" | tv &>/dev/null

# if PEN_CACHE==y then pen.el has indicated this should be cached/memoised.
# This is handled by `pen-ci`
export PEN_CACHE

if ! test -s $HOME/.pen/aix_api_key; then
    PEN_LM_COMMAND=openai-complete.sh
fi

case "$PEN_LM_COMMAND" in
    ai21-complete.sh) {
        if ! test -s $HOME/.pen/ai21_api_key; then
            # Switch to OpenAI of no key

            PEN_LM_COMMAND=openai-complete.sh
            export PEN_MODEL=davinci
        fi
    }
    ;;

    alephalpha-complete.sh) {
        if ! test -s $HOME/.pen/alephalpha_api_key; then
            # Switch to OpenAI of no key

            PEN_LM_COMMAND=openai-complete.sh
            export PEN_MODEL=UnknownMultiModal
        fi
    }
    ;;

    aix-complete.sh) {
        if ! test -s $HOME/.pen/aix_api_key; then
            # Switch to OpenAI of no key

            PEN_LM_COMMAND=openai-complete.sh
            export PEN_MODEL=davinci
        fi
    }
    ;;

    openai-complete.sh) {
            # Switch to OpenAI of no key

        if ! test -s $HOME/.pen/openai_api_key; then
            PEN_LM_COMMAND=aix-complete.sh
            export PEN_MODEL=GPT-J-6B
        fi
    }
    ;;
esac

case "$PEN_LM_COMMAND" in
    ai21-complete.sh) {
        :
    }
    ;;

    aix-complete.sh) {
        # It's too slow otherwise
        export PEN_N_COMPLETIONS=1
    }
    ;;

    goose-complete.sh) {
        export PEN_N_COMPLETIONS=1
    }
    ;;

    human-complete.sh) {
        # Need this because completions are always 1
        export PEN_N_COMPLETIONS=1
    }
    ;;

    hf-complete.sh) {
        # It's too slow otherwise

        if test "$PEN_MODE" = summarize; then
            # This is to ensure it's properly truncated
            export PEN_N_COMPLETIONS=1
        fi
    }
    ;;
esac

tmpdir=~/.pen/temp
mkdir -p "$tmpdir"
} &>/dev/null

proxy_lm_complete() {
    proxy_envs="$(pen-proxy-generate-envs)"

    # cmd curl -s --header "Content-Type: application/json; charset=utf-8" --request POST --data "$proxy_envs" "http://$PEN_PROXY/lm-complete" | xc &>/dev/null
    curl -s --header "Content-Type: application/json; charset=utf-8" --request POST --data "$proxy_envs" "http://$PEN_PROXY/lm-complete"
    return 0
}

export PEN_PROXY

# Actually, do not use pen-ci to cache here, yet.
# I would need to get a sha of all environment variables first.
# TODO For relevent environment variables, compute a sha for those and export the sha from elisp
# Don't compute the sha here

export PEN_PROXY_RESPONSE

if ! test -n "$PEN_GEN_DIR"; then
    if test "$PEN_PROXY_RESPONSE" = y; then
        : "${PEN_GEN_TIME:="$(date-ts)"}"
        : "${PEN_GEN_DATE:="$(date +%d.%m.%y -d "@${PEN_GEN_TIME}")"}"
        : "${PEN_GEN_DIR:="/root/.pen/results/"}"
    else
        # pen-proxy-generate-envs | pen-tv &>/dev/null
        echo PEN_GEN_DIR not specified 1>&2
        exit
    fi
fi

debug_tv() {
    if test -n "$LM_COMPLETE_DEBUG"; then
        pen-tv
    else
        cat
    fi
}

output_json_maybe(){
    if test "$PEN_PROXY_RESPONSE" = y; then
        # Convert directories to json
        # For each results dir, aggregate all result files
        awk 1 | while IFS=$'\n' read -r line; do
            pen-glob "$line/split*_*"
            pen-glob "$line/results*/split*_*"
            pen-glob "$line/res*.txt"
            pen-glob "$line/results*/res*.txt"
        done | {
            echo "["
            IFS=$'\n' read -r result
            if test -n "$result"; then
                cat "$result" | pen-q-jq
            fi
            while IFS=$'\n' read -r result; do
                echo ","
                cat "$result" | pen-q-jq
            done
            echo
            echo "]"
        }
    else
        cat
    fi
}

if test -n "$PEN_PROXY"; then
    # PEN_GEN_DIR
    # echo "tnehoa" | pen-tv

    # this comes out in jsonl
    # I need to transform it into separate files.

    i=0
    mkdir -p "$PEN_GEN_DIR"
    proxy_lm_complete | awk 1 | sed -e '/^\[/d' -e '/\]$/d' -e 's/,$//' | while IFS=$'\n' read -r line; do
        printf -- "%s" "$line" | pen-uq-jq > "$PEN_GEN_DIR/splitfile_$i.txt"
        i=$((i + 1))
    done
    echo "$PEN_GEN_DIR" 
    exit

    # The proxy system must be able to send back all results,
    # Not in the format of a list of directories.
    # Rather a singular json containing all results, which are reconstructed as directories

    # PEN_GEN_DIR will still be used, but here. Not in the proxy. The proxy will return all the results in a single JSON object
fi

# cmd parallel -j "$PEN_N_JOBS" | pen-tv &>/dev/null

if test "$LM_COMPLETE_DEBUG" = y; then
    # this will echo a single dir
    "$PEN_LM_COMMAND"
else
    {
    if test -n "$PEN_N_JOBS" && ! test "$PEN_N_JOBS" = 1; then
        mkdir -p "$PEN_GEN_DIR"

        # If I run the jobs with tmux then I can use the human engine

        # Do all of them in parallel
        #pen-ci "$PEN_LM_COMMAND" | awk 1 | while IFS=$'\n' read -r result_dir; do
        #    mv "$result_dir" "$PEN_GEN_DIR/"
        #done &>/dev/null
        for (( i = 1; i < "$PEN_N_JOBS"; i++ )); do
            # cmd-nice-posix pen-odn pen-ci --enabled= "$PEN_CACHE" "$PEN_LM_COMMAND" | awk 1
            cmd-nice-posix "$PEN_LM_COMMAND" | awk 1
            continue
        done | parallel -j "$PEN_N_JOBS" | awk 1 | while IFS=$'\n' read -r result_dir; do

            # I need a hack here.
            # The response from dalle-complete.sh must be modified
            mv "$result_dir" "$PEN_GEN_DIR/"

            bndn="$(basename -- "$result_dir")"
            if test -d "$PEN_GEN_DIR/$bndn/images"; then
                sed -i "s=^=$PEN_GEN_DIR/=" "$PEN_GEN_DIR/$bndn/response.txt"
            fi

            # the contents of reponse.txt is memoised

        done &>/dev/null
        echo "$PEN_GEN_DIR" | tee "$tmpdir/lm-complete-stdout.txt"
    else
        ## pen-ci will possibly cache/memoize the command
        # pen-ci "$PEN_LM_COMMAND" 2>"$tmpdir/lm-complete-stderr.txt" >"$tmpdir/lm-complete-stdout.txt"
        "$PEN_LM_COMMAND" 2>"$tmpdir/lm-complete-stderr.txt" >"$tmpdir/lm-complete-stdout.txt"
        cat "$tmpdir/lm-complete-stdout.txt"
    fi
    } | output_json_maybe | debug_tv
fi
# pen-proxy-generate-envs | pen-tv &>/dev/null

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# https://beta.openai.com/docs/api-reference/completions/create

# logprobs
# https://blog.scottlogic.com/2021/09/01/a-primer-on-the-openai-api-2.html

import openai
import os
import json
from typing import List

# The client semantic search system sends multiple prompts in a single request.
# Firstly, what is the reason for a list?
# TODO Make support for this.

# Taken from https://github.com/openai/openai-python/blob/main/examples/semanticsearch/semanticsearch.py
SCORE_MULTIPLIER = 100.0

API_TOKEN = os.environ.get("OPENAI_API_KEY")
PEN_MODEL = os.environ.get("PEN_MODEL") or "davinci"
PEN_MODEL = os.environ.get("PEN_MODEL") or "davinci-codex"
PEN_PROMPT = os.environ.get("PEN_PROMPT") or ""
PEN_SUFFIX = os.environ.get("PEN_SUFFIX") or ""
PEN_PAYLOADS = os.environ.get("PEN_PAYLOADS")
# Typically used for semantic search.
# Documents may be inserted into a prompt, exploding the prompt into a list, but only if PEN_PROMPTS doesn't already exist.
# As the exploding may happen within Pen.el
PEN_DOCUMENTS = os.environ.get("PEN_DOCUMENTS")
PEN_MODE = os.environ.get("PEN_MODE")
PEN_TEMPERATURE = os.environ.get("PEN_TEMPERATURE") or "0.8"
# json.loads("[\"hello my ;\\\"\",\"friend\"]")
PEN_STOP_SEQUENCES = json.loads(os.environ.get("PEN_STOP_SEQUENCES") or "[\"\\n\"]") or ["\n"]
PEN_STOP_SEQUENCE = os.environ.get("PEN_STOP_SEQUENCE") or "\n"
# empty string is falsy
PEN_LOGPROBS = os.environ.get("PEN_LOGPROBS")
PEN_END_POS = os.environ.get("PEN_END_POS") or len(PEN_PROMPT)
PEN_COLLECT_FROM_POS = os.environ.get("PEN_COLLECT_FROM_POS") or PEN_END_POS
PEN_TOP_K = os.environ.get("PEN_TOP_K") or "5"
PEN_TOP_P = float(os.environ.get("PEN_TOP_P") or "1.0")
PEN_SEARCH_THRESHOLD = float(os.environ.get("PEN_SEARCH_THRESHOLD") or "100")
PEN_QUERY = os.environ.get("PEN_QUERY")
PEN_GEN_UUID = os.environ.get("PEN_GEN_UUID")
PEN_GEN_TIME = os.environ.get("PEN_GEN_TIME")

if PEN_TOP_P > 1.0:
    PEN_TOP_P = 1.0

if PEN_COLLECT_FROM_POS:
    PEN_COLLECT_FROM_POS = int(PEN_COLLECT_FROM_POS)

if PEN_END_POS:
    PEN_END_POS = int(PEN_END_POS)

if PEN_SEARCH_THRESHOLD:
    PEN_SEARCH_THRESHOLD = float(PEN_SEARCH_THRESHOLD)

if PEN_DOCUMENTS:
    PEN_DOCUMENTS = json.loads(PEN_DOCUMENTS)

PEN_N_COMPLETIONS = os.environ.get("PEN_N_COMPLETIONS") or "2"
PEN_MAX_TOKENS = os.environ.get("PEN_MAX_TOKENS") or "15"
PEN_FREQUENCY_PENALTY = os.environ.get("PEN_FREQUENCY_PENALTY") or "0"
PEN_PRESENCE_PENALTY = os.environ.get("PEN_PRESENCE_PENALTY") or "0"
PEN_MAX_GENERATED_TOKENS = os.environ.get("PEN_MAX_GENERATED_TOKENS") or "5"
PEN_LOGIT_BIAS = os.environ.get("PEN_LOGIT_BIAS")
PEN_TRAILING_WHITESPACE = os.environ.get("PEN_TRAILING_WHITESPACE")

# Serialise the LOGIT_BIAS as json
# It needs to arrive as a python dict

# LOGIT_BIAS is not a big priority
# Besides, char-level models might make this completely redundant


def get_score(choice) -> float:
    query_len=(PEN_END_POS - PEN_COLLECT_FROM_POS)

    logprobs: List[float] = choice.logprobs.token_logprobs
    text = choice.logprobs.tokens
    total_len = 0
    last_used = len(text)
    while total_len < query_len:
        assert last_used > 0
        total_len += len(text[last_used - 1])
        last_used -= 1
    logits: List[float] = logprobs[last_used:]
    return sum(logits) / len(logits) * SCORE_MULTIPLIER

# I think I need to build the arguments list here.
# This is getting a bit silly.
# Or I could write this in clojure with libpython

# It might not be possible to use the Edit endpoint with the python client yet.
# I have to be using my shell script instead.
# Although, I should really be using a different languge.
if PEN_MODE == "edit":
    cs = openai.Completion.create(
        engine=PEN_MODEL,
        prompt=[PEN_PROMPT.replace("<document>", "")] +
        [PEN_PROMPT.replace("<document>", doc) for doc in PEN_DOCUMENTS],
        logprobs=0,
        max_tokens=0,
        temperature=float(PEN_TEMPERATURE),
        echo=True)['choices']
elif PEN_MODE == "search":
    cs = openai.Completion.create(
        engine=PEN_MODEL,
        prompt=[PEN_PROMPT.replace("<document>", "")] +
        [PEN_PROMPT.replace("<document>", doc) for doc in PEN_DOCUMENTS],
        logprobs=0,
        max_tokens=0,
        temperature=float(PEN_TEMPERATURE),
        echo=True)['choices']
elif PEN_LOGPROBS is not None and PEN_LOGPROBS:
    if PEN_SUFFIX:
        cs = openai.Completion.create(
            n=int(PEN_N_COMPLETIONS),
            engine=PEN_MODEL,
            prompt=PEN_PROMPT,
            suffix=PEN_SUFFIX,
            logprobs=int(PEN_LOGPROBS),
            frequency_penalty=float(PEN_FREQUENCY_PENALTY),
            presence_penalty=float(PEN_PRESENCE_PENALTY),
            top_p=float(PEN_TOP_P),
            best_of=int(PEN_TOP_K),
            # stop=PEN_STOP_SEQUENCE,
            stop=PEN_STOP_SEQUENCES,
            max_tokens=int(PEN_MAX_GENERATED_TOKENS),
            temperature=float(PEN_TEMPERATURE))['choices']
    else:
        cs = openai.Completion.create(
            n=int(PEN_N_COMPLETIONS),
            engine=PEN_MODEL,
            prompt=PEN_PROMPT,
            logprobs=int(PEN_LOGPROBS),
            frequency_penalty=float(PEN_FREQUENCY_PENALTY),
            presence_penalty=float(PEN_PRESENCE_PENALTY),
            top_p=float(PEN_TOP_P),
            best_of=int(PEN_TOP_K),
            # stop=PEN_STOP_SEQUENCE,
            stop=PEN_STOP_SEQUENCES,
            max_tokens=int(PEN_MAX_GENERATED_TOKENS),
            temperature=float(PEN_TEMPERATURE))['choices']
else:
    if PEN_SUFFIX:
        cs = openai.Completion.create(
            n=int(PEN_N_COMPLETIONS),
            engine=PEN_MODEL,
            prompt=PEN_PROMPT,
            suffix=PEN_SUFFIX,
            frequency_penalty=float(PEN_FREQUENCY_PENALTY),
            presence_penalty=float(PEN_PRESENCE_PENALTY),
            top_p=float(PEN_TOP_P),
            best_of=int(PEN_TOP_K),
            # stop=PEN_STOP_SEQUENCE,
            stop=PEN_STOP_SEQUENCES,
            max_tokens=int(PEN_MAX_GENERATED_TOKENS),
            temperature=float(PEN_TEMPERATURE))['choices']
    else:
        cs = openai.Completion.create(
            n=int(PEN_N_COMPLETIONS),
            engine=PEN_MODEL,
            prompt=PEN_PROMPT,
            frequency_penalty=float(PEN_FREQUENCY_PENALTY),
            presence_penalty=float(PEN_PRESENCE_PENALTY),
            top_p=float(PEN_TOP_P),
            best_of=int(PEN_TOP_K),
            # stop=PEN_STOP_SEQUENCE,
            stop=PEN_STOP_SEQUENCES,
            max_tokens=int(PEN_MAX_GENERATED_TOKENS),
            temperature=float(PEN_TEMPERATURE))['choices']

if PEN_MODE == "search":
    return_data = sorted(cs, key=lambda choice: choice.index)

    scores = [get_score(choice) for choice in return_data]
    # subtract score for empty document
    scores = [score - scores[0] for score in scores][1:]

    min_score=min(scores)
    scores[:] = [score - min_score for score in scores]
    max_score=max(scores)
    scores[:] = [score / max_score for score in scores]

    f = open("/tmp/scores.txt", "w")
    f.write(str(scores))
    f.close()

    results=[
        PEN_DOCUMENTS[document_idx]
        for document_idx, score in enumerate(scores)
        if score > PEN_SEARCH_THRESHOLD
    ]

    # This is ugly but it works
    if len(results) == 1:
        # print(PEN_PROMPT, end = '')
        print(results[0])
    else:
        for x in range(len(results)):
            print(f"===== Completion %i =====" % x)
            print(results[x])
else:
    if len(cs) == 1:
        print(PEN_PROMPT + cs[0]['text'].rstrip() + PEN_SUFFIX, end = '\n')
    else:
        for x in range(len(cs)):
            print(f"===== Completion %i =====" % x)
            print(PEN_PROMPT + cs[x]['text'].rstrip() + PEN_SUFFIX, end = '\n')


# with open('cs.json', 'w') as f:
#     json.dump(cs, f)

exit(0)

cs[0]['text']
cs[0]['logprobs']
cs[0]['logprobs']['text_offset']
cs[0]['logprobs']['token_logprobs']
cs[0]['logprobs']['tokens']
cs[0]['logprobs']['top_logprobs']
cs[0]['logprobs']['top_logprobs'][0]
cs[0]['logprobs']['top_logprobs'][0].keys()
cs[0]['logprobs']['top_logprobs'][0].values()
# json
# tv(str(cs[0]))
sps("jq . | vs", str(cs[0]))
sps("jq . | jq-showschema | vs", str(cs[0]))
# jq-showschema

cs[1]['text']
cs[1]['logprobs']
sps("jq . | jq-showschema | vs", str(cs[1]))

# Return probabilities
# 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# https://beta.openai.com/docs/api-reference/completions/create

# logprobs
# https://blog.scottlogic.com/2021/09/01/a-primer-on-the-openai-api-2.html

import openai
import os
import json
from typing import List

# The client semantic search system sends multiple prompts in a single request.
# Firstly, what is the reason for a list?
# TODO Make support for this.

# Taken from https://github.com/openai/openai-python/blob/main/examples/semanticsearch/semanticsearch.py
SCORE_MULTIPLIER = 100.0

API_TOKEN = os.environ.get("OPENAI_API_KEY")
PEN_MODEL = os.environ.get("PEN_MODEL") or "davinci"
PEN_MODEL = os.environ.get("PEN_MODEL") or "davinci-codex"
PEN_PROMPT = os.environ.get("PEN_PROMPT") or "Once upon a time"
PEN_PAYLOADS = os.environ.get("PEN_PAYLOADS")
# Typically used for semantic search.
# Documents may be inserted into a prompt, exploding the prompt into a list, but only if PEN_PROMPTS doesn't already exist.
# As the exploding may happen within Pen.el
PEN_DOCUMENTS = os.environ.get("PEN_DOCUMENTS")
PEN_MODE = os.environ.get("PEN_MODE")
PEN_TEMPERATURE = os.environ.get("PEN_TEMPERATURE") or "0.8"
# json.loads("[\"hello my ;\\\"\",\"friend\"]")
PEN_STOP_SEQUENCES = json.loads(os.environ.get("PEN_STOP_SEQUENCES") or "[\"\\n\"]") or ["\n"]
PEN_STOP_SEQUENCE = os.environ.get("PEN_STOP_SEQUENCE") or "\n"
# empty string is falsy
PEN_LOGPROBS = os.environ.get("PEN_LOGPROBS")
PEN_END_POS = os.environ.get("PEN_END_POS") or len(PEN_PROMPT)
PEN_COLLECT_FROM_POS = os.environ.get("PEN_COLLECT_FROM_POS") or PEN_END_POS
PEN_TOP_K = os.environ.get("PEN_TOP_K") or "5"
PEN_TOP_P = float(os.environ.get("PEN_TOP_P") or "1.0")
PEN_SEARCH_THRESHOLD = float(os.environ.get("PEN_SEARCH_THRESHOLD") or "100")
PEN_QUERY = os.environ.get("PEN_QUERY")

if PEN_TOP_P > 1.0:
    PEN_TOP_P = 1.0

if PEN_COLLECT_FROM_POS:
    PEN_COLLECT_FROM_POS = int(PEN_COLLECT_FROM_POS)

if PEN_END_POS:
    PEN_END_POS = int(PEN_END_POS)

if PEN_SEARCH_THRESHOLD:
    PEN_SEARCH_THRESHOLD = float(PEN_SEARCH_THRESHOLD)

if PEN_DOCUMENTS:
    PEN_DOCUMENTS = json.loads(PEN_DOCUMENTS)

PEN_N_COMPLETIONS = os.environ.get("PEN_N_COMPLETIONS") or "2"
PEN_MAX_TOKENS = os.environ.get("PEN_MAX_TOKENS") or "15"
PEN_FREQUENCY_PENALTY = os.environ.get("PEN_FREQUENCY_PENALTY") or "0"
PEN_PRESENCE_PENALTY = os.environ.get("PEN_PRESENCE_PENALTY") or "0"
PEN_MAX_GENERATED_TOKENS = os.environ.get("PEN_MAX_GENERATED_TOKENS") or "5"
PEN_LOGIT_BIAS = os.environ.get("PEN_LOGIT_BIAS")
PEN_TRAILING_WHITESPACE = os.environ.get("PEN_TRAILING_WHITESPACE")

# Serialise the LOGIT_BIAS as json
# It needs to arrive as a python dict

# LOGIT_BIAS is not a big priority
# Besides, char-level models might make this completely redundant


def get_score(choice) -> float:
    query_len=(PEN_END_POS - PEN_COLLECT_FROM_POS)

    logprobs: List[float] = choice.logprobs.token_logprobs
    text = choice.logprobs.tokens
    total_len = 0
    last_used = len(text)
    while total_len < query_len:
        assert last_used > 0
        total_len += len(text[last_used - 1])
        last_used -= 1
    logits: List[float] = logprobs[last_used:]
    return sum(logits) / len(logits) * SCORE_MULTIPLIER

if PEN_MODE == "search":
    cs = openai.Completion.create(
        engine=PEN_MODEL,
        prompt=[PEN_PROMPT.replace("<document>", "")] +
        [PEN_PROMPT.replace("<document>", doc) for doc in PEN_DOCUMENTS],
        logprobs=0,
        max_tokens=0,
        temperature=float(PEN_TEMPERATURE),
        echo=True)['choices']
elif PEN_LOGPROBS is not None and PEN_LOGPROBS:
    cs = openai.Completion.create(
         n=int(PEN_N_COMPLETIONS),
         engine=PEN_MODEL,
         prompt=PEN_PROMPT,
         logprobs=int(PEN_LOGPROBS),
         frequency_penalty=float(PEN_FREQUENCY_PENALTY),
         presence_penalty=float(PEN_PRESENCE_PENALTY),
         top_p=float(PEN_TOP_P),
         best_of=int(PEN_TOP_K),
         # stop=PEN_STOP_SEQUENCE,
         stop=PEN_STOP_SEQUENCES,
         max_tokens=int(PEN_MAX_GENERATED_TOKENS),
         temperature=float(PEN_TEMPERATURE))['choices']
else:
    cs = openai.Completion.create(
         n=int(PEN_N_COMPLETIONS),
         engine=PEN_MODEL,
         prompt=PEN_PROMPT,
         frequency_penalty=float(PEN_FREQUENCY_PENALTY),
         presence_penalty=float(PEN_PRESENCE_PENALTY),
         top_p=float(PEN_TOP_P),
         best_of=int(PEN_TOP_K),
         # stop=PEN_STOP_SEQUENCE,
         stop=PEN_STOP_SEQUENCES,
         max_tokens=int(PEN_MAX_GENERATED_TOKENS),
         temperature=float(PEN_TEMPERATURE))['choices']

if PEN_MODE == "search":
    return_data = sorted(cs, key=lambda choice: choice.index)

    scores = [get_score(choice) for choice in return_data]
    # subtract score for empty document
    scores = [score - scores[0] for score in scores][1:]

    min_score=min(scores)
    scores[:] = [score - min_score for score in scores]
    max_score=max(scores)
    scores[:] = [score / max_score for score in scores]

    f = open("/tmp/scores.txt", "w")
    f.write(str(scores))
    f.close()

    results=[
        PEN_DOCUMENTS[document_idx]
        for document_idx, score in enumerate(scores)
        if score > PEN_SEARCH_THRESHOLD
    ]

    # This is ugly but it works
    if len(results) == 1:
        # print(PEN_PROMPT, end = '')
        print(results[0])
    else:
        for x in range(len(results)):
            print(f"===== Completion %i =====" % x)
            print(results[x])
else:
    if len(cs) == 1:
        print(PEN_PROMPT, end = '')
        print(cs[0]['text'])
    else:
        for x in range(len(cs)):
            print(f"===== Completion %i =====" % x)
            print(PEN_PROMPT, end = '')
            print(cs[x]['text'])


with open('cs.json', 'w') as f:
    json.dump(cs, f)

exit(0)

cs[0]['text']
cs[0]['logprobs']
cs[0]['logprobs']['text_offset']
cs[0]['logprobs']['token_logprobs']
cs[0]['logprobs']['tokens']
cs[0]['logprobs']['top_logprobs']
cs[0]['logprobs']['top_logprobs'][0]
cs[0]['logprobs']['top_logprobs'][0].keys()
cs[0]['logprobs']['top_logprobs'][0].values()
# json
# tv(str(cs[0]))
sps("jq . | vs", str(cs[0]))
sps("jq . | jq-showschema | vs", str(cs[0]))
# jq-showschema

cs[1]['text']
cs[1]['logprobs']
sps("jq . | jq-showschema | vs", str(cs[1]))

# Return probabilities
# 
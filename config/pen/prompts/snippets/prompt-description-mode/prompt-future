# -*- mode: snippet -*-
# name: prompt-future
# group: pen
# key: prf
# expand-env: ((yas-indent-line 'fixed))
# --
# ------------------------------------
# Non-functional (in-development) keys
# ------------------------------------

# Enable running conversation. This is suitable for prompts that are chatbots or REPLs.
conversation: no

# Output to test against. Possibly using similarity.
test-output: "both are types of berry"

# This compares the output of the external script to the output of the LM
similarity-test: "compare <1> <2>"

# Prefer the external command if it's available.
prefer-external: on

# This is an optional external command which may be used to perform the same task as your prompt.
# This could be used in future to train the prompt.
# The external command must take all variables as arguments (no stdin).
# echo would simply result in the prompt function returning all the arguments as given.
external: "echo"

# This script returns a 0-1 decimal value representing the quality of the generated output.
# The input is 2 arguments each containing output
# The output is a decimal number from 0 to 1
quality-script: "my-quality-checker-for-this-prompt.sh"

# This script can be used to validate the output.
# If the output is accurate, the validation script returns exit code 1.
# The input is 2 arguments each containing output
validation-script: "my-validator-for-this-prompt.sh"

# This is the name of an external database-driven pretext generator.
# It would typically summarize and fact extract from history.
# It then passes the pretext to the new prompt.
conversation-pretext-generator: "human-conversation"


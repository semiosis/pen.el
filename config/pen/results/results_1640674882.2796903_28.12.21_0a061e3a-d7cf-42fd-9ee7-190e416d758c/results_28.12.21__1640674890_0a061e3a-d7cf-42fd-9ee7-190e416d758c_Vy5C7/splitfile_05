ity"
        https://arxiv.org/abs/1904.10509
    v +/"Self-Attention Sparsity"
        https://arxiv.org/abs/1905.10671
    v +/"Sparse Transformer"
        https://arxiv.org/abs/1904.10509
    v +/"Sparse Self-Attention"
        https://arxiv.org/abs/1905.10671

    v +/"Sparse Transformer with Self-Attentive Blocks"
        https://arxiv.org/abs/1808.03965

    v +/"Sparsely Connected Convolutional Networks"
        https://arxiv.org/abs/1801.05895

    v +/"Sparsely-Connected Convolutional Networks"
        https://arxiv.org/abs/

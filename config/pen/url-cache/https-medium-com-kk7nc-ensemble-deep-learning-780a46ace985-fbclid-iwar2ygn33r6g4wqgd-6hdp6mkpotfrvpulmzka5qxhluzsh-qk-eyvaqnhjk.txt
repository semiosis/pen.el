HTTP/1.1 200 OK
Date: Sun, 27 Mar 2022 03:34:50 GMT
Content-Type: text/html; charset=utf-8
Transfer-Encoding: chunked
Connection: keep-alive
CF-Ray: 6f251293eccafb8c-AKL
Age: 6
Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Expires: Mon, 28 Mar 2022 03:34:50 GMT
Strict-Transport-Security: max-age=15552000; includeSubDomains; preload
Vary: Accept-Encoding
CF-Cache-Status: HIT
content-security-policy: frame-ancestors 'self' https://medium.com
Expect-CT: max-age=604800, report-uri="https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct"
medium-fulfilled-by: edgy/8.3.0, valencia/main-20220325-212504-f5e15dc701, lite/main-20220325-213604-e791677e68, rito/main-20220325-212859-18ba3665cd, tutu/main-20220325-221105-fe45314fb8
medium-missing-time: 387
worker-cache-key: kk7nc.medium.com/ensemble-deep-learning-780a46ace985
worker-cache-middleware: true
worker-missing-cookies: 0
X-Content-Type-Options: nosniff
x-envoy-upstream-service-time: 730
x-request-received-at: 1648352084131
Server: cloudflare
alt-svc: h3=":443"; ma=86400, h3-29=":443"; ma=86400

<!doctype html><html lang="en"><head><title data-rh="true">Ensemble Deep Learning. Referenced paper : RMDL: Random… | by Kamran Kowsari | Medium</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2019-05-22T18:43:57.707Z"/><meta data-rh="true" name="title" content="Ensemble Deep Learning. Referenced paper : RMDL: Random… | by Kamran Kowsari | Medium"/><meta data-rh="true" property="og:title" content="Ensemble Deep Learning"/><meta data-rh="true" property="twitter:title" content="Ensemble Deep Learning"/><meta data-rh="true" name="twitter:site" content="@Medium"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/780a46ace985"/><meta data-rh="true" property="al:android:url" content="medium://p/780a46ace985"/><meta data-rh="true" property="al:ios:url" content="medium://p/780a46ace985"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="A new ensemble, deep learning approach for classification. Deep learning models have achieved state-of-the-art results across many domains. RMDL solves the problem of finding the best deep learning…"/><meta data-rh="true" property="og:description" content="Referenced paper : RMDL: Random Multimodel Deep Learning for Classification"/><meta data-rh="true" property="twitter:description" content="Referenced paper : RMDL: Random Multimodel Deep Learning for Classification"/><meta data-rh="true" property="og:url" content="https://kk7nc.medium.com/ensemble-deep-learning-780a46ace985"/><meta data-rh="true" property="al:web:url" content="https://kk7nc.medium.com/ensemble-deep-learning-780a46ace985"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1143/0*jRwJaYk_Wvc3jGKw"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1143/0*jRwJaYk_Wvc3jGKw"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" property="article:author" content="https://kk7nc.medium.com"/><meta data-rh="true" name="twitter:creator" content="@KamranKowsari"/><meta data-rh="true" name="author" content="Kamran Kowsari"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="11 min read"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/fit/c/120/120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/fit/c/76/76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/fit/c/60/60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://kk7nc.medium.com"/><link data-rh="true" rel="canonical" href="https://kk7nc.medium.com/ensemble-deep-learning-780a46ace985"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/780a46ace985"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F0*jRwJaYk_Wvc3jGKw"],"url":"https:\u002F\u002Fkk7nc.medium.com\u002Fensemble-deep-learning-780a46ace985","dateCreated":"2019-05-22T18:35:21.515Z","datePublished":"2019-05-22T18:35:21.515Z","dateModified":"2021-12-10T03:06:26.128Z","headline":"Ensemble Deep Learning - Kamran Kowsari - Medium","name":"Ensemble Deep Learning - Kamran Kowsari - Medium","description":"A new ensemble, deep learning approach for classification. Deep learning models have achieved state-of-the-art results across many domains. RMDL solves the problem of finding the best deep learning…","identifier":"780a46ace985","author":{"@type":"Person","name":"Kamran Kowsari","url":"https:\u002F\u002Fkk7nc.medium.com"},"creator":["Kamran Kowsari"],"publisher":{"@type":"Organization","name":"Medium","url":"https:\u002F\u002Fkk7nc.medium.com\u002F","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F616\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https:\u002F\u002Fkk7nc.medium.com\u002Fensemble-deep-learning-780a46ace985"}</script><style type="text/css" data-fela-rehydration="535" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{margin:auto}.n{max-width:1504px}.o{display:flex}.u{justify-content:space-between}.ag{height:100%}.al{padding:0 24px}.am{box-shadow:0px -2px 10px rgba(0, 0, 0, 0.15)}.an{height:56px}.ao{align-items:center}.ap{position:fixed}.aq{top:0}.ar{right:0}.as{left:0}.at{z-index:500}.au{color:inherit}.av{fill:inherit}.aw{font-size:inherit}.ax{border:inherit}.ay{font-family:inherit}.az{letter-spacing:inherit}.ba{font-weight:inherit}.bb{padding:0}.bc{margin:0}.bg:disabled{cursor:default}.bh:disabled{color:rgba(117, 117, 117, 1)}.bi:disabled{fill:rgba(117, 117, 117, 1)}.bj{height:25px}.bk{fill:rgba(41, 41, 41, 1)}.bl{margin-left:16px}.bm{display:none}.bo{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bp{font-size:14px}.bq{line-height:20px}.br{color:rgba(117, 117, 117, 1)}.bs{color:rgba(26, 137, 23, 1)}.bt{fill:rgba(26, 137, 23, 1)}.bw:disabled{color:rgba(163, 208, 162, 0.5)}.bx:disabled{fill:rgba(163, 208, 162, 0.5)}.cd{height:100vh}.ce{flex-direction:column}.cf{position:sticky}.cg{z-index:1}.ch{height:23px}.ci{padding-bottom:35px}.cj{fill:rgba(117, 117, 117, 1)}.ck{padding-left:28px}.cl{transition:all 0.2s ease-in-out}.cp{margin-right:28px}.cr{font-size:16px}.cs{line-height:24px}.ct{position:relative}.cu{display:inline-block}.cv{margin:0px 0px 35px 28px }.cw{width:24px}.cx{border:0}.cy{height:1px}.cz{background-color:rgba(230, 230, 230, 1)}.da{padding:0 24px 24px}.db{height:64px}.dc path{fill:rgba(168, 168, 168, 1)}.dd{justify-content:center}.de{flex:1}.df{border:none}.dg{background:transparent}.dh{box-shadow:0px 2px 10px rgba(0, 0, 0, 0.15)}.di{z-index:600}.dj{bottom:0}.dk{justify-content:space-around}.dl{height:16px}.dm{background-color:rgba(237, 237, 237, 1)}.ds{min-width:0}.dt{flex:1 1 auto}.du{padding:0 32px}.dv{box-sizing:border-box}.dw{border-left:1px solid rgba(230, 230, 230, 1)}.dx{min-height:100vh}.dy{width:394px}.ea{width:100%}.eb{padding-top:0px}.ec{text-align:center}.ed{color:rgba(242, 242, 242, 1)}.ee{padding:7px 16px 9px}.ef{fill:rgba(242, 242, 242, 1)}.eg{background:rgba(242, 242, 242, 1)}.eh{border-color:rgba(242, 242, 242, 1)}.en:disabled{cursor:inherit !important}.eo:disabled{opacity:0.1}.ep:disabled:hover{background:rgba(25, 25, 25, 1)}.eq:disabled:hover{border-color:rgba(25, 25, 25, 1)}.er{border-radius:99em}.es{border-width:1px}.et{border-style:solid}.eu{text-decoration:none}.fo{margin-left:auto}.fp{margin-right:auto}.fq{max-width:728px}.gb{align-items:flex-start}.gc{margin-right:16px}.gd{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.ge{border-radius:50%}.gf{height:48px}.gg{width:48px}.gh{position:absolute}.gi{color:rgba(41, 41, 41, 1)}.gj{margin-bottom:4px}.gk{flex-direction:row}.gl{padding-left:12px}.gq{font-size:13px}.gr{color:rgba(255, 255, 255, 1)}.gs{padding:0px 8px 1px}.gt{fill:rgba(255, 255, 255, 1)}.gu{background:rgba(26, 137, 23, 1)}.gv{border-color:rgba(26, 137, 23, 1)}.gy:disabled{opacity:0.3}.gz:disabled:hover{background:rgba(26, 137, 23, 1)}.ha:disabled:hover{border-color:rgba(26, 137, 23, 1)}.hb{flex-wrap:wrap}.hc{padding:0 8px}.hg{padding-right:4px}.hh{flex:0 0 auto}.hi{padding:8px 2px}.hk{margin:0 4px 0 28px}.hl{display:inline-flex}.hm{padding-top:24px}.hp{padding-right:12px}.hq{background:rgba(255, 255, 255, 1)}.hr{border:1px solid rgba(230, 230, 230, 1)}.hs{border-radius:4px}.ht{box-shadow:0 1px 4px rgba(230, 230, 230, 1)}.hu{max-height:100vh}.hv{overflow-y:auto}.hw{top:calc(100vh + 100px)}.hx{bottom:calc(100vh + 100px)}.hy{width:10px}.hz{pointer-events:none}.ia{word-break:break-word}.ib{word-wrap:break-word}.ic:after{display:block}.id:after{content:""}.ie:after{clear:both}.if{line-height:1.23}.ig{letter-spacing:0}.ih{font-style:normal}.ii{font-weight:700}.jd{margin-bottom:-0.27em}.je{max-width:1143px}.ji{clear:both}.jk{cursor:zoom-in}.jl{z-index:auto}.jn{max-width:100%}.jo{height:auto}.jp{line-height:1.58}.jq{letter-spacing:-0.004em}.jr{font-family:charter, Georgia, Cambria, "Times New Roman", Times, serif}.km{margin-bottom:-0.46em}.kn{text-decoration:underline}.ko{line-height:1.31}.kp{letter-spacing:-0.022em}.kq{font-weight:600}.ll{margin-bottom:-0.37em}.lv{padding:20px}.lw{overflow-x:auto}.lx{line-height:1.18}.ly{font-family:Menlo, Monaco, "Courier New", Courier, monospace}.lz{margin-top:-0.09em}.ma{margin-bottom:-0.09em}.mb{white-space:pre-wrap}.mc{line-height:28px}.md{letter-spacing:-0.003em}.mh{list-style-type:disc}.mi{margin-left:30px}.mj{padding-left:0px}.mk{font-size:18px}.nk{margin-bottom:-0.31em}.nl{max-width:1923px}.nm{margin-top:16px}.nn{opacity:1}.no{transition:opacity 300ms}.np{bottom:16px}.nq{padding:0 14px 0 16px}.nr{border-radius:20px}.ns{box-shadow:0px 2px 10px 0px rgba(0, 0, 0, 0.1)}.nt{height:40px}.nu{margin-right:5px}.nx{-webkit-user-select:none}.ny{outline:0}.nz{user-select:none}.oa{cursor:pointer}.ob> svg{pointer-events:none}.on{text-align:left}.oq{border-right:1px solid rgba(230, 230, 230, 1)}.or{margin:0 16px}.os{height:12px}.ot{padding:4px 0}.ov{border-top:none}.ow{height:52px}.ox{max-height:52px}.oy{box-sizing:content-box}.oz{position:static}.pa{flex:1 0 auto}.pc{max-width:155px}.pf{margin-left:24px}.pg{margin-top:0px}.ph path{fill:rgba(117, 117, 117, 1)}.pj{margin:0 20px}.pk{background-color:rgba(250, 250, 250, 1)}.pl{padding-bottom:4px}.pm{padding-top:32px}.pn{font-weight:500}.pt{overflow:hidden}.pu{text-overflow:ellipsis}.pv{display:-webkit-box}.pw{-webkit-line-clamp:2}.px{-webkit-box-orient:vertical}.pz{margin-left:8px}.qa{stroke:rgba(242, 242, 242, 1)}.qb{height:36px}.qc{width:36px}.qd{padding-top:25px}.qe{padding-bottom:96px}.qf{padding-left:16px}.qg{padding-top:40px}.qh{padding-right:16px}.qx{background:rgba(25, 25, 25, 1)}.qy{border-color:rgba(25, 25, 25, 1)}.rb{padding-bottom:26px}.rc{font-size:22px}.sm{flex-grow:0}.sn{margin-bottom:20px}.so{margin-right:8px}.sp{margin-top:4px}.sq{max-height:60px}.sr{-webkit-line-clamp:3}.ss{max-height:20px}.st{-webkit-line-clamp:1}.su{word-break:break-all}.sv{padding:40px 0}.sw{width:inherit}.sx{outline:none}.sy{margin-right:20px}.sz{padding:8px 0 11px}.ta{background-color:transparent}.tb::placeholder{color:rgba(117, 117, 117, 1)}.tc{padding:7px 7px 6px 8px}.td{margin-top:40px}.te{height:88px}.tf{width:88px}.tg{margin-top:12px}.th{margin-top:24px}.ti{margin-bottom:40px}.tj{width:auto}.tk{margin-top:32px}.tl{margin-bottom:16px}.tm{padding:24px 0}.tn{margin-right:6px}.to{font-size:11px}.tp{line-height:16px}.bd:hover{cursor:pointer}.be:hover{color:rgba(25, 25, 25, 1)}.bf:hover{fill:rgba(25, 25, 25, 1)}.bu:hover{color:rgba(15, 115, 12, 1)}.bv:hover{fill:rgba(15, 115, 12, 1)}.cm:hover{color:rgba(41, 41, 41, 1)}.cn:hover{fill:rgba(41, 41, 41, 1)}.ei:hover{background:rgba(242, 242, 242, 1)}.ej:hover{border-color:rgba(242, 242, 242, 1)}.ek:hover{cursor:wait}.el:hover{color:rgba(242, 242, 242, 1)}.em:hover{fill:rgba(242, 242, 242, 1)}.gw:hover{background:rgba(15, 115, 12, 1)}.gx:hover{border-color:rgba(15, 115, 12, 1)}.hj:hover path{fill:rgba(8, 8, 8, 1)}.oe:hover{fill:rgba(8, 8, 8, 1)}.om:hover{color:rgba(8, 8, 8, 1)}.ou:hover p{color:rgba(8, 8, 8, 1)}.qz:hover{background:rgba(8, 8, 8, 1)}.ra:hover{border-color:rgba(41, 41, 41, 1)}.jm:focus{transform:scale(1.01)}.od:focus{fill:rgba(8, 8, 8, 1)}.pi:focus path{fill:rgba(8, 8, 8, 1)}.oc:active{border-style:none}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.t{flex-direction:row}.z{width:80px}.ab{min-height:100vh}.ac{flex-shrink:1}.ae{border-right:1px solid rgba(230, 230, 230, 1)}.by{display:block}.bz{text-align:center}.ca{padding:40px 0}.dr{margin-bottom:0}.ez{margin-bottom:40px}.fg{margin:0 32px}.fh{max-width:692px}.fn{padding:0 16px}.fz{margin-bottom:32px}.ga{margin-top:56px}.hf{display:inline-flex}.iz{font-size:32px}.ja{margin-top:0.6em}.jb{line-height:40px}.jc{letter-spacing:-0.016em}.jh{margin-top:40px}.ki{font-size:20px}.kj{margin-top:2em}.kk{line-height:32px}.kl{letter-spacing:-0.003em}.lh{font-size:22px}.li{margin-top:3.14em}.lj{line-height:28px}.lk{letter-spacing:0}.lq{margin-top:0.86em}.mg{margin-top:0.94em}.mp{margin-top:1.14em}.ms{margin-top:2.14em}.mx{margin-top:1.91em}.ni{margin-top:2.37em}.nj{line-height:24px}.ol{margin-top:0px}.op{display:inline-block}.ps{max-height:48px}.qm{margin:0}.qr{white-space:normal}.qw{margin:0 0 0 12px}.rp{width:calc(100% + 32px)}.rq{margin-left:-16px}.rr{margin-right:-16px}.si{padding-left:16px}.sj{padding-right:16px}.sk{flex-basis:50%}.sl{max-width:50%}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ok{margin-top:0px}.oo{display:inline-block}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.oj{margin-top:0px}.pe{display:inline-block}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.bn{display:block}.oh{margin-top:0px}.oi{margin-right:0px}.pd{display:inline-block}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.p{flex-direction:column}.v{width:auto}.ah{display:block}.dn{margin-bottom:56px}.ev{margin-bottom:80px}.fa{margin:0 24px}.fj{padding:0 8px}.fr{margin-bottom:24px}.fs{margin-top:32px}.gm{display:inline-block}.hn{display:flex}.ij{font-size:32px}.ik{margin-top:0.64em}.il{line-height:40px}.im{letter-spacing:-0.016em}.js{font-size:18px}.jt{margin-top:1.56em}.ju{line-height:28px}.jv{letter-spacing:-0.003em}.kr{font-size:20px}.ks{margin-top:1.9em}.kt{line-height:24px}.ku{letter-spacing:0}.lm{margin-top:0.67em}.lr{margin-top:40px}.ml{margin-top:1.34em}.mt{margin-top:1.41em}.my{font-size:16px}.mz{margin-top:2.07em}.na{line-height:20px}.nv{margin-left:0px}.of{margin-top:0px}.og{margin-right:0px}.po{max-height:40px}.qi{margin:0}.qn{white-space:pre-line}.qs{margin:10px 0 0 0}.rd{width:calc(100% + 24px)}.re{margin-left:-12px}.rf{margin-right:-12px}.rs{padding-left:12px}.rt{padding-right:12px}.ru{flex-basis:100%}.rv{max-width:100%}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.s{flex-direction:column}.y{width:auto}.ak{display:block}.dq{margin-bottom:56px}.ey{margin-bottom:40px}.fe{margin:0 32px}.ff{max-width:692px}.fm{padding:0 16px}.fx{margin-bottom:24px}.fy{margin-top:32px}.gp{display:inline-block}.he{display:inline-flex}.iv{font-size:32px}.iw{margin-top:0.6em}.ix{line-height:40px}.iy{letter-spacing:-0.016em}.jg{margin-top:40px}.ke{font-size:20px}.kf{margin-top:2em}.kg{line-height:32px}.kh{letter-spacing:-0.003em}.ld{font-size:22px}.le{margin-top:3.14em}.lf{line-height:28px}.lg{letter-spacing:0}.lp{margin-top:0.86em}.lu{margin-top:56px}.mf{margin-top:0.94em}.mo{margin-top:1.14em}.mr{margin-top:2.14em}.mw{margin-top:1.91em}.ng{margin-top:2.37em}.nh{line-height:24px}.pr{max-height:48px}.ql{margin:0}.qq{white-space:normal}.qv{margin:0 0 0 12px}.rm{width:calc(100% + 32px)}.rn{margin-left:-16px}.ro{margin-right:-16px}.se{padding-left:16px}.sf{padding-right:16px}.sg{flex-basis:50%}.sh{max-width:50%}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.r{flex-direction:column}.x{width:auto}.aj{display:block}.dp{margin-bottom:56px}.ex{margin-bottom:40px}.fc{margin:0 32px}.fd{max-width:692px}.fl{padding:0 16px}.fv{margin-bottom:24px}.fw{margin-top:32px}.go{display:inline-block}.hd{display:inline-flex}.ir{font-size:32px}.is{margin-top:0.6em}.it{line-height:40px}.iu{letter-spacing:-0.016em}.jf{margin-top:40px}.ka{font-size:20px}.kb{margin-top:2em}.kc{line-height:32px}.kd{letter-spacing:-0.003em}.kz{font-size:22px}.la{margin-top:3.14em}.lb{line-height:28px}.lc{letter-spacing:0}.lo{margin-top:0.86em}.lt{margin-top:56px}.me{margin-top:0.94em}.mn{margin-top:1.14em}.mq{margin-top:2.14em}.mv{margin-top:1.91em}.ne{margin-top:2.37em}.nf{line-height:24px}.pq{max-height:48px}.qk{margin:0}.qp{white-space:normal}.qu{margin:0 0 0 12px}.rj{width:calc(100% + 28px)}.rk{margin-left:-14px}.rl{margin-right:-14px}.sa{padding-left:14px}.sb{padding-right:14px}.sc{flex-basis:50%}.sd{max-width:50%}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.q{flex-direction:column}.w{width:auto}.ai{display:block}.do{margin-bottom:56px}.ew{margin-bottom:80px}.fb{margin:0 24px}.fk{padding:0 8px}.ft{margin-bottom:24px}.fu{margin-top:32px}.gn{display:inline-block}.ho{display:flex}.in{font-size:32px}.io{margin-top:0.64em}.ip{line-height:40px}.iq{letter-spacing:-0.016em}.jw{font-size:18px}.jx{margin-top:1.56em}.jy{line-height:28px}.jz{letter-spacing:-0.003em}.kv{font-size:20px}.kw{margin-top:1.9em}.kx{line-height:24px}.ky{letter-spacing:0}.ln{margin-top:0.67em}.ls{margin-top:40px}.mm{margin-top:1.34em}.mu{margin-top:1.41em}.nb{font-size:16px}.nc{margin-top:2.07em}.nd{line-height:20px}.nw{margin-left:0px}.pp{max-height:40px}.qj{margin:0}.qo{white-space:pre-line}.qt{margin:10px 0 0 0}.rg{width:calc(100% + 24px)}.rh{margin-left:-12px}.ri{margin-right:-12px}.rw{padding-left:12px}.rx{padding-right:12px}.ry{flex-basis:50%}.rz{max-width:50%}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="print">.pb{display:none}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (min-width: 7000px)">.af{width:224px}.cb{text-align:left}.cc{padding:40px 24px}.co{display:none}.cq{display:block}.fi{margin:0 auto}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="all and (max-width: 1239.98px)">.dz{width:280px}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.jj{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><style type="text/css" data-fela-rehydration="535" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.py{max-height:none}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="m n l"><div class="o p q r s t u"><div class="v w x y z ab ac ae af"><nav class="ag"><div class="ah ai aj ak d"><div class="al am an o ao u ap aq ar as at c"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Homepage" href="https://medium.com/" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="bj bk"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a><div class="o ao"><div class="eb l ec"><div><a class="bo b bp bq ed ee ef eg eh ei ej ek el em en eo ep eq er ea es et dv cu eu" href="https://medium.com/plans?source=upgrade_membership---nav_full-------------------------------------" rel="noopener follow">Get unlimited access</a></div></div><div class="bl bm bn"><span class="bo b bp bq br"><a class="bs bt aw ax ay az ba bb bc bd bu bv bg bw bx" href="https://rsci.app.link/?$canonical_url=https%3A%2F%2Fmedium.com/p/780a46ace985&amp;~feature=LoOpenInAppButton&amp;~channel=ShowPostUnderUser&amp;~stage=mobileNavBar" rel="noopener follow">Open in app</a></span></div></div></div><div class="an l"></div></div><div class="ag h k j i by"><div class="cd o ce u cf aq cg c"><div class="bz ca cb cc"><a aria-label="Homepage" href="https://medium.com/" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="ch bk"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div><div class="l"><div class="ci l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/" rel="noopener follow"><div class="o ct"><div class="br cj o ck cl cm cn"><div class="l co cp"><div><div class="cu" role="tooltip" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Home"><path d="M4.5 10.75v10.5c0 .14.11.25.25.25h5c.14 0 .25-.11.25-.25v-5.5c0-.14.11-.25.25-.25h3.5c.14 0 .25.11.25.25v5.5c0 .14.11.25.25.25h5c.14 0 .25-.11.25-.25v-10.5M22 9l-9.1-6.83a1.5 1.5 0 0 0-1.8 0L2 9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></div><div class="bm cq cp" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Home"><path d="M4.5 10.75v10.5c0 .14.11.25.25.25h5c.14 0 .25-.11.25-.25v-5.5c0-.14.11-.25.25-.25h3.5c.14 0 .25.11.25.25v5.5c0 .14.11.25.25.25h5c.14 0 .25-.11.25-.25v-10.5M22 9l-9.1-6.83a1.5 1.5 0 0 0-1.8 0L2 9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path></svg></div><div class="bm cq bo b cr cs">Home</div></div></div></a></div><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fme%2Fnotifications&amp;source=--------------------------notifications_sidenav--------------" rel="noopener follow"><div class="ci l"><div class="o ct"><div class="br cj o ck cl cm cn"><div class="l co cp"><div><div class="cu" role="tooltip" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Notifications"><path d="M15 18.5a3 3 0 1 1-6 0" stroke="currentColor" stroke-linecap="round"></path><path d="M5.5 10.53V9a6.5 6.5 0 0 1 13 0v1.53c0 1.42.56 2.78 1.57 3.79l.03.03c.26.26.4.6.4.97v2.93c0 .14-.11.25-.25.25H3.75a.25.25 0 0 1-.25-.25v-2.93c0-.37.14-.71.4-.97l.03-.03c1-1 1.57-2.37 1.57-3.79z" stroke="currentColor" stroke-linejoin="round"></path></svg></div></div></div><div class="bm cq cp" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Notifications"><path d="M15 18.5a3 3 0 1 1-6 0" stroke="currentColor" stroke-linecap="round"></path><path d="M5.5 10.53V9a6.5 6.5 0 0 1 13 0v1.53c0 1.42.56 2.78 1.57 3.79l.03.03c.26.26.4.6.4.97v2.93c0 .14-.11.25-.25.25H3.75a.25.25 0 0 1-.25-.25v-2.93c0-.37.14-.71.4-.97l.03-.03c1-1 1.57-2.37 1.57-3.79z" stroke="currentColor" stroke-linejoin="round"></path></svg></div><div class="bm cq bo b cr cs">Notifications</div></div></div></div></a></span><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fme%2Flists&amp;source=--------------------------lists_sidenav--------------" rel="noopener follow"><div class="ci l"><div class="o ct"><div class="br cj o ck cl cm cn"><div class="l co cp"><div><div class="cu" role="tooltip" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Lists"><path d="M4.5 6.25V21c0 .2.24.32.4.2l5.45-4.09a.25.25 0 0 1 .3 0l5.45 4.09c.16.12.4 0 .4-.2V6.25a.25.25 0 0 0-.25-.25H4.75a.25.25 0 0 0-.25.25z" stroke="currentColor" stroke-linecap="round"></path><path d="M8 6V3.25c0-.14.11-.25.25-.25h11.5c.14 0 .25.11.25.25V16.5" stroke="currentColor" stroke-linecap="round"></path></svg></div></div></div><div class="bm cq cp" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Lists"><path d="M4.5 6.25V21c0 .2.24.32.4.2l5.45-4.09a.25.25 0 0 1 .3 0l5.45 4.09c.16.12.4 0 .4-.2V6.25a.25.25 0 0 0-.25-.25H4.75a.25.25 0 0 0-.25.25z" stroke="currentColor" stroke-linecap="round"></path><path d="M8 6V3.25c0-.14.11-.25.25-.25h11.5c.14 0 .25.11.25.25V16.5" stroke="currentColor" stroke-linecap="round"></path></svg></div><div class="bm cq bo b cr cs">Lists</div></div></div></div></a></span><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fme%2Fstories%2Fdrafts&amp;source=--------------------------stories_sidenav--------------" rel="noopener follow"><div class="ci l"><div class="o ct"><div class="br cj o ck cl cm cn"><div class="l co cp"><div><div class="cu" role="tooltip" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Stories"><path d="M4.75 21.5h14.5c.14 0 .25-.11.25-.25V2.75a.25.25 0 0 0-.25-.25H4.75a.25.25 0 0 0-.25.25v18.5c0 .14.11.25.25.25z" stroke="currentColor"></path><path d="M8 8.5h8M8 15.5h5M8 12h8" stroke="currentColor" stroke-linecap="round"></path></svg></div></div></div><div class="bm cq cp" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Stories"><path d="M4.75 21.5h14.5c.14 0 .25-.11.25-.25V2.75a.25.25 0 0 0-.25-.25H4.75a.25.25 0 0 0-.25.25v18.5c0 .14.11.25.25.25z" stroke="currentColor"></path><path d="M8 8.5h8M8 15.5h5M8 12h8" stroke="currentColor" stroke-linecap="round"></path></svg></div><div class="bm cq bo b cr cs">Stories</div></div></div></div></a></span><div class="cv cw l"><hr class="cx cy cz bc" aria-hidden="true"/></div><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=--------------------------new_post_sidenav--------------" rel="noopener follow"><div class="ci l"><div class="o ct"><div class="br cj o ck cl cm cn"><div class="l co cp"><div><div class="cu" role="tooltip" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg></div></div></div><div class="bm cq cp" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg></div><div class="bm cq bo b cr cs">Write</div></div></div></div></a></span></div><div class="da db o ao"></div></div></div><div class="ah ai aj ak d"><div class="l ap ar dj as at c"><div class="dh an ct di"><div class="ag o ao dk"><div class="dl cw l dm"></div><div class="dl cw l dm"></div><div class="dl cw l dm"></div></div></div></div></div></nav></div><main class="dn do dp dq dr ds l dt"><div class="l"><div class="ev ew ex ey ez l"><div class="o dd"><div class="ds ea fa fb fc fd fe ff fg fh fi"><article><div class="l"><div class="fj fk fl fm fn fo fp ea fq dv l"></div><div class="l"><header class="pw-post-byline-header fr fs ft fu fv fw fx fy fz ga l"><div class="o gb u"><div class="o"><div class="gc l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" rel="noopener follow" href="/?source=post_page-----780a46ace985-----------------------------------"><div class="l ct"><img alt="Kamran Kowsari" class="l dv ge gf gg" src="https://miro.medium.com/fit/c/96/96/0*WDW28d_jMNxFwCoA.jpg" width="48" height="48"/><div class="gd ge l gf gg gh aq"></div></div></a></div><div class="l"><div class="pw-author bo b cr cs gi"><div class="gj o gk"><div><div class="cu" role="tooltip" aria-hidden="false"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" rel="noopener follow" href="/?source=post_page-----780a46ace985-----------------------------------">Kamran Kowsari</a></div></div><div class="gl gm gn go gp d"><span><button class="bo b gq bq gr gs gt gu gv gw gx bd en gy gz ha er es et dv cu eu">Follow</button></span></div></div></div><div class="o ao hb"><p class="pw-published-date bo b bp bq br"><span>May 22, 2019</span></p><div class="hc cu" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bo b bp bq br">·</span></span></div><div class="pw-reading-time bo b bp bq br">11 min read</div></div></div></div><div class="o ao"><div class="h k hd he hf"><div class="hg l hh"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on twitter"><span class="cu hi dc hj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hg l hh"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on facebook"><span class="cu hi dc hj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hg l hh"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on linkedin"><span class="cu hi dc hj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l hh"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="cu hi dc hj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hk o ao"></div></div><div class="bl hl"><div><div class="cu" role="tooltip" aria-hidden="false"></div></div></div></div></div><div class="hm hn ho j i d"><div class="hm hn ho j i d"><div class="gc l"></div><div class="hp l hh"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on twitter"><span class="cu hi dc hj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hp l hh"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on facebook"><span class="cu hi dc hj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hp l hh"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on linkedin"><span class="cu hi dc hj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l hh"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="cu hi dc hj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8"></path></svg></span></button></div></div></div></div></div></header><span class="l"></span><section><div><div class="gh as hw hx hy hz"></div><div class="ia ib ic id ie"><div class=""><h1 id="be50" class="pw-post-title if ig ih bo ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd gi">Ensemble Deep Learning</h1></div><figure class="fs fu jf jg jh ji fo fp paragraph-image"><div role="button" tabindex="0" class="jj jk ct jl ea jm"><div class="fo fp je"><img alt="" class="ea jn jo" src="https://miro.medium.com/max/1400/0*jRwJaYk_Wvc3jGKw" width="700" height="395" role="presentation"/></div></div></figure><p id="b5ce" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">Referenced paper : <a class="au kn" href="https://arxiv.org/abs/1805.01890" rel="noopener ugc nofollow" target="_blank">RMDL: Random Multimodel Deep Learning for Classification</a></p><p id="a00e" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">Referenced paper: <a class="au kn" href="https://arxiv.org/abs/1808.08121" rel="noopener ugc nofollow" target="_blank">An Improvement of Data Classification Using Random Multimodel Deep Learning (RMDL)</a></p><h1 id="f4f8" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Random Multimodel Deep Learning (RMDL):</h1><p id="6a99" class="pw-post-body-paragraph jp jq ih jr b js lm ju jv jw ln jy jz ka lo kc kd ke lp kg kh ki lq kk kl km ia gi">A new ensemble, deep learning approach for classification. Deep learning models have achieved state-of-the-art results across many domains. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. RDML can accept as input a variety of data to include text, video, images, and symbolic.</p><p id="766b" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">Random Multimodel Deep Learning (RDML) architecture for classification. RMDL includes 3 Random models, oneDNN classifier at left, one Deep CNN classifier at middle, and one Deep RNN classifier at right (each unit could be LSTMor GRU).</p><h1 id="c212" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Installation</h1><p id="1b96" class="pw-post-body-paragraph jp jq ih jr b js lm ju jv jw ln jy jz ka lo kc kd ke lp kg kh ki lq kk kl km ia gi">There are pip and git for RMDL installation:</p><h1 id="457b" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Using pip</h1><pre class="lr ls lt lu ga lv eg lw"><span id="1719" class="gi lx kp ih ly b cr lz ma l mb">pip install RMDL</span></pre><h1 id="e28b" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Using git</h1><pre class="lr ls lt lu ga lv eg lw"><span id="05b6" class="gi lx kp ih ly b cr lz ma l mb">git clone --recursive <a class="au kn" href="https://github.com/kk7nc/RMDL.git" rel="noopener ugc nofollow" target="_blank">https://github.com/kk7nc/RMDL.git</a></span></pre><p id="3782" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">The primary requirements for this package are Python 3 with Tensorflow. The requirements.txt file contains a listing of the required Python packages; to install all requirements, run the following:</p><pre class="lr ls lt lu ga lv eg lw"><span id="f4fa" class="gi lx kp ih ly b cr lz ma l mb">pip -r install requirements.txt</span></pre><p id="f250" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">Or</p><pre class="lr ls lt lu ga lv eg lw"><span id="ef2b" class="gi lx kp ih ly b cr lz ma l mb">pip3  install -r requirements.txt</span></pre><p id="f704" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">Or:</p><pre class="lr ls lt lu ga lv eg lw"><span id="08b0" class="gi lx kp ih ly b cr lz ma l mb">conda install --file requirements.txt</span></pre><h1 id="bdfe" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Documentation:</h1><p id="298b" class="pw-post-body-paragraph jp jq ih jr b js lm ju jv jw ln jy jz ka lo kc kd ke lp kg kh ki lq kk kl km ia gi">The exponential growth in the number of complex datasets every year requires more enhancement in machine learning methods to provide robust and accurate data classification. Lately, deep learning approaches have been achieved surpassing results in comparison to previous machine learning algorithms on tasks such as image classification, natural language processing, face recognition, and etc. The success of these deep learning algorithms relies on their capacity to model complex and non-linear relationships within data. However, finding a suitable structure for these models has been a challenge for researchers. This paper introduces Random Multimodel Deep Learning (RMDL): a new ensemble, deep learning approach for classification. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. In short, RMDL trains multiple models of Deep Neural Network (DNN), Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) in parallel and combines their results to produce a better result of any of those models individually. To create these models, each deep learning model has been constructed in a random fashion regarding the number of layers and nodes in their neural network structure. The resulting RDML model can be used for various domains such as text, video, images, and symbolic. In this Project, we describe RMDL model in depth and show the results for image and text classification as well as face recognition. For image classification, we compared our model with some of the available baselines using MNIST and CIFAR-10 datasets. Similarly, we used four datasets namely, WOS, Reuters, IMDB, and 20newsgroup and compared our results with available baselines. Web of Science (WOS) has been collected by authors and consists of three sets~(small, medium and large set). Lastly, we used ORL dataset to compare the performance of our approach with other face recognition methods. These test results show that RDML model consistently outperforms standard methods over a broad range of data types and classification problems.</p><h1 id="2905" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Datasets for RMDL:</h1><h1 id="c066" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Text Datasets:</h1><ul class=""><li id="0760" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi"><a class="au kn" href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank">IMDB Dataset</a></li><li id="7473" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">This dataset contains 50,000 documents with 2 categories.</li><li id="11e0" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi"><a class="au kn" href="https://keras.io/datasets/" rel="noopener ugc nofollow" target="_blank">Reters-21578 Dataset</a></li><li id="6211" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">This dataset contains 21,578 documents with 90 categories.</li><li id="c1ef" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi"><a class="au kn" href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups" rel="noopener ugc nofollow" target="_blank">20Newsgroups Dataset</a></li><li id="3914" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">This dataset contains 20,000 documents with 20 categories.</li><li id="be3d" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">Web of Science Dataset (DOI: <a class="au kn" href="http://dx.doi.org/10.17632/9rw3vkcfy4.2" rel="noopener ugc nofollow" target="_blank">10.17632/9rw3vkcfy4.2</a>)</li><li id="5878" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">Web of Science Dataset <a class="au kn" href="http://dx.doi.org/10.17632/9rw3vkcfy4.2" rel="noopener ugc nofollow" target="_blank">WOS-11967</a></li><li id="0b53" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">This dataset contains 11,967 documents with 35 categories which include 7 parents categories.</li><li id="43e3" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">Web of Science Dataset <a class="au kn" href="http://dx.doi.org/10.17632/9rw3vkcfy4.2" rel="noopener ugc nofollow" target="_blank">WOS-46985</a></li><li id="6752" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">This dataset contains 46,985 documents with 134 categories which include 7 parents categories.</li><li id="cc4c" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">Web of Science Dataset <a class="au kn" href="http://dx.doi.org/10.17632/9rw3vkcfy4.2" rel="noopener ugc nofollow" target="_blank">WOS-5736</a></li><li id="dd45" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">This dataset contains 5,736 documents with 11 categories which include 3 parents categories.</li></ul><h1 id="b4c6" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Image datasets:</h1><ul class=""><li id="3ef3" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi"><a class="au kn" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank">MNIST Dataset</a></li><li id="9a3c" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">The MNIST database contains 60,000 training images and 10,000 testing images.</li><li id="4bf5" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi"><a class="au kn" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">CIFAR-10 Dataset</a></li><li id="f42c" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.</li></ul><h1 id="b97b" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Face Recognition</h1><p id="4359" class="pw-post-body-paragraph jp jq ih jr b js lm ju jv jw ln jy jz ka lo kc kd ke lp kg kh ki lq kk kl km ia gi"><a class="au kn" href="http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html" rel="noopener ugc nofollow" target="_blank">The Database of Faces (The Olivetti Faces Dataset)</a></p><ul class=""><li id="326d" class="mc md ih jr b js jt jw jx ka mq ke mr ki ms km mh mi mj mk gi">The The Database of Faces dataset consists of 400 92x112 colour images and grayscale in 40 person</li></ul><h1 id="46f7" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Requirements for RMDL :</h1><h1 id="5d7c" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">General:</h1><ul class=""><li id="ab57" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">Python 3.5 or later see <a class="au kn" href="https://www.python.org/" rel="noopener ugc nofollow" target="_blank">Instruction Documents</a></li><li id="76e8" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">TensorFlow see <a class="au kn" href="https://www.tensorflow.org/install/install_linux" rel="noopener ugc nofollow" target="_blank">Instruction Documents</a>.</li><li id="fd16" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">scikit-learn see <a class="au kn" href="http://scikit-learn.org/stable/install.html" rel="noopener ugc nofollow" target="_blank">Instruction Documents</a></li><li id="8f71" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">Keras see <a class="au kn" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank">Instruction Documents</a></li><li id="5d39" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">scipy see <a class="au kn" href="https://www.scipy.org/install.html" rel="noopener ugc nofollow" target="_blank">Instruction Documents</a></li></ul><h1 id="0dbe" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">GPU (if you want to run on GPU):</h1><ul class=""><li id="2800" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">CUDA® Toolkit 8.0. For details, see <a class="au kn" href="https://developer.nvidia.com/cuda-toolkit" rel="noopener ugc nofollow" target="_blank">NVIDIA’s documentation</a>.</li><li id="e430" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">The <a class="au kn" href="http://www.nvidia.com/Download/index.aspx" rel="noopener ugc nofollow" target="_blank">NVIDIA drivers associated with CUDA Toolkit 8.0</a>.</li><li id="b71d" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">cuDNN v6. For details, see <a class="au kn" href="https://developer.nvidia.com/cudnn" rel="noopener ugc nofollow" target="_blank">NVIDIA’s documentation</a>.</li><li id="ec46" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">GPU card with CUDA Compute Capability 3.0 or higher.</li><li id="164b" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">The libcupti-dev library,</li></ul><h1 id="f706" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Text and Document Classification</h1><ul class=""><li id="1b5f" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">Download GloVe: Global Vectors for Word Representation <a class="au kn" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">Instruction Documents</a></li><li id="3102" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">Set data directory into <a class="au kn" href="https://github.com/kk7nc/RMDL/blob/master/src/Global.py" rel="noopener ugc nofollow" target="_blank">Global.py</a></li><li id="d3e8" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">if you are not setting GloVe directory, GloVe will be downloaded</li></ul><h1 id="284b" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Parameters:</h1><h1 id="c306" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Text_Classification</h1><pre class="lr ls lt lu ga lv eg lw"><span id="daa5" class="gi lx kp ih ly b cr lz ma l mb">from RMDL import RMDL_Text</span><span id="f548" class="gi lx kp ih ly b cr mt mu mv mw mx ma l mb">Text_Classification(x_train, y_train, x_test,  y_test, batch_size=128,<br/>                 EMBEDDING_DIM=50,MAX_SEQUENCE_LENGTH = 500, MAX_NB_WORDS = 75000,<br/>                 GloVe_dir=&quot;&quot;, GloVe_file = &quot;glove.6B.50d.txt&quot;,<br/>                 sparse_categorical=True, random_deep=[3, 3, 3], epochs=[500, 500, 500],  plot=True,<br/>                 min_hidden_layer_dnn=1, max_hidden_layer_dnn=8, min_nodes_dnn=128, max_nodes_dnn=1024,<br/>                 min_hidden_layer_rnn=1, max_hidden_layer_rnn=5, min_nodes_rnn=32,  max_nodes_rnn=128,<br/>                 min_hidden_layer_cnn=3, max_hidden_layer_cnn=10, min_nodes_cnn=128, max_nodes_cnn=512,<br/>                 random_state=42, random_optimizor=True, dropout=0.05):</span></pre><h2 id="e89e" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Input</h2><ul class=""><li id="a59f" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">x_train</li><li id="3d1c" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">y_train</li><li id="f903" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">x_test</li><li id="4122" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">y_test</li></ul><h2 id="9373" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">batch_size</h2><ul class=""><li id="467c" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">batch_size: Integer. The number of samples per gradient update. If unspecified, it will default to 128.</li></ul><h2 id="04ab" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">EMBEDDING_DIM</h2><ul class=""><li id="efd7" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">batch_size: Integer. The shape of word embedding (this number should be same with GloVe or other pre-trained embedding techniques that be used), it will default to 50 that used with the pain of glove.6B.50d.txt file.</li></ul><h2 id="033f" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">MAX_SEQUENCE_LENGTH</h2><ul class=""><li id="8169" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">MAX_SEQUENCE_LENGTH: Integer. The maximum length of sequence or document in datasets, it will default to 500.</li></ul><h2 id="e63c" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">MAX_NB_WORDS</h2><ul class=""><li id="625b" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">MAX_NB_WORDS: Integer. The maximum number of unique words in datasets, it will default to 75000.</li></ul><h2 id="86fe" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">GloVe_dir</h2><ul class=""><li id="1551" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">GloVe_dir: String. Address of GloVe or any pre-trained directory, it will default to null which glove.6B.zip will be download.</li></ul><h2 id="b465" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">GloVe_file</h2><ul class=""><li id="e711" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">GloVe_dir: String. Which version of GloVe or pre-trained word emending will be used, it will default to glove.6B.50d.txt.</li><li id="f6be" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">NOTE: if you use another version of GloVe EMBEDDING_DIM must be the same dimensions.</li></ul><h2 id="91b2" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">sparse_categorical</h2><ul class=""><li id="6b84" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">sparse_categorical: bool. When target’s dataset is (n,1) should be True, it will default to True.</li></ul><h2 id="b4bf" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">random_deep</h2><ul class=""><li id="074c" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">random_deep: Integer [3]. Number of ensembled model used in RMDL random_deep[0] is number of DNN, random_deep[1] is number of RNN, random_deep[0] is number of CNN, it will default to [3, 3, 3].</li></ul><h2 id="b7d1" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">epochs</h2><ul class=""><li id="95d3" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">epochs: Integer [3]. Number of epochs in each ensembled model used in RMDL epochs[0] is number of epochs used in DNN, epochs[1] is number of epochs used in RNN, epochs[0] is number of epochs used in CNN, it will default to [500, 500, 500].</li></ul><h2 id="4dab" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">plot</h2><ul class=""><li id="2c0b" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">plot: bool. True: shows confusion matrix and accuracy and loss</li></ul><h2 id="f354" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_hidden_layer_dnn</h2><ul class=""><li id="555b" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_hidden_layer_dnn: Integer. Lower Bounds of hidden layers of DNN used in RMDL, it will default to 1.</li></ul><h2 id="33c8" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_hidden_layer_dnn</h2><ul class=""><li id="2d96" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">max_hidden_layer_dnn: Integer. Upper bounds of hidden layers of DNN used in RMDL, it will default to 8.</li></ul><h2 id="e882" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_nodes_dnn</h2><ul class=""><li id="500a" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_nodes_dnn: Integer. Lower bounds of nodes in each layer of DNN used in RMDL, it will default to 128.</li></ul><h2 id="0660" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_nodes_dnn</h2><ul class=""><li id="c176" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">max_nodes_dnn: Integer. Upper bounds of nodes in each layer of DNN used in RMDL, it will default to 1024.</li></ul><h2 id="b96b" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_hidden_layer_rnn</h2><ul class=""><li id="e163" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_hidden_layer_rnn: Integer. Lower Bounds of hidden layers of RNN used in RMDL, it will default to 1.</li></ul><h2 id="8442" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_hidden_layer_rnn</h2><ul class=""><li id="1a40" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">man_hidden_layer_rnn: Integer. Upper Bounds of hidden layers of RNN used in RMDL, it will default to 5.</li></ul><h2 id="a017" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_nodes_rnn</h2><ul class=""><li id="401e" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_nodes_rnn: Integer. Lower bounds of nodes (LSTM or GRU) in each layer of RNN used in RMDL, it will default to 32.</li></ul><h2 id="531b" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_nodes_rnn</h2><ul class=""><li id="edd0" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">max_nodes_rnn: Integer. Upper bounds of nodes (LSTM or GRU) in each layer of RNN used in RMDL, it will default to 128.</li></ul><h2 id="d3af" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_hidden_layer_cnn</h2><ul class=""><li id="d49a" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_hidden_layer_cnn: Integer. Lower Bounds of hidden layers of CNN used in RMDL, it will default to 3.</li></ul><h2 id="837d" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_hidden_layer_cnn</h2><ul class=""><li id="3ad4" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">max_hidden_layer_cnn: Integer. Upper Bounds of hidden layers of CNN used in RMDL, it will default to 10.</li></ul><h2 id="186f" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_nodes_cnn</h2><ul class=""><li id="5b29" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_nodes_cnn: Integer. Lower bounds of nodes (2D convolution layer) in each layer of CNN used in RMDL, it will default to 128.</li></ul><h2 id="1d62" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_nodes_cnn</h2><ul class=""><li id="4102" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_nodes_cnn: Integer. Upper bounds of nodes (2D convolution layer) in each layer of CNN used in RMDL, it will default to 512.</li></ul><h2 id="c91a" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">random_state</h2><ul class=""><li id="d085" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">random_state : Integer, RandomState instance or None, optional (default=None)</li><li id="0ed0" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">If Integer, random_state is the seed used by the random number generator;</li></ul><h2 id="cda2" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">random_optimizor</h2><ul class=""><li id="e4f3" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">random_optimizor : bool, If False, all models use adam optimizer. If True, all models use random optimizers. it will default to True</li></ul><h2 id="570d" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">dropout</h2><ul class=""><li id="1bbc" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.</li></ul><h1 id="8704" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Image_Classification</h1><pre class="lr ls lt lu ga lv eg lw"><span id="276a" class="gi lx kp ih ly b cr lz ma l mb">from RMDL import RMDL_Image</span><span id="7acb" class="gi lx kp ih ly b cr mt mu mv mw mx ma l mb">Image_Classification(x_train, y_train, x_test, y_test, shape, batch_size=128,<br/>                         sparse_categorical=True, random_deep=[3, 3, 3], epochs=[500, 500, 500], plot=True,<br/>                         min_hidden_layer_dnn=1, max_hidden_layer_dnn=8, min_nodes_dnn=128, max_nodes_dnn=1024,<br/>                         min_hidden_layer_rnn=1, max_hidden_layer_rnn=5, min_nodes_rnn=32, max_nodes_rnn=128,<br/>                         min_hidden_layer_cnn=3, max_hidden_layer_cnn=10, min_nodes_cnn=128, max_nodes_cnn=512,<br/>                         random_state=42, random_optimizor=True, dropout=0.05)</span></pre><h2 id="807c" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Input</h2><ul class=""><li id="f4eb" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">x_train</li><li id="f2b1" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">y_train</li><li id="a50c" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">x_test</li><li id="4df7" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">y_test</li></ul><h2 id="5eed" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">shape</h2><ul class=""><li id="a3bb" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">shape: np.shape . shape of image. The most common situation would be a 2D input with shape (batch_size, input_dim).</li></ul><h2 id="465a" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">batch_size</h2><ul class=""><li id="3dcc" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">batch_size: Integer. Number of samples per gradient update. If unspecified, it will default to 128.</li></ul><h2 id="8f40" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">sparse_categorical</h2><ul class=""><li id="4189" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">sparse_categorical: bool. When target’s dataset is (n,1) should be True, it will default to True.</li></ul><h2 id="303b" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">random_deep</h2><ul class=""><li id="15a3" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">random_deep: Integer [3]. Number of ensembled model used in RMDL random_deep[0] is number of DNN, random_deep[1] is number of RNN, random_deep[0] is number of CNN, it will default to [3, 3, 3].</li></ul><h2 id="71bf" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">epochs</h2><ul class=""><li id="4bda" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">epochs: Integer [3]. Number of epochs in each ensembled model used in RMDL epochs[0] is number of epochs used in DNN, epochs[1] is number of epochs used in RNN, epochs[0] is number of epochs used in CNN, it will default to [500, 500, 500].</li></ul><h2 id="9c79" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">plot</h2><ul class=""><li id="df9f" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">plot: bool. True: shows confusion matrix and accuracy and loss</li></ul><h2 id="e51c" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_hidden_layer_dnn</h2><ul class=""><li id="96d3" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_hidden_layer_dnn: Integer. Lower Bounds of hidden layers of DNN used in RMDL, it will default to 1.</li></ul><h2 id="dea1" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_hidden_layer_dnn</h2><ul class=""><li id="42ab" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">max_hidden_layer_dnn: Integer. Upper bounds of hidden layers of DNN used in RMDL, it will default to 8.</li></ul><h2 id="0c2a" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_nodes_dnn</h2><ul class=""><li id="9571" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_nodes_dnn: Integer. Lower bounds of nodes in each layer of DNN used in RMDL, it will default to 128.</li></ul><h2 id="77ce" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_nodes_dnn</h2><ul class=""><li id="c032" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">max_nodes_dnn: Integer. Upper bounds of nodes in each layer of DNN used in RMDL, it will default to 1024.</li></ul><h2 id="30dc" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_nodes_rnn</h2><ul class=""><li id="890a" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_nodes_rnn: Integer. Lower bounds of nodes (LSTM or GRU) in each layer of RNN used in RMDL, it will default to 32.</li></ul><h2 id="f762" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_nodes_rnn</h2><ul class=""><li id="e0f0" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">maz_nodes_rnn: Integer. Upper bounds of nodes (LSTM or GRU) in each layer of RNN used in RMDL, it will default to 128.</li></ul><h2 id="0339" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_hidden_layer_cnn</h2><ul class=""><li id="18ea" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_hidden_layer_cnn: Integer. Lower Bounds of hidden layers of CNN used in RMDL, it will default to 3.</li></ul><h2 id="2bb3" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_hidden_layer_cnn</h2><ul class=""><li id="c9e2" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">max_hidden_layer_cnn: Integer. Upper Bounds of hidden layers of CNN used in RMDL, it will default to 10.</li></ul><h2 id="cefd" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">min_nodes_cnn</h2><ul class=""><li id="d156" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_nodes_cnn: Integer. Lower bounds of nodes (2D convolution layer) in each layer of CNN used in RMDL, it will default to 128.</li></ul><h2 id="6bba" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">max_nodes_cnn</h2><ul class=""><li id="612b" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">min_nodes_cnn: Integer. Upper bounds of nodes (2D convolution layer) in each layer of CNN used in RMDL, it will default to 512.</li></ul><h2 id="30fb" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">random_state</h2><ul class=""><li id="2fca" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">random_state : Integer, RandomState instance or None, optional (default=None)</li><li id="dc7f" class="mc md ih jr b js ml jw mm ka mn ke mo ki mp km mh mi mj mk gi">If Integer, random_state is the seed used by the random number generator;</li></ul><h2 id="f53b" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">random_optimizor</h2><ul class=""><li id="3a9a" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">random_optimizor : bool, If False, all models use adam optimizer. If True, all models use random optimizers. it will default to True</li></ul><h2 id="f761" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">dropout</h2><ul class=""><li id="dfcc" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">dropout: Float between 0 and 1. A fraction of the units to drop for the linear transformation of the inputs.</li></ul><h1 id="36f6" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Example</h1><h1 id="18fe" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">MNIST</h1><ul class=""><li id="1dcf" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">The MNIST database contains 60,000 training images and 10,000 testing images.</li></ul><h2 id="77f0" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Import Packages</h2><pre class="lr ls lt lu ga lv eg lw"><span id="75c7" class="gi lx kp ih ly b cr lz ma l mb">from keras.datasets import mnist<br/>import numpy as np<br/>from RMDL import RMDL_Image as RMDL</span></pre><h2 id="8cdb" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Load Data</h2><pre class="lr ls lt lu ga lv eg lw"><span id="00bf" class="gi lx kp ih ly b cr lz ma l mb">(X_train, y_train), (X_test, y_test) = mnist.load_data()<br/>X_train_D = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(&#x27;float32&#x27;)<br/>X_test_D = X_test.reshape(X_test.shape[0], 28, 28, 1).astype(&#x27;float32&#x27;)<br/>X_train = X_train_D / 255.0<br/>X_test = X_test_D / 255.0<br/>number_of_classes = np.unique(y_train).shape[0]<br/>shape = (28, 28, 1)</span></pre><h2 id="016f" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Using RMDL</h2><pre class="lr ls lt lu ga lv eg lw"><span id="e05a" class="gi lx kp ih ly b cr lz ma l mb">batch_size = 128<br/>sparse_categorical = 0<br/>n_epochs = [100, 100, 100]  ## DNN-RNN-CNN<br/>Random_Deep = [3, 3, 3]  ## DNN-RNN-CNN</span><span id="9993" class="gi lx kp ih ly b cr mt mu mv mw mx ma l mb">RMDL.Image_Classification(X_train, y_train, X_test, y_test,shape,<br/>                     batch_size=batch_size,<br/>                     sparse_categorical=True,<br/>                     random_deep=Random_Deep,<br/>                     epochs=n_epochs)</span></pre><h1 id="9371" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">IMDB</h1><ul class=""><li id="3a8e" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">This dataset contains 50,000 documents with 2 categories.</li></ul><h2 id="0ef8" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Import Packages</h2><pre class="lr ls lt lu ga lv eg lw"><span id="38f2" class="gi lx kp ih ly b cr lz ma l mb">import sys<br/>import os<br/>from RMDL import text_feature_extraction as txt<br/>from keras.datasets import imdb<br/>import numpy as np<br/>from RMDL import RMDL_Text as RMDL</span></pre><h2 id="0131" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Load Data</h2><pre class="lr ls lt lu ga lv eg lw"><span id="756a" class="gi lx kp ih ly b cr lz ma l mb">print(&quot;Load IMDB dataset....&quot;)<br/>(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=MAX_NB_WORDS)<br/>print(len(X_train))<br/>print(y_test)<br/>word_index = imdb.get_word_index()<br/>index_word = {v: k for k, v in word_index.items()}<br/>X_train = [txt.text_cleaner(&#x27; &#x27;.join(index_word.get(w) for w in x)) for x in X_train]<br/>X_test = [txt.text_cleaner(&#x27; &#x27;.join(index_word.get(w) for w in x)) for x in X_test]<br/>X_train = np.array(X_train)<br/>X_train = np.array(X_train).ravel()<br/>print(X_train.shape)<br/>X_test = np.array(X_test)<br/>X_test = np.array(X_test).ravel()</span></pre><h2 id="3957" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Using RMDL</h2><pre class="lr ls lt lu ga lv eg lw"><span id="ffc8" class="gi lx kp ih ly b cr lz ma l mb">batch_size = 100<br/>sparse_categorical = 0<br/>n_epochs = [100, 100, 100]  ## DNN--RNN-CNN<br/>Random_Deep = [3, 3, 3]  ## DNN--RNN-CNN</span><span id="bed7" class="gi lx kp ih ly b cr mt mu mv mw mx ma l mb">RMDL.Text_Classification(X_train, y_train, X_test, y_test,<br/>                     batch_size=batch_size,<br/>                     sparse_categorical=sparse_categorical,<br/>                     random_deep=Random_Deep,<br/>                     epochs=n_epochs)</span></pre><h1 id="e282" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Web Of Science</h1><p id="f76f" class="pw-post-body-paragraph jp jq ih jr b js lm ju jv jw ln jy jz ka lo kc kd ke lp kg kh ki lq kk kl km ia gi"><strong class="jr ii">Linke of the dataset:</strong></p><p id="cca7" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">Web of Science Dataset <a class="au kn" href="http://dx.doi.org/10.17632/9rw3vkcfy4.2" rel="noopener ugc nofollow" target="_blank">WOS-11967</a></p><ul class=""><li id="3d58" class="mc md ih jr b js jt jw jx ka mq ke mr ki ms km mh mi mj mk gi">This dataset contains 11,967 documents with 35 categories which include 7 parents categories.</li></ul><p id="8bfc" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">Web of Science Dataset <a class="au kn" href="http://dx.doi.org/10.17632/9rw3vkcfy4.2" rel="noopener ugc nofollow" target="_blank">WOS-46985</a></p><ul class=""><li id="74f1" class="mc md ih jr b js jt jw jx ka mq ke mr ki ms km mh mi mj mk gi">This dataset contains 46,985 documents with 134 categories which include 7 parents categories.</li></ul><p id="3d55" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">Web of Science Dataset <a class="au kn" href="http://dx.doi.org/10.17632/9rw3vkcfy4.2" rel="noopener ugc nofollow" target="_blank">WOS-5736</a></p><ul class=""><li id="ebdc" class="mc md ih jr b js jt jw jx ka mq ke mr ki ms km mh mi mj mk gi">This dataset contains 5,736 documents with 11 categories which include 3 parents categories.</li></ul><h2 id="2243" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Import Packages</h2><pre class="lr ls lt lu ga lv eg lw"><span id="faab" class="gi lx kp ih ly b cr lz ma l mb">from RMDL import text_feature_extraction as txt<br/>from sklearn.model_selection import train_test_split<br/>from RMDL.Download import Download_WOS as WOS<br/>import numpy as np<br/>from RMDL import RMDL_Text as RMDL</span></pre><h2 id="af93" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Load Data</h2><pre class="lr ls lt lu ga lv eg lw"><span id="1bd9" class="gi lx kp ih ly b cr lz ma l mb">path_WOS = WOS.download_and_extract()<br/>fname = os.path.join(path_WOS,&quot;WebOfScience/WOS11967/X.txt&quot;)<br/>fnamek = os.path.join(path_WOS,&quot;WebOfScience/WOS11967/Y.txt&quot;)<br/>with open(fname, encoding=&quot;utf-8&quot;) as f:<br/>    content = f.readlines()<br/>    content = [txt.text_cleaner(x) for x in content]<br/>with open(fnamek) as fk:<br/>    contentk = fk.readlines()<br/>contentk = [x.strip() for x in contentk]<br/>Label = np.matrix(contentk, dtype=int)<br/>Label = np.transpose(Label)<br/>np.random.seed(7)<br/>print(Label.shape)<br/>X_train, X_test, y_train, y_test = train_test_split(content, Label, test_size=0.2, random_state=4)</span></pre><h2 id="fb06" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Using RMDL</h2><pre class="lr ls lt lu ga lv eg lw"><span id="3229" class="gi lx kp ih ly b cr lz ma l mb">batch_size = 100<br/>sparse_categorical = 0<br/>n_epochs = [5000, 500, 500]  ## DNN--RNN-CNN<br/>Random_Deep = [3, 3, 3]  ## DNN--RNN-CNN</span><span id="8af4" class="gi lx kp ih ly b cr mt mu mv mw mx ma l mb">RMDL.Text_Classification(X_train, y_train, X_test, y_test,<br/>                     batch_size=batch_size,<br/>                     sparse_categorical=True,<br/>                     random_deep=Random_Deep,<br/>                     epochs=n_epochs,no_of_classes=12)</span></pre><h1 id="4629" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Reuters-21578</h1><ul class=""><li id="4aa6" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">This dataset contains 21,578 documents with 90 categories.</li></ul><h2 id="b407" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Import Packages</h2><pre class="lr ls lt lu ga lv eg lw"><span id="1635" class="gi lx kp ih ly b cr lz ma l mb">import sys<br/>import os<br/>import nltk<br/>nltk.download(&quot;reuters&quot;)<br/>from nltk.corpus import reuters<br/>from sklearn.preprocessing import MultiLabelBinarizer<br/>import numpy as np<br/>from RMDL import RMDL_Text as RMDL</span></pre><h2 id="3eb1" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Load Data</h2><pre class="lr ls lt lu ga lv eg lw"><span id="61fb" class="gi lx kp ih ly b cr lz ma l mb">documents = reuters.fileids()</span><span id="3752" class="gi lx kp ih ly b cr mt mu mv mw mx ma l mb">train_docs_id = list(filter(lambda doc: doc.startswith(&quot;train&quot;),<br/>                          documents))<br/>test_docs_id = list(filter(lambda doc: doc.startswith(&quot;test&quot;),<br/>                         documents))<br/>X_train = [(reuters.raw(doc_id)) for doc_id in train_docs_id]<br/>X_test = [(reuters.raw(doc_id)) for doc_id in test_docs_id]<br/>mlb = MultiLabelBinarizer()<br/>y_train = mlb.fit_transform([reuters.categories(doc_id)<br/>                           for doc_id in train_docs_id])<br/>y_test = mlb.transform([reuters.categories(doc_id)<br/>                      for doc_id in test_docs_id])<br/>y_train = np.argmax(y_train, axis=1)<br/>y_test = np.argmax(y_test, axis=1)</span></pre><h2 id="2523" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Using RMDL</h2><pre class="lr ls lt lu ga lv eg lw"><span id="3685" class="gi lx kp ih ly b cr lz ma l mb">batch_size = 100<br/>sparse_categorical = 0<br/>n_epochs = [20, 500, 50]  ## DNN--RNN-CNN<br/>Random_Deep = [3, 0, 0]  ## DNN--RNN-CNN</span><span id="e027" class="gi lx kp ih ly b cr mt mu mv mw mx ma l mb">RMDL.Text_Classification(X_train, y_train, X_test, y_test,<br/>             batch_size=batch_size,<br/>             sparse_categorical=True,<br/>             random_deep=Random_Deep,<br/>             epochs=n_epochs)</span></pre><h1 id="4da0" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Olivetti Faces</h1><ul class=""><li id="6cba" class="mc md ih jr b js lm jw ln ka me ke mf ki mg km mh mi mj mk gi">There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).</li></ul><h2 id="5d9b" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Import Packages</h2><pre class="lr ls lt lu ga lv eg lw"><span id="1108" class="gi lx kp ih ly b cr lz ma l mb">from sklearn.datasets import fetch_olivetti_faces<br/>from sklearn.model_selection import train_test_split<br/>from RMDL import RMDL_Image as RMDL</span></pre><h2 id="fdf1" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Load Data</h2><pre class="lr ls lt lu ga lv eg lw"><span id="8c07" class="gi lx kp ih ly b cr lz ma l mb">number_of_classes = 40<br/>shape = (64, 64, 1)<br/>data = fetch_olivetti_faces()<br/>X_train, X_test, y_train, y_test = train_test_split(data.data,<br/>                                              data.target, stratify=data.target, test_size=40)<br/>X_train = X_train.reshape(X_train.shape[0], 64, 64, 1).astype(&#x27;float32&#x27;)<br/>X_test = X_test.reshape(X_test.shape[0], 64, 64, 1).astype(&#x27;float32&#x27;)</span></pre><h2 id="4912" class="lx kp ih bo kq my mz na ku nb nc nd ky ka ne nf lc ke ng nh lg ki ni nj lk nk gi">Using RMDL</h2><pre class="lr ls lt lu ga lv eg lw"><span id="7a64" class="gi lx kp ih ly b cr lz ma l mb">batch_size = 100<br/>sparse_categorical = 0<br/>n_epochs = [500, 500, 50]  ## DNN--RNN-CNN<br/>Random_Deep = [0, 0, 1]  ## DNN--RNN-CNN</span><span id="914d" class="gi lx kp ih ly b cr mt mu mv mw mx ma l mb">RMDL.Image_Classification(X_train, y_train, X_test, y_test,<br/>                      shape,<br/>                      random_optimizor=False,<br/>                      batch_size=batch_size,<br/>                      random_deep=Random_Deep,<br/>                      epochs=n_epochs)</span></pre><p id="e1cf" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">More Example <a class="au kn" href="https://github.com/kk7nc/RMDL/tree/master/Examples" rel="noopener ugc nofollow" target="_blank">link</a></p><figure class="lr ls lt lu ga ji fo fp paragraph-image"><div role="button" tabindex="0" class="jj jk ct jl ea jm"><div class="fo fp nl"><img alt="" class="ea jn jo" src="https://miro.medium.com/max/1400/0*gAoqpsfQrqSE2C87" width="700" height="276" role="presentation"/></div></div></figure><h1 id="0932" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Error and Comments:</h1><p id="c69b" class="pw-post-body-paragraph jp jq ih jr b js lm ju jv jw ln jy jz ka lo kc kd ke lp kg kh ki lq kk kl km ia gi">Send an email to <a class="au kn" href="mailto:kk7nc@virginia.edu" rel="noopener ugc nofollow" target="_blank">kk7nc@virginia.edu</a></p><h1 id="5eec" class="ko kp ih bo kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll gi">Citations</h1><pre class="lr ls lt lu ga lv eg lw"><span id="8d6b" class="gi lx kp ih ly b cr lz ma l mb">@inproceedings{Kowsari2018RMDL,<br/>     author = {Kowsari, Kamran and Heidarysafa, Mojtaba and Brown, Donald E. and Meimandi, Kiana Jafari and Barnes, Laura E.},<br/>     title = {RMDL: Random Multimodel Deep Learning for Classification},<br/>     booktitle = {Proceedings of the 2Nd International Conference on Information System and Data Mining},<br/>     series = {ICISDM &#x27;18},<br/>     year = {2018},<br/>     isbn = {978-1-4503-6354-9},<br/>     location = {Lakeland, FL, USA},<br/>     pages = {19--28},<br/>     numpages = {10},<br/>     url = {http://doi.acm.org/10.1145/3206098.3206111},<br/>     doi = {10.1145/3206098.3206111},<br/>     acmid = {3206111},<br/>     publisher = {ACM},<br/>     address = {New York, NY, USA},<br/>     keywords = {Data Mining, Deep Learning, Deep Neural Networks, Image Classification, Supervised Learning, Text Classification},<br/>    }</span></pre><p id="dc74" class="pw-post-body-paragraph jp jq ih jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km ia gi">and</p><pre class="lr ls lt lu ga lv eg lw"><span id="40e6" class="gi lx kp ih ly b cr lz ma l mb">@article{Heidarysafa2018RMDL,<br/>title={An Improvement of Data Classification Using Random Multimodel Deep Learning (RMDL)},<br/>author={Heidarysafa, Mojtaba and Kowsari, Kamran and Brown, Donald E. and Jafari Meimandi, Kiana and Barnes, Laura E.},<br/>booktitle={International Journal of Machine Learning and Computing (IJMLC)},<br/>year={2018},<br/>Volume={8},<br/>Number={4},<br/>pages={298--310},<br/>DOI={https://doi.org/10.18178/ijmlc.2018.8.4.703}<br/>}</span></pre></div></div></section></div></div></article></div></div><div class="nm l"></div><div></div><div class="cf nn o dd no np"><div class="nq nr ns nt o ao c"><div class="o ao gk"><div class="pw-multi-vote-icon ct nu nv nw nx"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F780a46ace985&amp;operation=register&amp;redirect=https%3A%2F%2Fkk7nc.medium.com%2Fensemble-deep-learning-780a46ace985&amp;user=Kamran+Kowsari&amp;userId=240e97f2aa2a&amp;source=-----780a46ace985---------------------clap_footer--------------" rel="noopener follow"><div class="bb ny cx nz oa ob oc nx cj od oe"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l of og oh oi oj ok ol"><div><div class="cu" role="tooltip" aria-hidden="false"><p class="bo b gq bq br"><button class="au av aw ax ay az ba bb bc bd om bf bg bh bi on">20<span class="l h g f oo op"></span></button></p></div></div></div></div><div class="oq or os l"></div><div><div class="cu" role="tooltip" aria-hidden="false"><button class="oa cx ot o ao cj oe ou" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></button></div></div></div></div><div class="l"></div><footer class="ov ow ox oy o ao oz cg c"><div class="l pa"><div class="o dd"><div class="ds ea fa fb fc fd fe ff fg fh fi"><div class="o u pb"><div class="o ao gk"><div class="pc l"><span class="l gm pd pe e d"><div class="o ao gk"><div class="pw-multi-vote-icon ct nu nv nw nx"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F780a46ace985&amp;operation=register&amp;redirect=https%3A%2F%2Fkk7nc.medium.com%2Fensemble-deep-learning-780a46ace985&amp;user=Kamran+Kowsari&amp;userId=240e97f2aa2a&amp;source=-----780a46ace985---------------------clap_footer--------------" rel="noopener follow"><div class="bb ny cx nz oa ob oc nx cj od oe"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l of og oh oi oj ok ol"><div><div class="cu" role="tooltip" aria-hidden="false"><p class="bo b gq bq br"><button class="au av aw ax ay az ba bb bc bd om bf bg bh bi on">20<span class="l h g f oo op"></span></button></p></div></div></div></div></span><span class="l h g f oo op"><div class="o ao gk"><div class="pw-multi-vote-icon ct nu nv nw nx"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F780a46ace985&amp;operation=register&amp;redirect=https%3A%2F%2Fkk7nc.medium.com%2Fensemble-deep-learning-780a46ace985&amp;user=Kamran+Kowsari&amp;userId=240e97f2aa2a&amp;source=-----780a46ace985---------------------clap_footer--------------" rel="noopener follow"><div class="bb ny cx nz oa ob oc nx cj od oe"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l of og oh oi oj ok ol"><div><div class="cu" role="tooltip" aria-hidden="false"><p class="bo b gq bq br"><button class="au av aw ax ay az ba bb bc bd om bf bg bh bi on">20</button></p></div></div></div></div></span></div><div class="pf o"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="oa cx ot o ao cj oe ou" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class="pg"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></button></div></div></div></div><div class="o ao"><div class="cu" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="cu" role="tooltip" aria-hidden="false"><button class="au av aw ax ay az ba hi bc bd be bf bg bh bi ph hj pi" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="#000"></path></svg></button></div></div></div><div class="pj l hh"></div></div></div></div></div></div></footer></div><div class="o dd"><div class="ds ea fa fb fc fd fe ff fg fh fi"></div></div><div class="l"><div class="l pk pb"><div class="l pb"><div class="pl pm l pk"><div class="o dd"><div class="ds ea fa fb fc fd fe ff fg fh fi"><div class="o ao u"><h2 class="bo pn my na po ku nb nd pp ky ka nf pq lc ke nh pr lg ki nj ps lk pt pu pv pw px py gi"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" rel="noopener follow" href="/?source=post_page-----780a46ace985-----------------------------------">More from Kamran Kowsari</a></h2><div class="pz o"><span><button class="bo b bp bq gr ee gt gu gv gw gx bd en gy gz ha er es et dv cu eu">Follow</button></span><div class="pz l"><div><div><div class="cu" role="tooltip" aria-hidden="false"><div class="l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F12881b9b03a5&amp;operation=register&amp;redirect=https%3A%2F%2Fkk7nc.medium.com%2Fensemble-deep-learning-780a46ace985&amp;newsletterV3=240e97f2aa2a&amp;newsletterV3Id=12881b9b03a5&amp;user=Kamran+Kowsari&amp;userId=240e97f2aa2a&amp;source=-----780a46ace985---------------------subscribe_user--------------" rel="noopener follow"><button class="bo b bp bq ed bb ef eg eh ei ej ek el em en gy gz ha er es et dv cu eu" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="qa qb qc"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25" stroke-width="0.5"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)" stroke-width="0.5"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5" stroke-linecap="round"></path><path d="M11.5 14.5L19 20l4-3" stroke-linecap="round"></path></svg></button></a></span></div></div></div></div></div></div></div></div></div></div></div><div class="qd l"><div class="qe qf qg qh l"><div class="hs l ec"><div class="o dd"><div class="qi qj qk ql qm jn ds ea"><div class="ah qn ai qo go qp gp qq op qr"><p class="bo b cr cs gi">Love podcasts or audiobooks? Learn on the go with our new app.</p></div><div class="qs ah qt ai qu go qv gp qw op"><a class="bo b bp bq gr ee gt qx qy qz ra bd en eo ep eq er es et dv cu eu" href="https://knowable.fyi/?utm_source=medium&amp;utm_medium=referral&amp;utm_campaign=medium-post-footer&amp;source=post_page-----780a46ace985-----------------------------------" rel="noopener follow">Try Knowable</a></div></div></div></div></div></div><div class="o dd"><div class="ds ea fa fb fc fd fe ff fg fh fi"><div class="qg l"><section class="pw-more-medium-articles l"><div class="rb l"><h2 class="bo pn rc mc ig gi">More from Medium</h2></div><div class="gb o gk hb rd re rf rg rh ri rj rk rl rm rn ro rp rq rr"><div class="rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm"><div class="ea ag"><a href="https://yolandamabusela.medium.com/sentiment-analysis-using-te-668444b1535d?source=post_internal_links---------0-------------------------------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/1*z053dgJU52BvUezXMob2Aw.png" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>Sentiment Analysis using Te</div></div><div class="bo b gq bq pt ss pu pv st px su py br"><div>Ideally i wanted to do sentiment analysis using the twitter api then i realized i have to start by creating a twitter developer account…</div></div></div></div></div></a></div></div><div class="rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm"><div class="ea ag"><a href="https://towardsdatascience.medium.com/using-semantic-ml-to-build-apps-powered-by-language-7be2a4e7e689?source=post_internal_links---------1-------------------------------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/1*8dO-lbHRDAfiuz3_obpFmQ.png" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>Using semantic ML to build apps powered by language</div></div></div></div></div></a></div></div><div class="rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm"><div class="ea ag"><a href="https://medium.com/@raywang1237/yolo-you-only-look-once-fcb98ff16d68?source=post_internal_links---------2-------------------------------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/0*T1aiN4aWXkaNnvdC" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>YOLO — You Only Look Once</div></div><div class="bo b gq bq pt ss pu pv st px su py br"><div>A state of the art real-time object detection algorithm</div></div></div></div></div></a></div></div><div class="rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm"><div class="ea ag"><a href="https://medium.com/@s.kirmer/combining-dask-and-pytorch-for-better-faster-transfer-learning-6ff64963e685?source=post_internal_links---------3-------------------------------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/1*I-KaPdjYYVFezJh2dzn_Qg.jpeg" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>Combining Dask and PyTorch for Better, Faster Transfer Learning</div></div></div></div></div></a></div></div><div class="rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm"><div class="ea ag"><a href="https://medium.com/@prahaladbelavadi/my-takeaway-from-hosting-my-second-workshop-586861c8ae12?source=post_internal_links---------4-------------------------------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>My takeaway from hosting my second workshop</div></div><div class="bo b gq bq pt ss pu pv st px su py br"><div>This second workshop I decided to take was related to machine learning using AWS resources and for those unaware of what AWS is, AWS is…</div></div></div></div></div></a></div></div><div class="rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm"><div class="ea ag"><a href="https://lakshmanraj23.medium.com/identifying-dog-breeds-using-convolutional-neural-networks-e1a039db87e4?source=post_internal_links---------5-------------------------------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/1*0_XqS9Coorib-FGGwNziuQ.jpeg" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>Udacity Capstone-Identifying Dog Breeds Using Convolutional Neural Networks</div></div></div></div></div></a></div></div><div class="rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm"><div class="ea ag"><a href="https://medium.com/@santhoopajayawardhana/ai-to-detect-hate-speech-related-sinhala-comments-in-social-media-b94196744eec?source=post_internal_links---------6-------------------------------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="Social Media usage in Sri Lanka" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/0*FzqBw1PS4T2IxXQ4" width="58" height="58"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>Artificial Intelligence to Detect Hate Speech related Sinhala comments in Social Media</div></div></div></div></div></a></div></div><div class="rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm"><div class="ea ag"><a href="https://louisdorard.medium.com/12-great-links-on-key-machine-learning-topics-in-2018-5a28da957ab4?source=post_internal_links---------7-------------------------------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/1*rhH-8BAIfDLrPcyKn880eg.jpeg" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>12 great links on key Machine Learning topics in 2018</div></div></div></div></div></a></div></div></div></section></div></div></div></div></div></div></main><div class="du dv c dw h k j i by dx dy dz"><div class="ag ea cu ct"><div class="l cf aq"><div class="dx o ce"><div class="l pa"><div class="l c"><div class="l"><div class="qg o ao"><div class="pw-susi-button l pa"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fkk7nc.medium.com%2Fensemble-deep-learning-780a46ace985&amp;source=post_page--------------------------nav_reg--------------" rel="noopener follow"><button class="bo b bp bq ed ee ef eg eh ei ej ek el em en eo ep eq er ea es et dv cu eu" aria-label="sign up">Get started</button></a></span></div></div></div><div class="sv l"><div class="o hr nr sw"><div class="cu" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><span class="tc l"><svg width="25" height="25" viewBox="0 0 25 25" fill="rgba(8, 8, 8, 1)"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></span><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" tabindex="0" class="df sx bo bp bq sy ea sz ta gi tb" placeholder="Search" value=""/></div><div class="td l"></div><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" rel="noopener follow" href="/"><div class="l ct"><img alt="Kamran Kowsari" class="l dv ge te tf" src="https://miro.medium.com/fit/c/176/176/0*WDW28d_jMNxFwCoA.jpg" width="88" height="88"/><div class="gd ge l te tf gh aq"></div></div></a><div class="nm l"></div><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" rel="noopener follow" href="/"><h2 class="pw-author-name bo pn cr bq ig gi">Kamran Kowsari</h2></a><div class="sp l"></div><p class="bo b bp bq gi"><span class="pw-follower-count bo b cr cs br"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi">165 Followers</button></span></p><div class="tg l"></div><div class="th l"></div><div class="ti o"><span><button class="bo b bp bq gr ee gt gu gv gw gx bd en gy gz ha er tj es et dv cu eu">Follow</button></span><div class="pz l"><div><div><div class="cu" role="tooltip" aria-hidden="false"><div class="l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F12881b9b03a5&amp;operation=register&amp;redirect=https%3A%2F%2Fkk7nc.medium.com%2Fensemble-deep-learning-780a46ace985&amp;newsletterV3=240e97f2aa2a&amp;newsletterV3Id=12881b9b03a5&amp;user=Kamran+Kowsari&amp;userId=240e97f2aa2a&amp;source=--------------------------subscribe_user--------------" rel="noopener follow"><button class="bo b bp bq ed bb ef eg eh ei ej ek el em en gy gz ha er es et dv cu eu" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="qa qb qc"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25" stroke-width="0.5"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)" stroke-width="0.5"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5" stroke-linecap="round"></path><path d="M11.5 14.5L19 20l4-3" stroke-linecap="round"></path></svg></button></a></span></div></div></div></div></div></div><div class="tk l"><div class="l"><div class="tl td l"><h2 class="bo pn cr bq ig gi">Related</h2></div><div class="l"><div class="ea ag"><a href="https://medium.com/@draj0718/the-math-behind-k-means-clustering-4aa85532085e?source=read_next_recirc---------0---------------------cc57183b_b030_4d8d_baaf_81524c85931d----------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/1*B6yM63KsquINow0oBx-BYg.png" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>The Math Behind K-Means Clustering</div></div><div class="bo b gq bq pt ss pu pv st px su py br"><div>Introduction</div></div></div></div></div></a></div><div class="ea ag"><a href="https://medium.com/@sunils0506/types-of-cross-validations-f1ad3a871f67?source=read_next_recirc---------1---------------------cc57183b_b030_4d8d_baaf_81524c85931d----------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/0*GLnW_te0TRnUACR7.png" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>Types of Cross Validations</div></div><div class="bo b gq bq pt ss pu pv st px su py br"><div>Cross-Validation also referred to as out of sampling technique . It is a resampling procedure used to evaluate machine learning models and…</div></div></div></div></div></a></div><div class="ea ag"><a href="https://creativityinczenyoga.medium.com/on-the-trees-of-machine-learning-301cdb84d57a?source=read_next_recirc---------2---------------------cc57183b_b030_4d8d_baaf_81524c85931d----------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/1*m1NJb4NoACc4xLMtKlfpSQ.png" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>On the Trees of Machine Learning</div></div><div class="bo b gq bq pt ss pu pv st px su py br"><div>Based on the StatQuest YouTube series by Josh Starmer</div></div></div></div></div></a></div><div class="ea ag"><a href="https://medium.com/@roushanakrahmat/what-is-ensemble-learning-356c3d36f1df?source=read_next_recirc---------3---------------------cc57183b_b030_4d8d_baaf_81524c85931d----------" rel="noopener follow"><div class="sn o ce dd"><div class="o gk"><img alt="" class="so sp" src="https://miro.medium.com/focal/116/116/50/50/0*NDI9YTlAdWOStvxr.png" width="58" height="58" role="presentation"/><div class="o ce"><div class="bo b gq bq pt sq pu pv sr px py gi"><div>What is Ensemble Learning?</div></div><div class="bo b gq bq pt ss pu pv st px su py br"><div>In machine learning and statistics, Ensemble learning is the prediction process using combining multiple learning models (it can be…</div></div></div></div></div></a></div></div></div></div></div></div></div><div class="tm o gk hb"><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://help.medium.com/hc/en-us" rel="noopener follow"><p class="bo b to tp br">Help</p></a></div><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.statuspage.io" rel="noopener follow"><p class="bo b to tp br">Status</p></a></div><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://about.medium.com/creators/" rel="noopener follow"><p class="bo b to tp br">Writers</p></a></div><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://blog.medium.com" rel="noopener follow"><p class="bo b to tp br">Blog</p></a></div><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e" rel="noopener follow"><p class="bo b to tp br">Careers</p></a></div><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9" rel="noopener follow"><p class="bo b to tp br">Privacy</p></a></div><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f" rel="noopener follow"><p class="bo b to tp br">Terms</p></a></div><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/about?autoplay=1" rel="noopener follow"><p class="bo b to tp br">About</p></a></div><div class="tn l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://knowable.fyi" rel="noopener follow"><p class="bo b to tp br">Knowable</p></a></div></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20220325-213604-e791677e68"</script><script>window.__GRAPHQL_URI__ = "https://kk7nc.medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"auroraPage":{"isAuroraPageEnabled":false},"bookReader":{"assets":{},"reader":{"currentAsset":null,"currentGFI":null,"settingsPanelIsOpen":false,"settings":{"fontFamily":"CHARTER","fontScale":"M","publisherStyling":false,"textAlignment":"start","theme":"White","lineSpacing":0,"wordSpacing":0,"letterSpacing":0},"internalNavCounter":0,"currentSelection":null}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-780a46ace985","user-240e97f2aa2a"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[]},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"USER","id":"240e97f2aa2a","explicit":true},"viewerIsBot":false},"debug":{"requestId":"c8180893-6012-44f9-8298-38c1ae95539f","hybridDevServices":[],"showBookReaderDebugger":false,"originalSpanCarrier":{"ot-tracer-spanid":"58a935f620c9381c","ot-tracer-traceid":"2c57224020d4d65c","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fkk7nc.medium.com\u002Fensemble-deep-learning-780a46ace985","host":"kk7nc.medium.com","hostname":"kk7nc.medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"queryString":"","currentHash":""},"tracing":{},"userOnboarding":{"showFirstBookPurchaseTooltip":false},"config":{"nodeEnv":"production","version":"main-20220325-213604-e791677e68","isTaggedVersion":false,"target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"main-20220325-213604-e791677e68","disableClientReporting":true},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20220325-213604-e791677e68","commit":"e791677e682c8d3406f8d4e3fdd8aa8d6a6511a5"}},"datacenter":"us"},"googleAnalyticsCode":"UA-24232453-2","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"cwr8xtycwgjryv82","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","user({\"id\":\"240e97f2aa2a\"})":{"__ref":"User:240e97f2aa2a"},"userResult({\"id\":\"240e97f2aa2a\"})":{"__ref":"User:240e97f2aa2a"},"collectionByDomainOrSlug({\"domainOrSlug\":\"kk7nc.medium.com\"})":null,"postResult({\"id\":\"780a46ace985\"})":{"__ref":"Post:780a46ace985"},"recirc({\"paging\":{\"limit\":4},\"postId\":\"780a46ace985\"})":{"__typename":"RexRecircResult","items":[{"__typename":"RexRecircItem","post":{"__ref":"Post:4aa85532085e"},"feedId":"cc57183b-b030-4d8d-baaf-81524c85931d"},{"__typename":"RexRecircItem","post":{"__ref":"Post:f1ad3a871f67"},"feedId":"cc57183b-b030-4d8d-baaf-81524c85931d"},{"__typename":"RexRecircItem","post":{"__ref":"Post:301cdb84d57a"},"feedId":"cc57183b-b030-4d8d-baaf-81524c85931d"},{"__typename":"RexRecircItem","post":{"__ref":"Post:356c3d36f1df"},"feedId":"cc57183b-b030-4d8d-baaf-81524c85931d"}]}},"User:240e97f2aa2a":{"id":"240e97f2aa2a","__typename":"User","customStyleSheet":null,"name":"Kamran Kowsari","username":"kk7nc","newsletterV3":{"__ref":"NewsletterV3:12881b9b03a5"},"imageId":"0*WDW28d_jMNxFwCoA.jpg","socialStats":{"__typename":"SocialStats","followerCount":165,"followingCount":12,"collectionFollowingCount":1},"bio":"","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:240e97f2aa2a-viewerId:lo_3468aa1399eb"},"viewerIsUser":false,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"kk7nc.medium.com","status":"ACTIVE","isSubdomain":true}},"hasSubdomain":true,"postSubscribeMembershipUpsellShownAt":0,"isSuspended":false,"about":"","bookAuthor":null,"homepagePostsConnection({\"paging\":{\"limit\":1}})":{"__typename":"PostConnection","posts":[{"__ref":"Post:5e965fecb499"}]},"mediumMemberAt":0,"allowNotes":true,"twitterScreenName":"KamranKowsari","referredMembershipCustomHeadline":"","referredMembershipCustomBody":"","isAuroraVisible":true,"atsQualifiedAt":1612205657525,"followersUserConnection({\"paging\":{\"limit\":10}})":{"__typename":"UserConnection","users":[{"__ref":"User:104a7ff92a84"},{"__ref":"User:111bff8a7188"},{"__ref":"User:11b4684b7c04"},{"__ref":"User:16f8063f79c8"},{"__ref":"User:1708eff7aa89"},{"__ref":"User:18ba011c6262"},{"__ref":"User:1b66568e33c2"},{"__ref":"User:1b66ab7113bc"},{"__ref":"User:1bce8a6f2aa4"},{"__ref":"User:1bd169001911"}],"pagingInfo":{"__typename":"Paging","next":{"__typename":"PageParams","to":null,"from":"1bd169001911","limit":10}}}},"UserViewerEdge:userId:240e97f2aa2a-viewerId:lo_3468aa1399eb":{"id":"userId:240e97f2aa2a-viewerId:lo_3468aa1399eb","__typename":"UserViewerEdge","isFollowing":false,"isUser":false},"NewsletterV3:12881b9b03a5":{"id":"12881b9b03a5","__typename":"NewsletterV3","type":"NEWSLETTER_TYPE_AUTHOR","slug":"240e97f2aa2a","name":"240e97f2aa2a","collection":null,"user":{"__ref":"User:240e97f2aa2a"},"description":"","promoHeadline":"","promoBody":"","showPromo":false,"subscribersCount":0},"Post:780a46ace985":{"id":"780a46ace985","__typename":"Post","firstPublishedAt":1558550121515,"visibility":"PUBLIC","creator":{"__ref":"User:240e97f2aa2a"},"canonicalUrl":"","collection":null,"content({\"postMeteringOptions\":null})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","bodyModel":{"__typename":"RichText","paragraphs":[{"__ref":"Paragraph:bc22134e6633_0"},{"__ref":"Paragraph:bc22134e6633_1"},{"__ref":"Paragraph:bc22134e6633_2"},{"__ref":"Paragraph:bc22134e6633_3"},{"__ref":"Paragraph:bc22134e6633_4"},{"__ref":"Paragraph:bc22134e6633_5"},{"__ref":"Paragraph:bc22134e6633_6"},{"__ref":"Paragraph:bc22134e6633_7"},{"__ref":"Paragraph:bc22134e6633_8"},{"__ref":"Paragraph:bc22134e6633_9"},{"__ref":"Paragraph:bc22134e6633_10"},{"__ref":"Paragraph:bc22134e6633_11"},{"__ref":"Paragraph:bc22134e6633_12"},{"__ref":"Paragraph:bc22134e6633_13"},{"__ref":"Paragraph:bc22134e6633_14"},{"__ref":"Paragraph:bc22134e6633_15"},{"__ref":"Paragraph:bc22134e6633_16"},{"__ref":"Paragraph:bc22134e6633_17"},{"__ref":"Paragraph:bc22134e6633_18"},{"__ref":"Paragraph:bc22134e6633_19"},{"__ref":"Paragraph:bc22134e6633_20"},{"__ref":"Paragraph:bc22134e6633_21"},{"__ref":"Paragraph:bc22134e6633_22"},{"__ref":"Paragraph:bc22134e6633_23"},{"__ref":"Paragraph:bc22134e6633_24"},{"__ref":"Paragraph:bc22134e6633_25"},{"__ref":"Paragraph:bc22134e6633_26"},{"__ref":"Paragraph:bc22134e6633_27"},{"__ref":"Paragraph:bc22134e6633_28"},{"__ref":"Paragraph:bc22134e6633_29"},{"__ref":"Paragraph:bc22134e6633_30"},{"__ref":"Paragraph:bc22134e6633_31"},{"__ref":"Paragraph:bc22134e6633_32"},{"__ref":"Paragraph:bc22134e6633_33"},{"__ref":"Paragraph:bc22134e6633_34"},{"__ref":"Paragraph:bc22134e6633_35"},{"__ref":"Paragraph:bc22134e6633_36"},{"__ref":"Paragraph:bc22134e6633_37"},{"__ref":"Paragraph:bc22134e6633_38"},{"__ref":"Paragraph:bc22134e6633_39"},{"__ref":"Paragraph:bc22134e6633_40"},{"__ref":"Paragraph:bc22134e6633_41"},{"__ref":"Paragraph:bc22134e6633_42"},{"__ref":"Paragraph:bc22134e6633_43"},{"__ref":"Paragraph:bc22134e6633_44"},{"__ref":"Paragraph:bc22134e6633_45"},{"__ref":"Paragraph:bc22134e6633_46"},{"__ref":"Paragraph:bc22134e6633_47"},{"__ref":"Paragraph:bc22134e6633_48"},{"__ref":"Paragraph:bc22134e6633_49"},{"__ref":"Paragraph:bc22134e6633_50"},{"__ref":"Paragraph:bc22134e6633_51"},{"__ref":"Paragraph:bc22134e6633_52"},{"__ref":"Paragraph:bc22134e6633_53"},{"__ref":"Paragraph:bc22134e6633_54"},{"__ref":"Paragraph:bc22134e6633_55"},{"__ref":"Paragraph:bc22134e6633_56"},{"__ref":"Paragraph:bc22134e6633_57"},{"__ref":"Paragraph:bc22134e6633_58"},{"__ref":"Paragraph:bc22134e6633_59"},{"__ref":"Paragraph:bc22134e6633_60"},{"__ref":"Paragraph:bc22134e6633_61"},{"__ref":"Paragraph:bc22134e6633_62"},{"__ref":"Paragraph:bc22134e6633_63"},{"__ref":"Paragraph:bc22134e6633_64"},{"__ref":"Paragraph:bc22134e6633_65"},{"__ref":"Paragraph:bc22134e6633_66"},{"__ref":"Paragraph:bc22134e6633_67"},{"__ref":"Paragraph:bc22134e6633_68"},{"__ref":"Paragraph:bc22134e6633_69"},{"__ref":"Paragraph:bc22134e6633_70"},{"__ref":"Paragraph:bc22134e6633_71"},{"__ref":"Paragraph:bc22134e6633_72"},{"__ref":"Paragraph:bc22134e6633_73"},{"__ref":"Paragraph:bc22134e6633_74"},{"__ref":"Paragraph:bc22134e6633_75"},{"__ref":"Paragraph:bc22134e6633_76"},{"__ref":"Paragraph:bc22134e6633_77"},{"__ref":"Paragraph:bc22134e6633_78"},{"__ref":"Paragraph:bc22134e6633_79"},{"__ref":"Paragraph:bc22134e6633_80"},{"__ref":"Paragraph:bc22134e6633_81"},{"__ref":"Paragraph:bc22134e6633_82"},{"__ref":"Paragraph:bc22134e6633_83"},{"__ref":"Paragraph:bc22134e6633_84"},{"__ref":"Paragraph:bc22134e6633_85"},{"__ref":"Paragraph:bc22134e6633_86"},{"__ref":"Paragraph:bc22134e6633_87"},{"__ref":"Paragraph:bc22134e6633_88"},{"__ref":"Paragraph:bc22134e6633_89"},{"__ref":"Paragraph:bc22134e6633_90"},{"__ref":"Paragraph:bc22134e6633_91"},{"__ref":"Paragraph:bc22134e6633_92"},{"__ref":"Paragraph:bc22134e6633_93"},{"__ref":"Paragraph:bc22134e6633_94"},{"__ref":"Paragraph:bc22134e6633_95"},{"__ref":"Paragraph:bc22134e6633_96"},{"__ref":"Paragraph:bc22134e6633_97"},{"__ref":"Paragraph:bc22134e6633_98"},{"__ref":"Paragraph:bc22134e6633_99"},{"__ref":"Paragraph:bc22134e6633_100"},{"__ref":"Paragraph:bc22134e6633_101"},{"__ref":"Paragraph:bc22134e6633_102"},{"__ref":"Paragraph:bc22134e6633_103"},{"__ref":"Paragraph:bc22134e6633_104"},{"__ref":"Paragraph:bc22134e6633_105"},{"__ref":"Paragraph:bc22134e6633_106"},{"__ref":"Paragraph:bc22134e6633_107"},{"__ref":"Paragraph:bc22134e6633_108"},{"__ref":"Paragraph:bc22134e6633_109"},{"__ref":"Paragraph:bc22134e6633_110"},{"__ref":"Paragraph:bc22134e6633_111"},{"__ref":"Paragraph:bc22134e6633_112"},{"__ref":"Paragraph:bc22134e6633_113"},{"__ref":"Paragraph:bc22134e6633_114"},{"__ref":"Paragraph:bc22134e6633_115"},{"__ref":"Paragraph:bc22134e6633_116"},{"__ref":"Paragraph:bc22134e6633_117"},{"__ref":"Paragraph:bc22134e6633_118"},{"__ref":"Paragraph:bc22134e6633_119"},{"__ref":"Paragraph:bc22134e6633_120"},{"__ref":"Paragraph:bc22134e6633_121"},{"__ref":"Paragraph:bc22134e6633_122"},{"__ref":"Paragraph:bc22134e6633_123"},{"__ref":"Paragraph:bc22134e6633_124"},{"__ref":"Paragraph:bc22134e6633_125"},{"__ref":"Paragraph:bc22134e6633_126"},{"__ref":"Paragraph:bc22134e6633_127"},{"__ref":"Paragraph:bc22134e6633_128"},{"__ref":"Paragraph:bc22134e6633_129"},{"__ref":"Paragraph:bc22134e6633_130"},{"__ref":"Paragraph:bc22134e6633_131"},{"__ref":"Paragraph:bc22134e6633_132"},{"__ref":"Paragraph:bc22134e6633_133"},{"__ref":"Paragraph:bc22134e6633_134"},{"__ref":"Paragraph:bc22134e6633_135"},{"__ref":"Paragraph:bc22134e6633_136"},{"__ref":"Paragraph:bc22134e6633_137"},{"__ref":"Paragraph:bc22134e6633_138"},{"__ref":"Paragraph:bc22134e6633_139"},{"__ref":"Paragraph:bc22134e6633_140"},{"__ref":"Paragraph:bc22134e6633_141"},{"__ref":"Paragraph:bc22134e6633_142"},{"__ref":"Paragraph:bc22134e6633_143"},{"__ref":"Paragraph:bc22134e6633_144"},{"__ref":"Paragraph:bc22134e6633_145"},{"__ref":"Paragraph:bc22134e6633_146"},{"__ref":"Paragraph:bc22134e6633_147"},{"__ref":"Paragraph:bc22134e6633_148"},{"__ref":"Paragraph:bc22134e6633_149"},{"__ref":"Paragraph:bc22134e6633_150"},{"__ref":"Paragraph:bc22134e6633_151"},{"__ref":"Paragraph:bc22134e6633_152"},{"__ref":"Paragraph:bc22134e6633_153"},{"__ref":"Paragraph:bc22134e6633_154"},{"__ref":"Paragraph:bc22134e6633_155"},{"__ref":"Paragraph:bc22134e6633_156"},{"__ref":"Paragraph:bc22134e6633_157"},{"__ref":"Paragraph:bc22134e6633_158"},{"__ref":"Paragraph:bc22134e6633_159"},{"__ref":"Paragraph:bc22134e6633_160"},{"__ref":"Paragraph:bc22134e6633_161"},{"__ref":"Paragraph:bc22134e6633_162"},{"__ref":"Paragraph:bc22134e6633_163"},{"__ref":"Paragraph:bc22134e6633_164"},{"__ref":"Paragraph:bc22134e6633_165"},{"__ref":"Paragraph:bc22134e6633_166"},{"__ref":"Paragraph:bc22134e6633_167"},{"__ref":"Paragraph:bc22134e6633_168"},{"__ref":"Paragraph:bc22134e6633_169"},{"__ref":"Paragraph:bc22134e6633_170"},{"__ref":"Paragraph:bc22134e6633_171"},{"__ref":"Paragraph:bc22134e6633_172"},{"__ref":"Paragraph:bc22134e6633_173"},{"__ref":"Paragraph:bc22134e6633_174"},{"__ref":"Paragraph:bc22134e6633_175"},{"__ref":"Paragraph:bc22134e6633_176"},{"__ref":"Paragraph:bc22134e6633_177"},{"__ref":"Paragraph:bc22134e6633_178"},{"__ref":"Paragraph:bc22134e6633_179"},{"__ref":"Paragraph:bc22134e6633_180"},{"__ref":"Paragraph:bc22134e6633_181"},{"__ref":"Paragraph:bc22134e6633_182"},{"__ref":"Paragraph:bc22134e6633_183"},{"__ref":"Paragraph:bc22134e6633_184"},{"__ref":"Paragraph:bc22134e6633_185"},{"__ref":"Paragraph:bc22134e6633_186"},{"__ref":"Paragraph:bc22134e6633_187"},{"__ref":"Paragraph:bc22134e6633_188"},{"__ref":"Paragraph:bc22134e6633_189"},{"__ref":"Paragraph:bc22134e6633_190"},{"__ref":"Paragraph:bc22134e6633_191"},{"__ref":"Paragraph:bc22134e6633_192"},{"__ref":"Paragraph:bc22134e6633_193"},{"__ref":"Paragraph:bc22134e6633_194"},{"__ref":"Paragraph:bc22134e6633_195"},{"__ref":"Paragraph:bc22134e6633_196"},{"__ref":"Paragraph:bc22134e6633_197"},{"__ref":"Paragraph:bc22134e6633_198"},{"__ref":"Paragraph:bc22134e6633_199"},{"__ref":"Paragraph:bc22134e6633_200"},{"__ref":"Paragraph:bc22134e6633_201"},{"__ref":"Paragraph:bc22134e6633_202"},{"__ref":"Paragraph:bc22134e6633_203"},{"__ref":"Paragraph:bc22134e6633_204"},{"__ref":"Paragraph:bc22134e6633_205"},{"__ref":"Paragraph:bc22134e6633_206"},{"__ref":"Paragraph:bc22134e6633_207"},{"__ref":"Paragraph:bc22134e6633_208"},{"__ref":"Paragraph:bc22134e6633_209"},{"__ref":"Paragraph:bc22134e6633_210"},{"__ref":"Paragraph:bc22134e6633_211"},{"__ref":"Paragraph:bc22134e6633_212"},{"__ref":"Paragraph:bc22134e6633_213"},{"__ref":"Paragraph:bc22134e6633_214"},{"__ref":"Paragraph:bc22134e6633_215"},{"__ref":"Paragraph:bc22134e6633_216"},{"__ref":"Paragraph:bc22134e6633_217"},{"__ref":"Paragraph:bc22134e6633_218"},{"__ref":"Paragraph:bc22134e6633_219"},{"__ref":"Paragraph:bc22134e6633_220"},{"__ref":"Paragraph:bc22134e6633_221"},{"__ref":"Paragraph:bc22134e6633_222"},{"__ref":"Paragraph:bc22134e6633_223"},{"__ref":"Paragraph:bc22134e6633_224"},{"__ref":"Paragraph:bc22134e6633_225"},{"__ref":"Paragraph:bc22134e6633_226"},{"__ref":"Paragraph:bc22134e6633_227"},{"__ref":"Paragraph:bc22134e6633_228"},{"__ref":"Paragraph:bc22134e6633_229"}],"sections":[{"__typename":"Section","name":"1eea","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}]}},"customStyleSheet":null,"isPublished":true,"isLocked":false,"license":"ALL_RIGHTS_RESERVED","isMarkedPaywallOnly":false,"mediumUrl":"https:\u002F\u002Fkk7nc.medium.com\u002Fensemble-deep-learning-780a46ace985","allowResponses":true,"postResponses":{"__typename":"PostResponses","count":0},"isLimitedState":false,"isNewsletter":false,"layerCake":0,"tags":[{"__ref":"Tag:machine-learning"},{"__ref":"Tag:classification"},{"__ref":"Tag:ensemble-learning"}],"topics":[{"__typename":"Topic","name":"Machine Learning"}],"isSeries":false,"sequence":null,"uniqueSlug":"ensemble-deep-learning-780a46ace985","primaryTopic":null,"socialTitle":"","socialDek":"","noIndex":null,"curationStatus":"CURATION_STATUS_NOT_REVIEWED","metaDescription":"","latestPublishedAt":1558550637707,"readingTime":10.568238993710692,"previewContent":{"__typename":"PreviewContent","subtitle":"Referenced paper : RMDL: Random Multimodel Deep Learning for Classification"},"previewImage":{"__ref":"ImageMetadata:0*jRwJaYk_Wvc3jGKw"},"isShortform":false,"isSuspended":false,"responseRootPost":{"__typename":"ResponseRootPost","post":{"__ref":"Post:780a46ace985"}},"lockedSource":"LOCKED_POST_SOURCE_NONE","clapCount":20,"statusForCollection":null,"pendingCollection":null,"title":"Ensemble Deep Learning","inResponseToEntityType":null,"seoTitle":"","updatedAt":1639105586128,"shortformType":"SHORTFORM_TYPE_LINK","structuredData":"","seoDescription":"","isIndexable":true,"pinnedAt":0,"internalLinks({\"paging\":{\"limit\":8}})":{"__typename":"InternalLinksConnection","items":[{"__ref":"Post:668444b1535d"},{"__ref":"Post:7be2a4e7e689"},{"__ref":"Post:fcb98ff16d68"},{"__ref":"Post:6ff64963e685"},{"__ref":"Post:586861c8ae12"},{"__ref":"Post:e1a039db87e4"},{"__ref":"Post:b94196744eec"},{"__ref":"Post:5a28da957ab4"}]},"pinnedByCreatorAt":0,"curationEligibleAt":1558550120483,"responseDistribution":"NOT_DISTRIBUTED","inResponseToPostResult":null,"inResponseToCatalogResult":null,"latestPublishedVersion":"bc22134e6633","isAuthorNewsletter":false,"voterCount":10,"recommenders":[]},"Topic:1eca0103fff3":{"id":"1eca0103fff3","__typename":"Topic","name":"Machine Learning","slug":"machine-learning"},"ImageMetadata:1*B6yM63KsquINow0oBx-BYg.png":{"id":"1*B6yM63KsquINow0oBx-BYg.png","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:858e07742a6f":{"id":"858e07742a6f","__typename":"User","customDomainState":null,"hasSubdomain":false,"username":"draj0718"},"Post:4aa85532085e":{"id":"4aa85532085e","__typename":"Post","title":"The Math Behind K-Means Clustering","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@draj0718\u002Fthe-math-behind-k-means-clustering-4aa85532085e","previewContent":{"__typename":"PreviewContent","subtitle":"Introduction","isFullContent":false},"primaryTopic":{"__ref":"Topic:1eca0103fff3"},"collection":null,"previewImage":{"__ref":"ImageMetadata:1*B6yM63KsquINow0oBx-BYg.png"},"clapCount":8,"visibility":"PUBLIC","creator":{"__ref":"User:858e07742a6f"},"isSeries":false,"sequence":null,"uniqueSlug":"the-math-behind-k-means-clustering-4aa85532085e"},"ImageMetadata:0*GLnW_te0TRnUACR7.png":{"id":"0*GLnW_te0TRnUACR7.png","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:b3e3bc4a9802":{"id":"b3e3bc4a9802","__typename":"User","customDomainState":null,"hasSubdomain":false,"username":"sunils0506"},"Post:f1ad3a871f67":{"id":"f1ad3a871f67","__typename":"Post","title":"Types of Cross Validations","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@sunils0506\u002Ftypes-of-cross-validations-f1ad3a871f67","previewContent":{"__typename":"PreviewContent","subtitle":"Cross-Validation also referred to as out of sampling technique . It is a resampling procedure used to evaluate machine learning models and…","isFullContent":false},"primaryTopic":{"__ref":"Topic:1eca0103fff3"},"collection":null,"previewImage":{"__ref":"ImageMetadata:0*GLnW_te0TRnUACR7.png"},"clapCount":6,"visibility":"PUBLIC","creator":{"__ref":"User:b3e3bc4a9802"},"isSeries":false,"sequence":null,"uniqueSlug":"types-of-cross-validations-f1ad3a871f67"},"Collection:12e0cb81eab9":{"id":"12e0cb81eab9","__typename":"Collection","name":"Deterministic Algorithms Lab","slug":"da-labs","domain":null},"ImageMetadata:1*m1NJb4NoACc4xLMtKlfpSQ.png":{"id":"1*m1NJb4NoACc4xLMtKlfpSQ.png","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:46ca39eaec3a":{"id":"46ca39eaec3a","__typename":"User","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"creativityinczenyoga.medium.com"}},"hasSubdomain":true,"username":"creativityinczenyoga"},"Post:301cdb84d57a":{"id":"301cdb84d57a","__typename":"Post","title":"On the Trees of Machine Learning","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fda-labs\u002Fon-the-trees-of-machine-learning-301cdb84d57a","previewContent":{"__typename":"PreviewContent","subtitle":"Based on the StatQuest YouTube series by Josh Starmer","isFullContent":false},"primaryTopic":{"__ref":"Topic:1eca0103fff3"},"collection":{"__ref":"Collection:12e0cb81eab9"},"previewImage":{"__ref":"ImageMetadata:1*m1NJb4NoACc4xLMtKlfpSQ.png"},"clapCount":1,"visibility":"PUBLIC","creator":{"__ref":"User:46ca39eaec3a"},"isSeries":false,"sequence":null,"uniqueSlug":"on-the-trees-of-machine-learning-301cdb84d57a"},"ImageMetadata:0*NDI9YTlAdWOStvxr.png":{"id":"0*NDI9YTlAdWOStvxr.png","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:e871918a28ed":{"id":"e871918a28ed","__typename":"User","customDomainState":null,"hasSubdomain":false,"username":"roushanakrahmat"},"Post:356c3d36f1df":{"id":"356c3d36f1df","__typename":"Post","title":"What is Ensemble Learning?","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@roushanakrahmat\u002Fwhat-is-ensemble-learning-356c3d36f1df","previewContent":{"__typename":"PreviewContent","subtitle":"In machine learning and statistics, Ensemble learning is the prediction process using combining multiple learning models (it can be…","isFullContent":false},"primaryTopic":{"__ref":"Topic:1eca0103fff3"},"collection":null,"previewImage":{"__ref":"ImageMetadata:0*NDI9YTlAdWOStvxr.png"},"clapCount":100,"visibility":"PUBLIC","creator":{"__ref":"User:e871918a28ed"},"isSeries":false,"sequence":null,"uniqueSlug":"what-is-ensemble-learning-356c3d36f1df"},"Post:5e965fecb499":{"id":"5e965fecb499","__typename":"Post"},"Paragraph:bc22134e6633_0":{"id":"bc22134e6633_0","__typename":"Paragraph","name":"be50","text":"Ensemble Deep Learning","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_1":{"id":"bc22134e6633_1","__typename":"Paragraph","name":"91b7","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*jRwJaYk_Wvc3jGKw"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_2":{"id":"bc22134e6633_2","__typename":"Paragraph","name":"b5ce","text":"Referenced paper : RMDL: Random Multimodel Deep Learning for Classification","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":19,"end":75,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.01890","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_3":{"id":"bc22134e6633_3","__typename":"Paragraph","name":"a00e","text":"Referenced paper: An Improvement of Data Classification Using Random Multimodel Deep Learning (RMDL)","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":18,"end":100,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.08121","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_4":{"id":"bc22134e6633_4","__typename":"Paragraph","name":"f4f8","text":"Random Multimodel Deep Learning (RMDL):","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_5":{"id":"bc22134e6633_5","__typename":"Paragraph","name":"6a99","text":"A new ensemble, deep learning approach for classification. Deep learning models have achieved state-of-the-art results across many domains. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. RDML can accept as input a variety of data to include text, video, images, and symbolic.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_6":{"id":"bc22134e6633_6","__typename":"Paragraph","name":"766b","text":"Random Multimodel Deep Learning (RDML) architecture for classification. RMDL includes 3 Random models, oneDNN classifier at left, one Deep CNN classifier at middle, and one Deep RNN classifier at right (each unit could be LSTMor GRU).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_7":{"id":"bc22134e6633_7","__typename":"Paragraph","name":"c212","text":"Installation","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_8":{"id":"bc22134e6633_8","__typename":"Paragraph","name":"1b96","text":"There are pip and git for RMDL installation:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_9":{"id":"bc22134e6633_9","__typename":"Paragraph","name":"457b","text":"Using pip","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_10":{"id":"bc22134e6633_10","__typename":"Paragraph","name":"1719","text":"pip install RMDL","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_11":{"id":"bc22134e6633_11","__typename":"Paragraph","name":"e28b","text":"Using git","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_12":{"id":"bc22134e6633_12","__typename":"Paragraph","name":"05b6","text":"git clone --recursive https:\u002F\u002Fgithub.com\u002Fkk7nc\u002FRMDL.git","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":22,"end":55,"href":"https:\u002F\u002Fgithub.com\u002Fkk7nc\u002FRMDL.git","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_13":{"id":"bc22134e6633_13","__typename":"Paragraph","name":"3782","text":"The primary requirements for this package are Python 3 with Tensorflow. The requirements.txt file contains a listing of the required Python packages; to install all requirements, run the following:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_14":{"id":"bc22134e6633_14","__typename":"Paragraph","name":"f4fa","text":"pip -r install requirements.txt","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_15":{"id":"bc22134e6633_15","__typename":"Paragraph","name":"f250","text":"Or","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_16":{"id":"bc22134e6633_16","__typename":"Paragraph","name":"ef2b","text":"pip3  install -r requirements.txt","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_17":{"id":"bc22134e6633_17","__typename":"Paragraph","name":"f704","text":"Or:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_18":{"id":"bc22134e6633_18","__typename":"Paragraph","name":"08b0","text":"conda install --file requirements.txt","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_19":{"id":"bc22134e6633_19","__typename":"Paragraph","name":"bdfe","text":"Documentation:","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_20":{"id":"bc22134e6633_20","__typename":"Paragraph","name":"298b","text":"The exponential growth in the number of complex datasets every year requires more enhancement in machine learning methods to provide robust and accurate data classification. Lately, deep learning approaches have been achieved surpassing results in comparison to previous machine learning algorithms on tasks such as image classification, natural language processing, face recognition, and etc. The success of these deep learning algorithms relies on their capacity to model complex and non-linear relationships within data. However, finding a suitable structure for these models has been a challenge for researchers. This paper introduces Random Multimodel Deep Learning (RMDL): a new ensemble, deep learning approach for classification. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. In short, RMDL trains multiple models of Deep Neural Network (DNN), Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) in parallel and combines their results to produce a better result of any of those models individually. To create these models, each deep learning model has been constructed in a random fashion regarding the number of layers and nodes in their neural network structure. The resulting RDML model can be used for various domains such as text, video, images, and symbolic. In this Project, we describe RMDL model in depth and show the results for image and text classification as well as face recognition. For image classification, we compared our model with some of the available baselines using MNIST and CIFAR-10 datasets. Similarly, we used four datasets namely, WOS, Reuters, IMDB, and 20newsgroup and compared our results with available baselines. Web of Science (WOS) has been collected by authors and consists of three sets~(small, medium and large set). Lastly, we used ORL dataset to compare the performance of our approach with other face recognition methods. These test results show that RDML model consistently outperforms standard methods over a broad range of data types and classification problems.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_21":{"id":"bc22134e6633_21","__typename":"Paragraph","name":"2905","text":"Datasets for RMDL:","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_22":{"id":"bc22134e6633_22","__typename":"Paragraph","name":"c066","text":"Text Datasets:","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_23":{"id":"bc22134e6633_23","__typename":"Paragraph","name":"0760","text":"IMDB Dataset","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":12,"href":"http:\u002F\u002Fai.stanford.edu\u002F~amaas\u002Fdata\u002Fsentiment\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_24":{"id":"bc22134e6633_24","__typename":"Paragraph","name":"7473","text":"This dataset contains 50,000 documents with 2 categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_25":{"id":"bc22134e6633_25","__typename":"Paragraph","name":"11e0","text":"Reters-21578 Dataset","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":20,"href":"https:\u002F\u002Fkeras.io\u002Fdatasets\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_26":{"id":"bc22134e6633_26","__typename":"Paragraph","name":"6211","text":"This dataset contains 21,578 documents with 90 categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_27":{"id":"bc22134e6633_27","__typename":"Paragraph","name":"c1ef","text":"20Newsgroups Dataset","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":20,"href":"https:\u002F\u002Farchive.ics.uci.edu\u002Fml\u002Fdatasets\u002FTwenty+Newsgroups","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_28":{"id":"bc22134e6633_28","__typename":"Paragraph","name":"3914","text":"This dataset contains 20,000 documents with 20 categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_29":{"id":"bc22134e6633_29","__typename":"Paragraph","name":"be3d","text":"Web of Science Dataset (DOI: 10.17632\u002F9rw3vkcfy4.2)","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":29,"end":50,"href":"http:\u002F\u002Fdx.doi.org\u002F10.17632\u002F9rw3vkcfy4.2","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_30":{"id":"bc22134e6633_30","__typename":"Paragraph","name":"5878","text":"Web of Science Dataset WOS-11967","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":23,"end":32,"href":"http:\u002F\u002Fdx.doi.org\u002F10.17632\u002F9rw3vkcfy4.2","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_31":{"id":"bc22134e6633_31","__typename":"Paragraph","name":"0b53","text":"This dataset contains 11,967 documents with 35 categories which include 7 parents categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_32":{"id":"bc22134e6633_32","__typename":"Paragraph","name":"43e3","text":"Web of Science Dataset WOS-46985","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":23,"end":32,"href":"http:\u002F\u002Fdx.doi.org\u002F10.17632\u002F9rw3vkcfy4.2","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_33":{"id":"bc22134e6633_33","__typename":"Paragraph","name":"6752","text":"This dataset contains 46,985 documents with 134 categories which include 7 parents categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_34":{"id":"bc22134e6633_34","__typename":"Paragraph","name":"cc4c","text":"Web of Science Dataset WOS-5736","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":23,"end":31,"href":"http:\u002F\u002Fdx.doi.org\u002F10.17632\u002F9rw3vkcfy4.2","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_35":{"id":"bc22134e6633_35","__typename":"Paragraph","name":"dd45","text":"This dataset contains 5,736 documents with 11 categories which include 3 parents categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_36":{"id":"bc22134e6633_36","__typename":"Paragraph","name":"b4c6","text":"Image datasets:","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_37":{"id":"bc22134e6633_37","__typename":"Paragraph","name":"3ef3","text":"MNIST Dataset","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":13,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FMNIST_database","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_38":{"id":"bc22134e6633_38","__typename":"Paragraph","name":"9a3c","text":"The MNIST database contains 60,000 training images and 10,000 testing images.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_39":{"id":"bc22134e6633_39","__typename":"Paragraph","name":"4bf5","text":"CIFAR-10 Dataset","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":16,"href":"https:\u002F\u002Fwww.cs.toronto.edu\u002F~kriz\u002Fcifar.html","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_40":{"id":"bc22134e6633_40","__typename":"Paragraph","name":"f42c","text":"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_41":{"id":"bc22134e6633_41","__typename":"Paragraph","name":"b97b","text":"Face Recognition","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_42":{"id":"bc22134e6633_42","__typename":"Paragraph","name":"4359","text":"The Database of Faces (The Olivetti Faces Dataset)","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":50,"href":"http:\u002F\u002Fwww.cl.cam.ac.uk\u002Fresearch\u002Fdtg\u002Fattarchive\u002Ffacedatabase.html","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_43":{"id":"bc22134e6633_43","__typename":"Paragraph","name":"326d","text":"The The Database of Faces dataset consists of 400 92x112 colour images and grayscale in 40 person","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_44":{"id":"bc22134e6633_44","__typename":"Paragraph","name":"46f7","text":"Requirements for RMDL :","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_45":{"id":"bc22134e6633_45","__typename":"Paragraph","name":"5d7c","text":"General:","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_46":{"id":"bc22134e6633_46","__typename":"Paragraph","name":"ab57","text":"Python 3.5 or later see Instruction Documents","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":24,"end":45,"href":"https:\u002F\u002Fwww.python.org\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_47":{"id":"bc22134e6633_47","__typename":"Paragraph","name":"76e8","text":"TensorFlow see Instruction Documents.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":15,"end":36,"href":"https:\u002F\u002Fwww.tensorflow.org\u002Finstall\u002Finstall_linux","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_48":{"id":"bc22134e6633_48","__typename":"Paragraph","name":"fd16","text":"scikit-learn see Instruction Documents","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":17,"end":38,"href":"http:\u002F\u002Fscikit-learn.org\u002Fstable\u002Finstall.html","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_49":{"id":"bc22134e6633_49","__typename":"Paragraph","name":"8f71","text":"Keras see Instruction Documents","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":10,"end":31,"href":"https:\u002F\u002Fkeras.io\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_50":{"id":"bc22134e6633_50","__typename":"Paragraph","name":"5d39","text":"scipy see Instruction Documents","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":10,"end":31,"href":"https:\u002F\u002Fwww.scipy.org\u002Finstall.html","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_51":{"id":"bc22134e6633_51","__typename":"Paragraph","name":"0dbe","text":"GPU (if you want to run on GPU):","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_52":{"id":"bc22134e6633_52","__typename":"Paragraph","name":"2800","text":"CUDA® Toolkit 8.0. For details, see NVIDIA’s documentation.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":36,"end":58,"href":"https:\u002F\u002Fdeveloper.nvidia.com\u002Fcuda-toolkit","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_53":{"id":"bc22134e6633_53","__typename":"Paragraph","name":"e430","text":"The NVIDIA drivers associated with CUDA Toolkit 8.0.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":51,"href":"http:\u002F\u002Fwww.nvidia.com\u002FDownload\u002Findex.aspx","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_54":{"id":"bc22134e6633_54","__typename":"Paragraph","name":"b71d","text":"cuDNN v6. For details, see NVIDIA’s documentation.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":27,"end":49,"href":"https:\u002F\u002Fdeveloper.nvidia.com\u002Fcudnn","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_55":{"id":"bc22134e6633_55","__typename":"Paragraph","name":"ec46","text":"GPU card with CUDA Compute Capability 3.0 or higher.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_56":{"id":"bc22134e6633_56","__typename":"Paragraph","name":"164b","text":"The libcupti-dev library,","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_57":{"id":"bc22134e6633_57","__typename":"Paragraph","name":"f706","text":"Text and Document Classification","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_58":{"id":"bc22134e6633_58","__typename":"Paragraph","name":"1b5f","text":"Download GloVe: Global Vectors for Word Representation Instruction Documents","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":55,"end":76,"href":"https:\u002F\u002Fnlp.stanford.edu\u002Fprojects\u002Fglove\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_59":{"id":"bc22134e6633_59","__typename":"Paragraph","name":"3102","text":"Set data directory into Global.py","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":24,"end":33,"href":"https:\u002F\u002Fgithub.com\u002Fkk7nc\u002FRMDL\u002Fblob\u002Fmaster\u002Fsrc\u002FGlobal.py","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_60":{"id":"bc22134e6633_60","__typename":"Paragraph","name":"d3e8","text":"if you are not setting GloVe directory, GloVe will be downloaded","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_61":{"id":"bc22134e6633_61","__typename":"Paragraph","name":"284b","text":"Parameters:","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_62":{"id":"bc22134e6633_62","__typename":"Paragraph","name":"c306","text":"Text_Classification","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_63":{"id":"bc22134e6633_63","__typename":"Paragraph","name":"daa5","text":"from RMDL import RMDL_Text","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_64":{"id":"bc22134e6633_64","__typename":"Paragraph","name":"f548","text":"Text_Classification(x_train, y_train, x_test,  y_test, batch_size=128,\n                 EMBEDDING_DIM=50,MAX_SEQUENCE_LENGTH = 500, MAX_NB_WORDS = 75000,\n                 GloVe_dir=\"\", GloVe_file = \"glove.6B.50d.txt\",\n                 sparse_categorical=True, random_deep=[3, 3, 3], epochs=[500, 500, 500],  plot=True,\n                 min_hidden_layer_dnn=1, max_hidden_layer_dnn=8, min_nodes_dnn=128, max_nodes_dnn=1024,\n                 min_hidden_layer_rnn=1, max_hidden_layer_rnn=5, min_nodes_rnn=32,  max_nodes_rnn=128,\n                 min_hidden_layer_cnn=3, max_hidden_layer_cnn=10, min_nodes_cnn=128, max_nodes_cnn=512,\n                 random_state=42, random_optimizor=True, dropout=0.05):","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_65":{"id":"bc22134e6633_65","__typename":"Paragraph","name":"e89e","text":"Input","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_66":{"id":"bc22134e6633_66","__typename":"Paragraph","name":"a59f","text":"x_train","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_67":{"id":"bc22134e6633_67","__typename":"Paragraph","name":"3d1c","text":"y_train","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_68":{"id":"bc22134e6633_68","__typename":"Paragraph","name":"f903","text":"x_test","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_69":{"id":"bc22134e6633_69","__typename":"Paragraph","name":"4122","text":"y_test","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_70":{"id":"bc22134e6633_70","__typename":"Paragraph","name":"9373","text":"batch_size","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_71":{"id":"bc22134e6633_71","__typename":"Paragraph","name":"467c","text":"batch_size: Integer. The number of samples per gradient update. If unspecified, it will default to 128.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_72":{"id":"bc22134e6633_72","__typename":"Paragraph","name":"04ab","text":"EMBEDDING_DIM","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_73":{"id":"bc22134e6633_73","__typename":"Paragraph","name":"efd7","text":"batch_size: Integer. The shape of word embedding (this number should be same with GloVe or other pre-trained embedding techniques that be used), it will default to 50 that used with the pain of glove.6B.50d.txt file.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_74":{"id":"bc22134e6633_74","__typename":"Paragraph","name":"033f","text":"MAX_SEQUENCE_LENGTH","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_75":{"id":"bc22134e6633_75","__typename":"Paragraph","name":"8169","text":"MAX_SEQUENCE_LENGTH: Integer. The maximum length of sequence or document in datasets, it will default to 500.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_76":{"id":"bc22134e6633_76","__typename":"Paragraph","name":"e63c","text":"MAX_NB_WORDS","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_77":{"id":"bc22134e6633_77","__typename":"Paragraph","name":"625b","text":"MAX_NB_WORDS: Integer. The maximum number of unique words in datasets, it will default to 75000.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_78":{"id":"bc22134e6633_78","__typename":"Paragraph","name":"86fe","text":"GloVe_dir","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_79":{"id":"bc22134e6633_79","__typename":"Paragraph","name":"1551","text":"GloVe_dir: String. Address of GloVe or any pre-trained directory, it will default to null which glove.6B.zip will be download.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_80":{"id":"bc22134e6633_80","__typename":"Paragraph","name":"b465","text":"GloVe_file","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_81":{"id":"bc22134e6633_81","__typename":"Paragraph","name":"e711","text":"GloVe_dir: String. Which version of GloVe or pre-trained word emending will be used, it will default to glove.6B.50d.txt.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_82":{"id":"bc22134e6633_82","__typename":"Paragraph","name":"f6be","text":"NOTE: if you use another version of GloVe EMBEDDING_DIM must be the same dimensions.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_83":{"id":"bc22134e6633_83","__typename":"Paragraph","name":"91b2","text":"sparse_categorical","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_84":{"id":"bc22134e6633_84","__typename":"Paragraph","name":"6b84","text":"sparse_categorical: bool. When target’s dataset is (n,1) should be True, it will default to True.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_85":{"id":"bc22134e6633_85","__typename":"Paragraph","name":"b4bf","text":"random_deep","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_86":{"id":"bc22134e6633_86","__typename":"Paragraph","name":"074c","text":"random_deep: Integer [3]. Number of ensembled model used in RMDL random_deep[0] is number of DNN, random_deep[1] is number of RNN, random_deep[0] is number of CNN, it will default to [3, 3, 3].","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_87":{"id":"bc22134e6633_87","__typename":"Paragraph","name":"b7d1","text":"epochs","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_88":{"id":"bc22134e6633_88","__typename":"Paragraph","name":"95d3","text":"epochs: Integer [3]. Number of epochs in each ensembled model used in RMDL epochs[0] is number of epochs used in DNN, epochs[1] is number of epochs used in RNN, epochs[0] is number of epochs used in CNN, it will default to [500, 500, 500].","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_89":{"id":"bc22134e6633_89","__typename":"Paragraph","name":"4dab","text":"plot","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_90":{"id":"bc22134e6633_90","__typename":"Paragraph","name":"2c0b","text":"plot: bool. True: shows confusion matrix and accuracy and loss","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_91":{"id":"bc22134e6633_91","__typename":"Paragraph","name":"f354","text":"min_hidden_layer_dnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_92":{"id":"bc22134e6633_92","__typename":"Paragraph","name":"555b","text":"min_hidden_layer_dnn: Integer. Lower Bounds of hidden layers of DNN used in RMDL, it will default to 1.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_93":{"id":"bc22134e6633_93","__typename":"Paragraph","name":"33c8","text":"max_hidden_layer_dnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_94":{"id":"bc22134e6633_94","__typename":"Paragraph","name":"2d96","text":"max_hidden_layer_dnn: Integer. Upper bounds of hidden layers of DNN used in RMDL, it will default to 8.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_95":{"id":"bc22134e6633_95","__typename":"Paragraph","name":"e882","text":"min_nodes_dnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_96":{"id":"bc22134e6633_96","__typename":"Paragraph","name":"500a","text":"min_nodes_dnn: Integer. Lower bounds of nodes in each layer of DNN used in RMDL, it will default to 128.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_97":{"id":"bc22134e6633_97","__typename":"Paragraph","name":"0660","text":"max_nodes_dnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_98":{"id":"bc22134e6633_98","__typename":"Paragraph","name":"c176","text":"max_nodes_dnn: Integer. Upper bounds of nodes in each layer of DNN used in RMDL, it will default to 1024.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_99":{"id":"bc22134e6633_99","__typename":"Paragraph","name":"b96b","text":"min_hidden_layer_rnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_100":{"id":"bc22134e6633_100","__typename":"Paragraph","name":"e163","text":"min_hidden_layer_rnn: Integer. Lower Bounds of hidden layers of RNN used in RMDL, it will default to 1.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_101":{"id":"bc22134e6633_101","__typename":"Paragraph","name":"8442","text":"max_hidden_layer_rnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_102":{"id":"bc22134e6633_102","__typename":"Paragraph","name":"1a40","text":"man_hidden_layer_rnn: Integer. Upper Bounds of hidden layers of RNN used in RMDL, it will default to 5.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_103":{"id":"bc22134e6633_103","__typename":"Paragraph","name":"a017","text":"min_nodes_rnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_104":{"id":"bc22134e6633_104","__typename":"Paragraph","name":"401e","text":"min_nodes_rnn: Integer. Lower bounds of nodes (LSTM or GRU) in each layer of RNN used in RMDL, it will default to 32.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_105":{"id":"bc22134e6633_105","__typename":"Paragraph","name":"531b","text":"max_nodes_rnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_106":{"id":"bc22134e6633_106","__typename":"Paragraph","name":"edd0","text":"max_nodes_rnn: Integer. Upper bounds of nodes (LSTM or GRU) in each layer of RNN used in RMDL, it will default to 128.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_107":{"id":"bc22134e6633_107","__typename":"Paragraph","name":"d3af","text":"min_hidden_layer_cnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_108":{"id":"bc22134e6633_108","__typename":"Paragraph","name":"d49a","text":"min_hidden_layer_cnn: Integer. Lower Bounds of hidden layers of CNN used in RMDL, it will default to 3.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_109":{"id":"bc22134e6633_109","__typename":"Paragraph","name":"837d","text":"max_hidden_layer_cnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_110":{"id":"bc22134e6633_110","__typename":"Paragraph","name":"3ad4","text":"max_hidden_layer_cnn: Integer. Upper Bounds of hidden layers of CNN used in RMDL, it will default to 10.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_111":{"id":"bc22134e6633_111","__typename":"Paragraph","name":"186f","text":"min_nodes_cnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_112":{"id":"bc22134e6633_112","__typename":"Paragraph","name":"5b29","text":"min_nodes_cnn: Integer. Lower bounds of nodes (2D convolution layer) in each layer of CNN used in RMDL, it will default to 128.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_113":{"id":"bc22134e6633_113","__typename":"Paragraph","name":"1d62","text":"max_nodes_cnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_114":{"id":"bc22134e6633_114","__typename":"Paragraph","name":"4102","text":"min_nodes_cnn: Integer. Upper bounds of nodes (2D convolution layer) in each layer of CNN used in RMDL, it will default to 512.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_115":{"id":"bc22134e6633_115","__typename":"Paragraph","name":"c91a","text":"random_state","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_116":{"id":"bc22134e6633_116","__typename":"Paragraph","name":"d085","text":"random_state : Integer, RandomState instance or None, optional (default=None)","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_117":{"id":"bc22134e6633_117","__typename":"Paragraph","name":"0ed0","text":"If Integer, random_state is the seed used by the random number generator;","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_118":{"id":"bc22134e6633_118","__typename":"Paragraph","name":"cda2","text":"random_optimizor","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_119":{"id":"bc22134e6633_119","__typename":"Paragraph","name":"e4f3","text":"random_optimizor : bool, If False, all models use adam optimizer. If True, all models use random optimizers. it will default to True","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_120":{"id":"bc22134e6633_120","__typename":"Paragraph","name":"570d","text":"dropout","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_121":{"id":"bc22134e6633_121","__typename":"Paragraph","name":"1bbc","text":"dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_122":{"id":"bc22134e6633_122","__typename":"Paragraph","name":"8704","text":"Image_Classification","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_123":{"id":"bc22134e6633_123","__typename":"Paragraph","name":"276a","text":"from RMDL import RMDL_Image","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_124":{"id":"bc22134e6633_124","__typename":"Paragraph","name":"7acb","text":"Image_Classification(x_train, y_train, x_test, y_test, shape, batch_size=128,\n                         sparse_categorical=True, random_deep=[3, 3, 3], epochs=[500, 500, 500], plot=True,\n                         min_hidden_layer_dnn=1, max_hidden_layer_dnn=8, min_nodes_dnn=128, max_nodes_dnn=1024,\n                         min_hidden_layer_rnn=1, max_hidden_layer_rnn=5, min_nodes_rnn=32, max_nodes_rnn=128,\n                         min_hidden_layer_cnn=3, max_hidden_layer_cnn=10, min_nodes_cnn=128, max_nodes_cnn=512,\n                         random_state=42, random_optimizor=True, dropout=0.05)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_125":{"id":"bc22134e6633_125","__typename":"Paragraph","name":"807c","text":"Input","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_126":{"id":"bc22134e6633_126","__typename":"Paragraph","name":"f4eb","text":"x_train","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_127":{"id":"bc22134e6633_127","__typename":"Paragraph","name":"f2b1","text":"y_train","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_128":{"id":"bc22134e6633_128","__typename":"Paragraph","name":"a50c","text":"x_test","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_129":{"id":"bc22134e6633_129","__typename":"Paragraph","name":"4df7","text":"y_test","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_130":{"id":"bc22134e6633_130","__typename":"Paragraph","name":"5eed","text":"shape","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_131":{"id":"bc22134e6633_131","__typename":"Paragraph","name":"a3bb","text":"shape: np.shape . shape of image. The most common situation would be a 2D input with shape (batch_size, input_dim).","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_132":{"id":"bc22134e6633_132","__typename":"Paragraph","name":"465a","text":"batch_size","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_133":{"id":"bc22134e6633_133","__typename":"Paragraph","name":"3dcc","text":"batch_size: Integer. Number of samples per gradient update. If unspecified, it will default to 128.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_134":{"id":"bc22134e6633_134","__typename":"Paragraph","name":"8f40","text":"sparse_categorical","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_135":{"id":"bc22134e6633_135","__typename":"Paragraph","name":"4189","text":"sparse_categorical: bool. When target’s dataset is (n,1) should be True, it will default to True.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_136":{"id":"bc22134e6633_136","__typename":"Paragraph","name":"303b","text":"random_deep","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_137":{"id":"bc22134e6633_137","__typename":"Paragraph","name":"15a3","text":"random_deep: Integer [3]. Number of ensembled model used in RMDL random_deep[0] is number of DNN, random_deep[1] is number of RNN, random_deep[0] is number of CNN, it will default to [3, 3, 3].","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_138":{"id":"bc22134e6633_138","__typename":"Paragraph","name":"71bf","text":"epochs","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_139":{"id":"bc22134e6633_139","__typename":"Paragraph","name":"4bda","text":"epochs: Integer [3]. Number of epochs in each ensembled model used in RMDL epochs[0] is number of epochs used in DNN, epochs[1] is number of epochs used in RNN, epochs[0] is number of epochs used in CNN, it will default to [500, 500, 500].","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_140":{"id":"bc22134e6633_140","__typename":"Paragraph","name":"9c79","text":"plot","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_141":{"id":"bc22134e6633_141","__typename":"Paragraph","name":"df9f","text":"plot: bool. True: shows confusion matrix and accuracy and loss","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_142":{"id":"bc22134e6633_142","__typename":"Paragraph","name":"e51c","text":"min_hidden_layer_dnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_143":{"id":"bc22134e6633_143","__typename":"Paragraph","name":"96d3","text":"min_hidden_layer_dnn: Integer. Lower Bounds of hidden layers of DNN used in RMDL, it will default to 1.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_144":{"id":"bc22134e6633_144","__typename":"Paragraph","name":"dea1","text":"max_hidden_layer_dnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_145":{"id":"bc22134e6633_145","__typename":"Paragraph","name":"42ab","text":"max_hidden_layer_dnn: Integer. Upper bounds of hidden layers of DNN used in RMDL, it will default to 8.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_146":{"id":"bc22134e6633_146","__typename":"Paragraph","name":"0c2a","text":"min_nodes_dnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_147":{"id":"bc22134e6633_147","__typename":"Paragraph","name":"9571","text":"min_nodes_dnn: Integer. Lower bounds of nodes in each layer of DNN used in RMDL, it will default to 128.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_148":{"id":"bc22134e6633_148","__typename":"Paragraph","name":"77ce","text":"max_nodes_dnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_149":{"id":"bc22134e6633_149","__typename":"Paragraph","name":"c032","text":"max_nodes_dnn: Integer. Upper bounds of nodes in each layer of DNN used in RMDL, it will default to 1024.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_150":{"id":"bc22134e6633_150","__typename":"Paragraph","name":"30dc","text":"min_nodes_rnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_151":{"id":"bc22134e6633_151","__typename":"Paragraph","name":"890a","text":"min_nodes_rnn: Integer. Lower bounds of nodes (LSTM or GRU) in each layer of RNN used in RMDL, it will default to 32.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_152":{"id":"bc22134e6633_152","__typename":"Paragraph","name":"f762","text":"max_nodes_rnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_153":{"id":"bc22134e6633_153","__typename":"Paragraph","name":"e0f0","text":"maz_nodes_rnn: Integer. Upper bounds of nodes (LSTM or GRU) in each layer of RNN used in RMDL, it will default to 128.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_154":{"id":"bc22134e6633_154","__typename":"Paragraph","name":"0339","text":"min_hidden_layer_cnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_155":{"id":"bc22134e6633_155","__typename":"Paragraph","name":"18ea","text":"min_hidden_layer_cnn: Integer. Lower Bounds of hidden layers of CNN used in RMDL, it will default to 3.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_156":{"id":"bc22134e6633_156","__typename":"Paragraph","name":"2bb3","text":"max_hidden_layer_cnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_157":{"id":"bc22134e6633_157","__typename":"Paragraph","name":"c9e2","text":"max_hidden_layer_cnn: Integer. Upper Bounds of hidden layers of CNN used in RMDL, it will default to 10.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_158":{"id":"bc22134e6633_158","__typename":"Paragraph","name":"cefd","text":"min_nodes_cnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_159":{"id":"bc22134e6633_159","__typename":"Paragraph","name":"d156","text":"min_nodes_cnn: Integer. Lower bounds of nodes (2D convolution layer) in each layer of CNN used in RMDL, it will default to 128.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_160":{"id":"bc22134e6633_160","__typename":"Paragraph","name":"6bba","text":"max_nodes_cnn","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_161":{"id":"bc22134e6633_161","__typename":"Paragraph","name":"612b","text":"min_nodes_cnn: Integer. Upper bounds of nodes (2D convolution layer) in each layer of CNN used in RMDL, it will default to 512.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_162":{"id":"bc22134e6633_162","__typename":"Paragraph","name":"30fb","text":"random_state","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_163":{"id":"bc22134e6633_163","__typename":"Paragraph","name":"2fca","text":"random_state : Integer, RandomState instance or None, optional (default=None)","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_164":{"id":"bc22134e6633_164","__typename":"Paragraph","name":"dc7f","text":"If Integer, random_state is the seed used by the random number generator;","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_165":{"id":"bc22134e6633_165","__typename":"Paragraph","name":"f53b","text":"random_optimizor","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_166":{"id":"bc22134e6633_166","__typename":"Paragraph","name":"3a9a","text":"random_optimizor : bool, If False, all models use adam optimizer. If True, all models use random optimizers. it will default to True","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_167":{"id":"bc22134e6633_167","__typename":"Paragraph","name":"f761","text":"dropout","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_168":{"id":"bc22134e6633_168","__typename":"Paragraph","name":"dfcc","text":"dropout: Float between 0 and 1. A fraction of the units to drop for the linear transformation of the inputs.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_169":{"id":"bc22134e6633_169","__typename":"Paragraph","name":"36f6","text":"Example","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_170":{"id":"bc22134e6633_170","__typename":"Paragraph","name":"18fe","text":"MNIST","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_171":{"id":"bc22134e6633_171","__typename":"Paragraph","name":"1dcf","text":"The MNIST database contains 60,000 training images and 10,000 testing images.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_172":{"id":"bc22134e6633_172","__typename":"Paragraph","name":"77f0","text":"Import Packages","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_173":{"id":"bc22134e6633_173","__typename":"Paragraph","name":"75c7","text":"from keras.datasets import mnist\nimport numpy as np\nfrom RMDL import RMDL_Image as RMDL","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_174":{"id":"bc22134e6633_174","__typename":"Paragraph","name":"8cdb","text":"Load Data","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_175":{"id":"bc22134e6633_175","__typename":"Paragraph","name":"00bf","text":"(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train_D = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\nX_test_D = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\nX_train = X_train_D \u002F 255.0\nX_test = X_test_D \u002F 255.0\nnumber_of_classes = np.unique(y_train).shape[0]\nshape = (28, 28, 1)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_176":{"id":"bc22134e6633_176","__typename":"Paragraph","name":"016f","text":"Using RMDL","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_177":{"id":"bc22134e6633_177","__typename":"Paragraph","name":"e05a","text":"batch_size = 128\nsparse_categorical = 0\nn_epochs = [100, 100, 100]  ## DNN-RNN-CNN\nRandom_Deep = [3, 3, 3]  ## DNN-RNN-CNN","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_178":{"id":"bc22134e6633_178","__typename":"Paragraph","name":"9993","text":"RMDL.Image_Classification(X_train, y_train, X_test, y_test,shape,\n                     batch_size=batch_size,\n                     sparse_categorical=True,\n                     random_deep=Random_Deep,\n                     epochs=n_epochs)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_179":{"id":"bc22134e6633_179","__typename":"Paragraph","name":"9371","text":"IMDB","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_180":{"id":"bc22134e6633_180","__typename":"Paragraph","name":"3a8e","text":"This dataset contains 50,000 documents with 2 categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_181":{"id":"bc22134e6633_181","__typename":"Paragraph","name":"0ef8","text":"Import Packages","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_182":{"id":"bc22134e6633_182","__typename":"Paragraph","name":"38f2","text":"import sys\nimport os\nfrom RMDL import text_feature_extraction as txt\nfrom keras.datasets import imdb\nimport numpy as np\nfrom RMDL import RMDL_Text as RMDL","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_183":{"id":"bc22134e6633_183","__typename":"Paragraph","name":"0131","text":"Load Data","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_184":{"id":"bc22134e6633_184","__typename":"Paragraph","name":"756a","text":"print(\"Load IMDB dataset....\")\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=MAX_NB_WORDS)\nprint(len(X_train))\nprint(y_test)\nword_index = imdb.get_word_index()\nindex_word = {v: k for k, v in word_index.items()}\nX_train = [txt.text_cleaner(' '.join(index_word.get(w) for w in x)) for x in X_train]\nX_test = [txt.text_cleaner(' '.join(index_word.get(w) for w in x)) for x in X_test]\nX_train = np.array(X_train)\nX_train = np.array(X_train).ravel()\nprint(X_train.shape)\nX_test = np.array(X_test)\nX_test = np.array(X_test).ravel()","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_185":{"id":"bc22134e6633_185","__typename":"Paragraph","name":"3957","text":"Using RMDL","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_186":{"id":"bc22134e6633_186","__typename":"Paragraph","name":"ffc8","text":"batch_size = 100\nsparse_categorical = 0\nn_epochs = [100, 100, 100]  ## DNN--RNN-CNN\nRandom_Deep = [3, 3, 3]  ## DNN--RNN-CNN","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_187":{"id":"bc22134e6633_187","__typename":"Paragraph","name":"bed7","text":"RMDL.Text_Classification(X_train, y_train, X_test, y_test,\n                     batch_size=batch_size,\n                     sparse_categorical=sparse_categorical,\n                     random_deep=Random_Deep,\n                     epochs=n_epochs)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_188":{"id":"bc22134e6633_188","__typename":"Paragraph","name":"e282","text":"Web Of Science","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_189":{"id":"bc22134e6633_189","__typename":"Paragraph","name":"f76f","text":"Linke of the dataset:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_190":{"id":"bc22134e6633_190","__typename":"Paragraph","name":"cca7","text":"Web of Science Dataset WOS-11967","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":23,"end":32,"href":"http:\u002F\u002Fdx.doi.org\u002F10.17632\u002F9rw3vkcfy4.2","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_191":{"id":"bc22134e6633_191","__typename":"Paragraph","name":"3d58","text":"This dataset contains 11,967 documents with 35 categories which include 7 parents categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_192":{"id":"bc22134e6633_192","__typename":"Paragraph","name":"8bfc","text":"Web of Science Dataset WOS-46985","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":23,"end":32,"href":"http:\u002F\u002Fdx.doi.org\u002F10.17632\u002F9rw3vkcfy4.2","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_193":{"id":"bc22134e6633_193","__typename":"Paragraph","name":"74f1","text":"This dataset contains 46,985 documents with 134 categories which include 7 parents categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_194":{"id":"bc22134e6633_194","__typename":"Paragraph","name":"3d55","text":"Web of Science Dataset WOS-5736","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":23,"end":31,"href":"http:\u002F\u002Fdx.doi.org\u002F10.17632\u002F9rw3vkcfy4.2","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_195":{"id":"bc22134e6633_195","__typename":"Paragraph","name":"ebdc","text":"This dataset contains 5,736 documents with 11 categories which include 3 parents categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_196":{"id":"bc22134e6633_196","__typename":"Paragraph","name":"2243","text":"Import Packages","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_197":{"id":"bc22134e6633_197","__typename":"Paragraph","name":"faab","text":"from RMDL import text_feature_extraction as txt\nfrom sklearn.model_selection import train_test_split\nfrom RMDL.Download import Download_WOS as WOS\nimport numpy as np\nfrom RMDL import RMDL_Text as RMDL","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_198":{"id":"bc22134e6633_198","__typename":"Paragraph","name":"af93","text":"Load Data","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_199":{"id":"bc22134e6633_199","__typename":"Paragraph","name":"1bd9","text":"path_WOS = WOS.download_and_extract()\nfname = os.path.join(path_WOS,\"WebOfScience\u002FWOS11967\u002FX.txt\")\nfnamek = os.path.join(path_WOS,\"WebOfScience\u002FWOS11967\u002FY.txt\")\nwith open(fname, encoding=\"utf-8\") as f:\n    content = f.readlines()\n    content = [txt.text_cleaner(x) for x in content]\nwith open(fnamek) as fk:\n    contentk = fk.readlines()\ncontentk = [x.strip() for x in contentk]\nLabel = np.matrix(contentk, dtype=int)\nLabel = np.transpose(Label)\nnp.random.seed(7)\nprint(Label.shape)\nX_train, X_test, y_train, y_test = train_test_split(content, Label, test_size=0.2, random_state=4)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_200":{"id":"bc22134e6633_200","__typename":"Paragraph","name":"fb06","text":"Using RMDL","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_201":{"id":"bc22134e6633_201","__typename":"Paragraph","name":"3229","text":"batch_size = 100\nsparse_categorical = 0\nn_epochs = [5000, 500, 500]  ## DNN--RNN-CNN\nRandom_Deep = [3, 3, 3]  ## DNN--RNN-CNN","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_202":{"id":"bc22134e6633_202","__typename":"Paragraph","name":"8af4","text":"RMDL.Text_Classification(X_train, y_train, X_test, y_test,\n                     batch_size=batch_size,\n                     sparse_categorical=True,\n                     random_deep=Random_Deep,\n                     epochs=n_epochs,no_of_classes=12)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_203":{"id":"bc22134e6633_203","__typename":"Paragraph","name":"4629","text":"Reuters-21578","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_204":{"id":"bc22134e6633_204","__typename":"Paragraph","name":"4aa6","text":"This dataset contains 21,578 documents with 90 categories.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_205":{"id":"bc22134e6633_205","__typename":"Paragraph","name":"b407","text":"Import Packages","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_206":{"id":"bc22134e6633_206","__typename":"Paragraph","name":"1635","text":"import sys\nimport os\nimport nltk\nnltk.download(\"reuters\")\nfrom nltk.corpus import reuters\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport numpy as np\nfrom RMDL import RMDL_Text as RMDL","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_207":{"id":"bc22134e6633_207","__typename":"Paragraph","name":"3eb1","text":"Load Data","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_208":{"id":"bc22134e6633_208","__typename":"Paragraph","name":"61fb","text":"documents = reuters.fileids()","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_209":{"id":"bc22134e6633_209","__typename":"Paragraph","name":"3752","text":"train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n                          documents))\ntest_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),\n                         documents))\nX_train = [(reuters.raw(doc_id)) for doc_id in train_docs_id]\nX_test = [(reuters.raw(doc_id)) for doc_id in test_docs_id]\nmlb = MultiLabelBinarizer()\ny_train = mlb.fit_transform([reuters.categories(doc_id)\n                           for doc_id in train_docs_id])\ny_test = mlb.transform([reuters.categories(doc_id)\n                      for doc_id in test_docs_id])\ny_train = np.argmax(y_train, axis=1)\ny_test = np.argmax(y_test, axis=1)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_210":{"id":"bc22134e6633_210","__typename":"Paragraph","name":"2523","text":"Using RMDL","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_211":{"id":"bc22134e6633_211","__typename":"Paragraph","name":"3685","text":"batch_size = 100\nsparse_categorical = 0\nn_epochs = [20, 500, 50]  ## DNN--RNN-CNN\nRandom_Deep = [3, 0, 0]  ## DNN--RNN-CNN","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_212":{"id":"bc22134e6633_212","__typename":"Paragraph","name":"e027","text":"RMDL.Text_Classification(X_train, y_train, X_test, y_test,\n             batch_size=batch_size,\n             sparse_categorical=True,\n             random_deep=Random_Deep,\n             epochs=n_epochs)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_213":{"id":"bc22134e6633_213","__typename":"Paragraph","name":"4da0","text":"Olivetti Faces","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_214":{"id":"bc22134e6633_214","__typename":"Paragraph","name":"6cba","text":"There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open \u002F closed eyes, smiling \u002F not smiling) and facial details (glasses \u002F no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_215":{"id":"bc22134e6633_215","__typename":"Paragraph","name":"5d9b","text":"Import Packages","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_216":{"id":"bc22134e6633_216","__typename":"Paragraph","name":"1108","text":"from sklearn.datasets import fetch_olivetti_faces\nfrom sklearn.model_selection import train_test_split\nfrom RMDL import RMDL_Image as RMDL","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_217":{"id":"bc22134e6633_217","__typename":"Paragraph","name":"fdf1","text":"Load Data","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_218":{"id":"bc22134e6633_218","__typename":"Paragraph","name":"8c07","text":"number_of_classes = 40\nshape = (64, 64, 1)\ndata = fetch_olivetti_faces()\nX_train, X_test, y_train, y_test = train_test_split(data.data,\n                                              data.target, stratify=data.target, test_size=40)\nX_train = X_train.reshape(X_train.shape[0], 64, 64, 1).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 64, 64, 1).astype('float32')","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_219":{"id":"bc22134e6633_219","__typename":"Paragraph","name":"4912","text":"Using RMDL","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_220":{"id":"bc22134e6633_220","__typename":"Paragraph","name":"7a64","text":"batch_size = 100\nsparse_categorical = 0\nn_epochs = [500, 500, 50]  ## DNN--RNN-CNN\nRandom_Deep = [0, 0, 1]  ## DNN--RNN-CNN","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_221":{"id":"bc22134e6633_221","__typename":"Paragraph","name":"914d","text":"RMDL.Image_Classification(X_train, y_train, X_test, y_test,\n                      shape,\n                      random_optimizor=False,\n                      batch_size=batch_size,\n                      random_deep=Random_Deep,\n                      epochs=n_epochs)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_222":{"id":"bc22134e6633_222","__typename":"Paragraph","name":"e1cf","text":"More Example link","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":13,"end":17,"href":"https:\u002F\u002Fgithub.com\u002Fkk7nc\u002FRMDL\u002Ftree\u002Fmaster\u002FExamples","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_223":{"id":"bc22134e6633_223","__typename":"Paragraph","name":"1563","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*gAoqpsfQrqSE2C87"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_224":{"id":"bc22134e6633_224","__typename":"Paragraph","name":"0932","text":"Error and Comments:","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_225":{"id":"bc22134e6633_225","__typename":"Paragraph","name":"c69b","text":"Send an email to kk7nc@virginia.edu","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":17,"end":35,"href":"mailto:kk7nc@virginia.edu","anchorType":"LINK","userId":null,"linkMetadata":null}]},"Paragraph:bc22134e6633_226":{"id":"bc22134e6633_226","__typename":"Paragraph","name":"5eec","text":"Citations","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_227":{"id":"bc22134e6633_227","__typename":"Paragraph","name":"8d6b","text":"@inproceedings{Kowsari2018RMDL,\n     author = {Kowsari, Kamran and Heidarysafa, Mojtaba and Brown, Donald E. and Meimandi, Kiana Jafari and Barnes, Laura E.},\n     title = {RMDL: Random Multimodel Deep Learning for Classification},\n     booktitle = {Proceedings of the 2Nd International Conference on Information System and Data Mining},\n     series = {ICISDM '18},\n     year = {2018},\n     isbn = {978-1-4503-6354-9},\n     location = {Lakeland, FL, USA},\n     pages = {19--28},\n     numpages = {10},\n     url = {http:\u002F\u002Fdoi.acm.org\u002F10.1145\u002F3206098.3206111},\n     doi = {10.1145\u002F3206098.3206111},\n     acmid = {3206111},\n     publisher = {ACM},\n     address = {New York, NY, USA},\n     keywords = {Data Mining, Deep Learning, Deep Neural Networks, Image Classification, Supervised Learning, Text Classification},\n    }","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_228":{"id":"bc22134e6633_228","__typename":"Paragraph","name":"dc74","text":"and","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"Paragraph:bc22134e6633_229":{"id":"bc22134e6633_229","__typename":"Paragraph","name":"40e6","text":"@article{Heidarysafa2018RMDL,\ntitle={An Improvement of Data Classification Using Random Multimodel Deep Learning (RMDL)},\nauthor={Heidarysafa, Mojtaba and Kowsari, Kamran and Brown, Donald E. and Jafari Meimandi, Kiana and Barnes, Laura E.},\nbooktitle={International Journal of Machine Learning and Computing (IJMLC)},\nyear={2018},\nVolume={8},\nNumber={4},\npages={298--310},\nDOI={https:\u002F\u002Fdoi.org\u002F10.18178\u002Fijmlc.2018.8.4.703}\n}","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"dropCapImage":null,"markups":[]},"ImageMetadata:0*jRwJaYk_Wvc3jGKw":{"id":"0*jRwJaYk_Wvc3jGKw","__typename":"ImageMetadata","originalHeight":644,"originalWidth":1143,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:0*gAoqpsfQrqSE2C87":{"id":"0*gAoqpsfQrqSE2C87","__typename":"ImageMetadata","originalHeight":756,"originalWidth":1923,"focusPercentX":null,"focusPercentY":null,"alt":null},"Tag:machine-learning":{"id":"machine-learning","__typename":"Tag"},"Tag:classification":{"id":"classification","__typename":"Tag"},"Tag:ensemble-learning":{"id":"ensemble-learning","__typename":"Tag"},"ImageMetadata:1*z053dgJU52BvUezXMob2Aw.png":{"id":"1*z053dgJU52BvUezXMob2Aw.png","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:6a5941a17d08":{"id":"6a5941a17d08","__typename":"User","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"yolandamabusela.medium.com"}},"hasSubdomain":true,"username":"yolandamabusela"},"Post:668444b1535d":{"id":"668444b1535d","__typename":"Post","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Ideally i wanted to do sentiment analysis using the twitter api then i realized i have to start by creating a twitter developer account…"},"collection":null,"title":"Sentiment Analysis using Te","mediumUrl":"https:\u002F\u002Fyolandamabusela.medium.com\u002Fsentiment-analysis-using-te-668444b1535d","primaryTopic":null,"previewImage":{"__ref":"ImageMetadata:1*z053dgJU52BvUezXMob2Aw.png"},"clapCount":0,"creator":{"__ref":"User:6a5941a17d08"},"isSeries":false,"sequence":null,"uniqueSlug":"sentiment-analysis-using-te-668444b1535d"},"Collection:7f60cf5620c9":{"id":"7f60cf5620c9","__typename":"Collection","slug":"towards-data-science","name":"Towards Data Science","domain":"towardsdatascience.com"},"ImageMetadata:1*8dO-lbHRDAfiuz3_obpFmQ.png":{"id":"1*8dO-lbHRDAfiuz3_obpFmQ.png","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:7e12c71dfa81":{"id":"7e12c71dfa81","__typename":"User","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"towardsdatascience.medium.com"}},"hasSubdomain":true,"username":"towardsdatascience"},"Post:7be2a4e7e689":{"id":"7be2a4e7e689","__typename":"Post","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Build Apps Powered by Language with Semantic ML"},"collection":{"__ref":"Collection:7f60cf5620c9"},"title":"Using semantic ML to build apps powered by language","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fusing-semantic-ml-to-build-apps-powered-by-language-7be2a4e7e689","primaryTopic":null,"previewImage":{"__ref":"ImageMetadata:1*8dO-lbHRDAfiuz3_obpFmQ.png"},"clapCount":4,"creator":{"__ref":"User:7e12c71dfa81"},"isSeries":false,"sequence":null,"uniqueSlug":"using-semantic-ml-to-build-apps-powered-by-language-7be2a4e7e689"},"ImageMetadata:0*T1aiN4aWXkaNnvdC":{"id":"0*T1aiN4aWXkaNnvdC","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:b7ab2b7564b0":{"id":"b7ab2b7564b0","__typename":"User","customDomainState":null,"hasSubdomain":false,"username":"raywang1237"},"Post:fcb98ff16d68":{"id":"fcb98ff16d68","__typename":"Post","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"A state of the art real-time object detection algorithm"},"collection":null,"title":"YOLO — You Only Look Once","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@raywang1237\u002Fyolo-you-only-look-once-fcb98ff16d68","primaryTopic":{"__ref":"Topic:1eca0103fff3"},"previewImage":{"__ref":"ImageMetadata:0*T1aiN4aWXkaNnvdC"},"clapCount":55,"creator":{"__ref":"User:b7ab2b7564b0"},"isSeries":false,"sequence":null,"uniqueSlug":"yolo-you-only-look-once-fcb98ff16d68"},"Collection:7219b4dc6c4c":{"id":"7219b4dc6c4c","__typename":"Collection","slug":"analytics-vidhya","name":"Analytics Vidhya","domain":null},"ImageMetadata:1*I-KaPdjYYVFezJh2dzn_Qg.jpeg":{"id":"1*I-KaPdjYYVFezJh2dzn_Qg.jpeg","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:a8dc77209ef3":{"id":"a8dc77209ef3","__typename":"User","customDomainState":null,"hasSubdomain":false,"username":"s.kirmer"},"Post:6ff64963e685":{"id":"6ff64963e685","__typename":"Post","visibility":"LOCKED","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Introducing a new Python package: dask-pytorch-ddp!"},"collection":{"__ref":"Collection:7219b4dc6c4c"},"title":"Combining Dask and PyTorch for Better, Faster Transfer Learning","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fanalytics-vidhya\u002Fcombining-dask-and-pytorch-for-better-faster-transfer-learning-6ff64963e685","primaryTopic":null,"previewImage":{"__ref":"ImageMetadata:1*I-KaPdjYYVFezJh2dzn_Qg.jpeg"},"clapCount":51,"creator":{"__ref":"User:a8dc77209ef3"},"isSeries":false,"sequence":null,"uniqueSlug":"combining-dask-and-pytorch-for-better-faster-transfer-learning-6ff64963e685"},"Collection:95668a57d3dd":{"id":"95668a57d3dd","__typename":"Collection","slug":"takeaway-chuck","name":"Takeaway-chuck","domain":null},"ImageMetadata:":{"id":"","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:a4280b6f29b4":{"id":"a4280b6f29b4","__typename":"User","customDomainState":null,"hasSubdomain":false,"username":"prahaladbelavadi"},"Post:586861c8ae12":{"id":"586861c8ae12","__typename":"Post","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"This second workshop I decided to take was related to machine learning using AWS resources and for those unaware of what AWS is, AWS is…"},"collection":{"__ref":"Collection:95668a57d3dd"},"title":"My takeaway from hosting my second workshop","mediumUrl":"https:\u002F\u002Fmedium.com\u002Ftakeaway-chuck\u002Fmy-takeaway-from-hosting-my-second-workshop-586861c8ae12","primaryTopic":null,"previewImage":{"__ref":"ImageMetadata:"},"clapCount":4,"creator":{"__ref":"User:a4280b6f29b4"},"isSeries":false,"sequence":null,"uniqueSlug":"my-takeaway-from-hosting-my-second-workshop-586861c8ae12"},"ImageMetadata:1*0_XqS9Coorib-FGGwNziuQ.jpeg":{"id":"1*0_XqS9Coorib-FGGwNziuQ.jpeg","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:e5a0f35c766":{"id":"e5a0f35c766","__typename":"User","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"lakshmanraj23.medium.com"}},"hasSubdomain":true,"username":"lakshmanraj23"},"Post:e1a039db87e4":{"id":"e1a039db87e4","__typename":"Post","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Project Overview"},"collection":{"__ref":"Collection:7219b4dc6c4c"},"title":"Udacity Capstone-Identifying Dog Breeds Using Convolutional Neural Networks","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fanalytics-vidhya\u002Fidentifying-dog-breeds-using-convolutional-neural-networks-e1a039db87e4","primaryTopic":{"__ref":"Topic:1eca0103fff3"},"previewImage":{"__ref":"ImageMetadata:1*0_XqS9Coorib-FGGwNziuQ.jpeg"},"clapCount":1,"creator":{"__ref":"User:e5a0f35c766"},"isSeries":false,"sequence":null,"uniqueSlug":"identifying-dog-breeds-using-convolutional-neural-networks-e1a039db87e4"},"Collection:98111c9905da":{"id":"98111c9905da","__typename":"Collection","slug":"towards-artificial-intelligence","name":"Towards AI","domain":"pub.towardsai.net"},"ImageMetadata:0*FzqBw1PS4T2IxXQ4":{"id":"0*FzqBw1PS4T2IxXQ4","__typename":"ImageMetadata","alt":"Social Media usage in Sri Lanka","focusPercentX":null,"focusPercentY":null},"User:bba69b0859d3":{"id":"bba69b0859d3","__typename":"User","customDomainState":null,"hasSubdomain":false,"username":"santhoopajayawardhana"},"Post:b94196744eec":{"id":"b94196744eec","__typename":"Post","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Using Deep learning models to detect Sinhala hate speech on social media"},"collection":{"__ref":"Collection:98111c9905da"},"title":"Artificial Intelligence to Detect Hate Speech related Sinhala comments in Social Media","mediumUrl":"https:\u002F\u002Fpub.towardsai.net\u002Fai-to-detect-hate-speech-related-sinhala-comments-in-social-media-b94196744eec","primaryTopic":null,"previewImage":{"__ref":"ImageMetadata:0*FzqBw1PS4T2IxXQ4"},"clapCount":116,"creator":{"__ref":"User:bba69b0859d3"},"isSeries":false,"sequence":null,"uniqueSlug":"ai-to-detect-hate-speech-related-sinhala-comments-in-social-media-b94196744eec"},"Collection:ab4667ddfdad":{"id":"ab4667ddfdad","__typename":"Collection","slug":"louis-dorard","name":"Own Machine Learning","domain":null},"ImageMetadata:1*rhH-8BAIfDLrPcyKn880eg.jpeg":{"id":"1*rhH-8BAIfDLrPcyKn880eg.jpeg","__typename":"ImageMetadata","alt":null,"focusPercentX":null,"focusPercentY":null},"User:21b9cb0aa377":{"id":"21b9cb0aa377","__typename":"User","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"louisdorard.medium.com"}},"hasSubdomain":true,"username":"louisdorard"},"Post:5a28da957ab4":{"id":"5a28da957ab4","__typename":"Post","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"As the year just ended, I thought of sharing a selection of 12 great links on key and practical Machine Learning topics that I came across…"},"collection":{"__ref":"Collection:ab4667ddfdad"},"title":"12 great links on key Machine Learning topics in 2018","mediumUrl":"https:\u002F\u002Fmedium.com\u002Flouis-dorard\u002F12-great-links-on-key-machine-learning-topics-in-2018-5a28da957ab4","primaryTopic":null,"previewImage":{"__ref":"ImageMetadata:1*rhH-8BAIfDLrPcyKn880eg.jpeg"},"clapCount":4,"creator":{"__ref":"User:21b9cb0aa377"},"isSeries":false,"sequence":null,"uniqueSlug":"12-great-links-on-key-machine-learning-topics-in-2018-5a28da957ab4"},"User:104a7ff92a84":{"id":"104a7ff92a84","__typename":"User","name":"merlyn susan","bio":"","imageId":"0*2YDZHP6OKkoCm1WW.jpg","mediumMemberAt":0,"username":"merlynsusan5021","customDomainState":null,"hasSubdomain":false},"User:111bff8a7188":{"id":"111bff8a7188","__typename":"User","name":"Alexander Fedorenko","bio":"","imageId":"0*SRAonKycSq22cXgJ.jpg","mediumMemberAt":1637048354000,"username":"alex.grig.fed","customDomainState":null,"hasSubdomain":false},"User:11b4684b7c04":{"id":"11b4684b7c04","__typename":"User","name":"Sonu Ranjit Jacob","bio":"","imageId":"1*JUEAJ1r65NRgGhIXfBjk1A.png","mediumMemberAt":0,"username":"sonurjacob96","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"sonurjacob96.medium.com"}},"hasSubdomain":true},"User:16f8063f79c8":{"id":"16f8063f79c8","__typename":"User","name":"Bakkali Souhail","bio":"","imageId":"0*luFlNHk-z_di1zdp.","mediumMemberAt":0,"username":"souhail.bkl","customDomainState":null,"hasSubdomain":false},"User:1708eff7aa89":{"id":"1708eff7aa89","__typename":"User","name":"Rosli Fet","bio":"","imageId":"0*1suYOZ3O2MfY_MAX","mediumMemberAt":0,"username":"roslifet","customDomainState":null,"hasSubdomain":false},"User:18ba011c6262":{"id":"18ba011c6262","__typename":"User","name":"Marek Minarovič","bio":"","imageId":"0*ugegyEcdqAdM3fA9.","mediumMemberAt":0,"username":"mrkrm","customDomainState":null,"hasSubdomain":false},"User:1b66568e33c2":{"id":"1b66568e33c2","__typename":"User","name":"Pisit Makpaisit(Remixman)","bio":"Just a versatile programmer","imageId":"0*Mlkn-eK3FZyr4mW1.jpg","mediumMemberAt":0,"username":"remixman","customDomainState":null,"hasSubdomain":false},"User:1b66ab7113bc":{"id":"1b66ab7113bc","__typename":"User","name":"An Average Data Guy","bio":"","imageId":"1*P4S8ZV9qDP4b-Smh3opX-g.jpeg","mediumMemberAt":0,"username":"anaveragedataguy","customDomainState":null,"hasSubdomain":false},"User:1bce8a6f2aa4":{"id":"1bce8a6f2aa4","__typename":"User","name":"Noeurn Krol","bio":"","imageId":"1*7KU9E8hYulzeusRjm0R1BA.jpeg","mediumMemberAt":0,"username":"noeurnkrol","customDomainState":null,"hasSubdomain":false},"User:1bd169001911":{"id":"1bd169001911","__typename":"User","name":"Nachus MarS","bio":"","imageId":"1*HaCfwQz8IiciqstSLM3TpQ.jpeg","mediumMemberAt":0,"username":"nac.el.rojo","customDomainState":null,"hasSubdomain":false}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT","shouldUseCache":true}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.4949e24a.js"></script><script src="https://cdn-client.medium.com/lite/static/js/5786.875f6653.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.1679c86b.js"></script><script src="https://cdn-client.medium.com/lite/static/js/45573.4354ed57.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/instrumentation.2147e77b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/10407.21469f6d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/49216.e3d3bf0a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/AppLayout.2e0e912b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.55ddfe42.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/79678.176160d5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1752.a348f767.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7794.9590314e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/88316.3eb3bc8f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/82405.da63a51f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/75221.85bec25f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/27927.0c766d23.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/90786.25ebc206.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/95472.20329d15.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/59984.cee64d0e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/47464.370de892.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/43303.6bbe36a7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/69865.f2530e98.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/53818.52296386.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/85057.d191adbc.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/88246.12665b2e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/97332.3eda0eaa.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/28491.cf9aa3ed.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/31229.263afd61.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6562.02748b96.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/83284.3f2fce3d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/50864.38e6c977.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/50082.93fc8de3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/59616.82d95d9f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/86970.ac2ccbc2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/28360.8df461a9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/65281.92cfc4b6.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/74991.d7c10f4b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/68054.da9be6f8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/11914.8c229c33.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/13954.98d3b6a9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.2f08fa5b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/75374.164f9ef6.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.RightColumnContent.4310602b.chunk.js"></script><script>window.main();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"6f251293eccafb8c","token":"0b5f665943484354a59c39c6833f7078","version":"2021.12.0","si":100}' crossorigin="anonymous"></script>
</body></html>

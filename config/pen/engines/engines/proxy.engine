engine-title: Proxy
# The proxy engine isn't really offline.
# I will need to change some things like api-endpoint dynamically
include: Offline
model: DummyModel
api-endpoint: "http://localhost"
foundation: true
lm-command: "proxy-complete.sh"
engine-delimiter: "\n\n"
# For the API
default-temperature: 0.0
force-n-jobs: 1
modes:
- image-to-text
# modes:
# - search
# - classification
# 'layers' is like 'provides'. see glossary
layers:
- foundation
- nl
- code
- vision
# Pick this engine when you need 'just' NL âˆ© Code
specialities:
- nl+vision
# e.g. may also put finetuning labels at the end
# - python
engine-min-tokens: 0
engine-whitespace-support: yes
engine-max-tokens: 2048
upstream-engine: Offline